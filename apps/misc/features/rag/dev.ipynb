{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Imports"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import packages\n",
				"from configs import settings, const, components\n",
				"from configs.settings import logger\n",
				"import asyncio, os, time, yaml, json, datetime, copy, random\n",
				"from typing import Any, AsyncGenerator, Generator, Callable, Literal, Optional, TypeAlias, Union\n",
				"from tqdm import tqdm\n",
				"from pprint import pprint\n",
				"\n",
				"from toolkit.llm.llama_index import (\n",
				"\tagents, cores, deploys as dpls, evaluation, messages, models, \n",
				"\tobservability, types, utils as utils_llama_index, workflows as wfs\n",
				")\n",
				"from toolkit.llm.llama_index.data import loading, querying, storing\n",
				"\n",
				"from features.agents.car.tools import VehicleDB\n",
				"from features.agents.tools import map\n",
				"\n",
				"from toolkit.utils import utils, typer as t\n",
				"from toolkit.utils.llm import measure_performance, main as utils_llm\n",
				"from toolkit.utils.utils import rp_print"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# RAG"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"<span style=\"color: red;\">We are currently in the migration process.<br>\n",
				"The cell below contains the implementation of the LlamaIndex framework.<br>\n",
				"You may not need to execute this. For more information on LangChain implementation, please refer to the URLs listed in the Reference section.\n",
				"</span>\n",
				"\n",
				"Please use LangChain version:\n",
				"```\n",
				"pip install --upgrade -r apps/requirements/dev.langchain.requirements.txt\n",
				"```"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"prompts_rag = settings.prompts_rag\n",
				"\n",
				"prompt_generate_result = prompts_rag[\"generate_result\"]\n",
				"\n",
				"queries = [\n",
				"\t\"Could you provide some tips or notes to consider before driving a car?\",\n",
				"\t\"How can parents prevent children from accidentally opening doors or windows while driving?\",\n",
				"\t\"When should a child start using the vehicle's seat belt instead of a child restraint system?\",\n",
				"\t\"What is the recommended seating position for children in a vehicle?\",\n",
				"]\n",
				"\n",
				"user_query = queries[1]\n",
				"\n",
				"retrieved_data = await utils.time_it(\n",
				"\tlambda: await components.retriever_car_manual.aretrieve(user_query), \n",
				" \tname=\"Vector Database Data Retrieval\"\n",
				")\n",
				"\n",
				"# retrieved_data = await components.retriever_car_manual.aretrieve(user_query)\n",
				"\n",
				"retrieved_data_texts = await utils_llama_index.extract_text(retrieved_data)\n",
				"\n",
				"async for token in await utils_llama_index.interact_model(\n",
				"\tprompt=prompt_generate_result, system_prompt=prompts_rag[\"system\"][\"car_manual\"],\n",
				"\tmode=\"astream\", \n",
				"\tuser_question=user_query, retrieved_data=retrieved_data_texts,\n",
				"\tmeasure_performance=True,\n",
				"):\n",
				"  print(token, end=\"\", flush=True)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Ref"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"- https://python.langchain.com/docs/tutorials/rag/\n",
				"- https://python.langchain.com/docs/tutorials/qa_chat_history/\n",
				"- https://python.langchain.com/docs/integrations/vectorstores/qdrant/\n",
				"- Graph\n",
				"  - https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/\n",
				"  - https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag/\n",
				"  - https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_crag/\n",
				"  - https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_self_rag/\n",
				"  - https://langchain-ai.github.io/langgraph/tutorials/sql-agent/"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Note:\n",
				"- For a quick start, utilize the OpenAI GPT-3.5 model: https://python.langchain.com/docs/integrations/llms/openai/"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Migrate from LlamaIndex to LangChain\n",
				"\n",
				"- https://docs.llamaindex.ai/en/stable/examples/vector_stores/QdrantIndexDemo/\n",
				"- https://docs.llamaindex.ai/en/stable/understanding/rag/\n",
				"- https://docs.llamaindex.ai/en/stable/understanding/agent/rag_agent/\n",
				"- https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/\n",
				"- module_guides\n",
				"  - https://docs.llamaindex.ai/en/stable/module_guides/loading/\n",
				"  - https://docs.llamaindex.ai/en/stable/module_guides/indexing/\n",
				"  - https://docs.llamaindex.ai/en/stable/module_guides/storing/\n",
				"  - https://docs.llamaindex.ai/en/stable/module_guides/querying/\n",
				"- Examples\n",
				"  - Workflows\n",
				"    - https://docs.llamaindex.ai/en/stable/examples/workflow/citation_query_engine/\n",
				"    - https://docs.llamaindex.ai/en/stable/examples/workflow/corrective_rag_pack/\n",
				"    - https://docs.llamaindex.ai/en/stable/examples/workflow/long_rag_pack/\n",
				"    - https://docs.llamaindex.ai/en/stable/examples/workflow/rag/"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "dev",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.15"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
