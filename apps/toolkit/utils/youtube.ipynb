{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-api-python-client youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "def get_video_title(video_id: str) -> Tuple[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Fetch video title using video ID.\n",
    "    Returns tuple of (title, error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get webpage content\n",
    "        url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "        html = urllib.request.urlopen(url).read().decode()\n",
    "        \n",
    "        # Search for title in meta data\n",
    "        title_match = re.search(r'<meta name=\"title\" content=\"([^\"]+)\"', html)\n",
    "        if title_match:\n",
    "            return title_match.group(1), None\n",
    "            \n",
    "        # Alternative method: search in page title\n",
    "        title_match = re.search(r'<title>([^<]+)</title>', html)\n",
    "        if title_match:\n",
    "            title = title_match.group(1).replace(' - YouTube', '')\n",
    "            return title, None\n",
    "            \n",
    "        return \"Unknown Title\", \"Could not extract title\"\n",
    "    except Exception as e:\n",
    "        return \"Unknown Title\", f\"Error fetching title: {str(e)}\"\n",
    "\n",
    "def extract_video_id(url: str) -> Optional[str]:\n",
    "    \"\"\"Extract video ID from YouTube URL.\"\"\"\n",
    "    patterns = [\n",
    "        r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*',\n",
    "        r'(?:embed\\/)([0-9A-Za-z_-]{11})',\n",
    "        r'(?:youtu\\.be\\/)([0-9A-Za-z_-]{11})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "def get_transcript(video_id: str) -> tuple[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Fetch transcript for a single video.\n",
    "    Returns tuple of (transcript_text, error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        full_text = ' '.join(item['text'] for item in transcript_list)\n",
    "        return full_text, None\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error fetching transcript for video {video_id}: {str(e)}\"\n",
    "        return \"\", error_msg\n",
    "\n",
    "def save_transcripts(urls: List[str], output_file: str) -> None:\n",
    "    \"\"\"Process YouTube URLs and save their transcripts to a file.\"\"\"\n",
    "    \n",
    "    # Create or overwrite output file\n",
    "    with Path(output_file).open('w', encoding='utf-8') as f:\n",
    "        for url in urls:\n",
    "            # Extract video ID\n",
    "            video_id = extract_video_id(url)\n",
    "            if not video_id:\n",
    "                logger.warning(f\"Invalid YouTube URL: {url}\")\n",
    "                continue\n",
    "                \n",
    "            # Get video title\n",
    "            logger.info(f\"Processing video: {url}\")\n",
    "            title, title_error = get_video_title(video_id)\n",
    "            \n",
    "            # Get transcript\n",
    "            transcript, transcript_error = get_transcript(video_id)\n",
    "            \n",
    "            # Write to file\n",
    "            f.write(f\"\\n=== Video Information ===\\n\")\n",
    "            f.write(f\"URL: {url}\\n\")\n",
    "            f.write(f\"Title: {title}\\n\")\n",
    "            if title_error:\n",
    "                f.write(f\"Title Error: {title_error}\\n\")\n",
    "            f.write(\"\\n=== Transcript ===\\n\")\n",
    "            if transcript_error:\n",
    "                f.write(f\"Error: {transcript_error}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{transcript}\\n\")\n",
    "            f.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "urls = [\n",
    "\t\"https://youtu.be/wwC86t5k77Y?si=uvSH2RJ34WE4o5wY\",\n",
    "\t\"https://youtu.be/fv1rkctrEPk?si=5xL18SO0S95U-pv9\",\n",
    "\t\"https://youtu.be/K0it90lnqnk?si=ycfjnE0sEhXT_kwX\",\n",
    "\t\"https://youtu.be/Nl6SVPpRUQI?si=TVmfJTZTzJk82eyC\",\n",
    "\t\"https://youtu.be/jnaeB6LjoQs?si=FPRySBEux7h2icIs\",\n",
    "\t\"https://youtu.be/CG-USxkH_Ho?si=jANv1CLodMNbWmPs\",\n",
    "\t\"https://youtu.be/2mY9YT2yUy4?si=ZpWhPRa1Vw1R5dzA\",\n",
    "\t\"https://youtu.be/uSMdnoTdG2E?si=-kM93wOrkr1Y31xv\",\n",
    "]\n",
    "save_transcripts(urls, \"transcripts.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from pytube import YouTube\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def get_youtube_script(video_url: str) -> tuple[str, str, str]:\n",
    "    try:\n",
    "        # Extract video ID from URL\n",
    "        if \"v=\" in video_url:\n",
    "            video_id = video_url.split(\"v=\")[1]\n",
    "        else:\n",
    "            split_url = video_url.split(\"/\")\n",
    "            video_id = split_url[-1].split(\"?\")[0]\n",
    "\n",
    "        # Get video title and channel name\n",
    "        yt = YouTube(video_url)\n",
    "        title = yt.title\n",
    "        channel = yt.author\n",
    "\n",
    "        # Get transcript\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        script = ' '.join([entry['text'] for entry in transcript])\n",
    "\n",
    "        return title, channel, script\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}. video_url: `{video_url}`\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def extract_n_save_info(yaml_file: str):\n",
    "    # Load the YAML file\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        videos = yaml.safe_load(file)\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        title, channel, _ = get_youtube_script(video['url'])\n",
    "        if title and channel:\n",
    "            video['title'] = title\n",
    "            video['channel'] = channel\n",
    "\n",
    "    # Save the updated data back to the YAML file\n",
    "    with open(yaml_file, 'w') as file:\n",
    "        yaml.dump(videos, file)\n",
    "\n",
    "def process_title(title: str) -> str:\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    import re\n",
    "    processed_title = re.sub(r'[^\\w\\s-]', '', title)\n",
    "    processed_title = re.sub(r'\\s+', '_', processed_title)\n",
    "    return processed_title.lower()\n",
    "\n",
    "def process_videos(yaml_file: str):\n",
    "    # Load the YAML file\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        videos: list = yaml.safe_load(file)\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        if 'title' in video:\n",
    "            video['title'] = process_title(video['title'])\n",
    "        \n",
    "        # Fetch channel info if missing\n",
    "        if 'channel' not in video or video['channel'] is None:\n",
    "            _, channel, _ = get_youtube_script(video['url'])\n",
    "            video['channel'] = channel\n",
    "\n",
    "    # Sort the list of videos based on the 'channel' key, handling None values\n",
    "    videos.sort(key=lambda x: (x['channel'] is None, x['channel']))\n",
    "\n",
    "    # Save the sorted data back to the YAML file\n",
    "    with open(yaml_file, 'w') as file:\n",
    "        yaml.dump(videos, file)\n",
    "\n",
    "\n",
    "def save_youtube_script(video_url: str, output_file: str):\n",
    "\ttitle, channel, script = get_youtube_script(video_url)\n",
    "\tif script:\n",
    "\t\twith open(output_file, 'w', encoding='utf-8') as file:\n",
    "\t\t\t\tfile.write(f\"Title: {title}\\nChannel: {channel}\\nScript: {script}\\n\\n\")\n",
    "\n",
    "def save_youtube_scripts(yaml_file: str, output_file: str, duration_limit: int):\n",
    "    # Split the output file into directory and file name\n",
    "    directory = os.path.dirname(output_file)\n",
    "    base_name, extension = os.path.splitext(os.path.basename(output_file))\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Load the YAML file\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        videos = yaml.safe_load(file)\n",
    "\n",
    "    total_duration = 0\n",
    "    file_index = 0\n",
    "    current_file = os.path.join(directory, f'{base_name}_{file_index}{extension}')\n",
    "    file_handle = open(current_file, 'w', encoding='utf-8')\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        title, channel, script = get_youtube_script(video['url'])\n",
    "        if title and channel and script:\n",
    "            video_duration = video['length']\n",
    "            if total_duration + video_duration > duration_limit:\n",
    "                file_handle.close()\n",
    "                file_index += 1\n",
    "                current_file = os.path.join(directory, f'{base_name}_{file_index}{extension}')\n",
    "                file_handle = open(current_file, 'w', encoding='utf-8')\n",
    "                total_duration = 0\n",
    "\n",
    "            file_handle.write(f\"Title: {title}\\nChannel: {channel}\\nScript: {script}\\n\\n\" + \"-\"*80 + \"\\n\\n\")\n",
    "            total_duration += video_duration\n",
    "            video['title'] = title\n",
    "            video['channel'] = channel\n",
    "\n",
    "    file_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_n_save_info(\n",
    "#     yaml_file=\"tmp/script_urls/prompt_engineering.yaml\",\n",
    "# )\n",
    "\n",
    "# process_videos(\n",
    "# \tyaml_file=\"tmp/script_urls/prompt_engineering.yaml\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_youtube_scripts(\n",
    "\tyaml_file=\"tmp/script_urls/prompt_engineering.yaml\",\n",
    "\toutput_file=\"./tmp/scripts/prompt_engineering/youtube_scripts.txt\",\n",
    "\tduration_limit=60,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import config\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = \"https://www.youtube.com/watch?v=vU2S6dVf79M\"\n",
    "script = get_youtube_script(youtube_url)\n",
    "\n",
    "with open(\"./data/llm_input.txt\", 'w', encoding='utf-8') as file:\n",
    "    file.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/llm_input.txt'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Split the content into paragraphs based on the newline character\n",
    "paragraphs = content.split('\\n\\n')\n",
    "\n",
    "# Remove empty paragraphs\n",
    "paragraphs = [paragraph.strip()\n",
    "              for paragraph in paragraphs if paragraph.strip()]\n",
    "\n",
    "# gpt-3.5-turbo-0125, gpt-3.5-turbo-instruct\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "\n",
    "template = \"\"\"\\\n",
    "Your output should use the following template:\n",
    "\n",
    "# Keywords/Entities/Concepts/Complex Words\n",
    "\n",
    "## Name\n",
    "- Definition: Explanation, Core Meaning,  Key Features, Essential Attributes, Distinguishing Traits\n",
    "- Types: Varieties, Classifications, Different Forms\n",
    "- Usage: Practical Applications, Common Scenarios, Real-world Examples\n",
    "- Benefits, Challenges/Limitations/Issues\n",
    "- Others: Additional Insights, Miscellaneous Information, Noteworthy Details, History, Related Concepts\n",
    "\n",
    "# Techniques\n",
    "\n",
    "## Name\n",
    "- Description: Overview of the technique. Explanation of the fundamental concept/idea behind the technique.\n",
    "- Components: Breakdown of the key elements or parts involved in the technique.\n",
    "- Pipeline: Stages/Steps that outline the process flow of the technique, illustrating how data or tasks move through the system.\n",
    "- Implementation: Details on how to apply or integrate the technique. Recommended guidelines, strategies, Best Practices for using the technique effectively.\n",
    "- Use Cases: Examples and scenarios where the technique is particularly useful.\n",
    "- Advantages: Discussion of the benefits and strengths of the technique.\n",
    "- Limitations: Identification of any drawbacks or constraints associated with the technique. Potential mistakes or issues to be aware of when implementing the technique.\n",
    "\n",
    "Apply the following guidelines:\n",
    "- Create a detailed summary of the YouTube video using its transcription.\n",
    "- Extract important keywords from the transcript.\n",
    "- Identify complex words that may be unfamiliar to the average reader.\n",
    "- Extract techniques mentioned in the video.\n",
    "- If a keyword and a technique share the same name, combine them into one section.\n",
    "- Ensure that explanations are derived from the entire script.\n",
    "- Provide a comprehensive and clear understanding of the video's content.\n",
    "- Don't make it up. Only output content from the script only.\n",
    "\n",
    "Here is the script:\n",
    "{text}\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "chain = prompt_template | model\n",
    "\n",
    "output_file_path = './data/llm_output.txt'\n",
    "with open(output_file_path, 'a', encoding='utf-8') as f:\n",
    "  for i in tqdm(range(len(paragraphs))):\n",
    "    result = chain.invoke({\"text\": paragraphs[i]}).content\n",
    "    f.writelines(result + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
