Basics Guide Overview
üü¢
This article is rated easy
Reading Time: 3 minutes
Last updated on October 22, 2024
Valeriia Kuka

steps


Welcome to the Basics Section of the Prompt Engineering Guide.
This section is designed to introduce you to prompt engineering, a critical skill when working with generative AI models such as ChatGPT, Gemini, Cohere Chat, Claude, and more. Through this guide, you'll gain foundational knowledge about these AI tools and the basic techniques needed to harness their potential effectively.

The guide provides a non-technical introduction to Generative AI (GenAI), covering prompting strategies, popular GenAI tools, and practical ways to integrate GenAI into your everyday life. Whether you're a complete beginner or someone looking to enhance your skills, this guide will help you get started quickly. As you progress, the subsequent modules will deepen your knowledge and refine your prompting techniques for various AI use cases.

Below is a summary of the key topics covered in this guide. Click on any section to jump directly to that topic.

Key Sections of the Guide
Introduction to AI: A brief introduction to Artificial Intelligence (AI) and Generative AI, explaining how these systems work and their impact.

Getting Started with ChatGPT: Learn how to set up and use ChatGPT for various tasks, from simple queries to advanced functions like summarizing text and solving problems.

Learn Prompting Embeds: An interactive tool that allows you to experiment with different prompts directly on the Learn Prompting website to improve your prompting skills.

Prompt Engineering: Discover the fundamentals of prompt engineering, a critical skill for working with generative AI models like ChatGPT and DALL-E, and learn how to craft effective prompts.

How to Write an Effective Prompt?: A practical guide with tips and techniques to improve the quality of your AI's responses, whether you're writing, coding, or generating images.

Giving Instructions: This guide dives into instruction prompting, explaining how to provide clear, concise instructions to get the desired output from generative AI models.

Assigning Roles: Learn how to use role prompting to assign specific roles to AI models, helping you control the tone, style, and accuracy of the generated content for various tasks.

Shot-Based Prompting: Explore zero-shot, one-shot, and few-shot prompting techniques. Learn how providing examples to the AI can improve accuracy, along with real-world applications of each method.

Parts of a Prompt: A detailed breakdown of the key components of a prompt, including examples and tips to help you structure your prompts for optimal results.

Combining Techniques: Discover how to combine different prompting techniques, such as context, instructions, and examples, to enhance the AI model's ability to handle more complex tasks.

Chatbots vs. LLMs: Learn the key differences between chatbots and large language models (LLMs), exploring why chatbots are often the preferred interface for interacting with LLMs.

Priming Prompt: Priming chatbots involves structuring prompts to guide the chatbot‚Äôs responses. Learn how to use this technique to influence the behavior and output of chatbots for specific goals.

Limitations of LLMs: While LLMs are powerful, they have limitations. This document covers common challenges like hallucinations, biases, and prompt hacking, and offers strategies to work around them.

Beyond LLMs: Generative AI Applications Beyond Text Data: Explore the full range of generative AI capabilities beyond text generation, including image, audio, and video creation, and how these applications are shaping industries.

Problem Solving with GenAI: Learn the Learn Prompting Method, a structured approach to problem-solving using generative AI, from identifying the right tools to refining prompts through testing.

Moving Forward: Beyond the Basics: A sneak peek into advanced prompt engineering techniques and applications that will help you deepen your skills and expertise as you move beyond the basics.

---

Introduction to AI
üü¢
This article is rated easy
Reading Time: 3 minutes
Last updated on October 22, 2024
Valeriia Kuka


techniques


Introduction
In this document, we briefly introduce the concept of Artificial Intelligence (AI) and its known as Generative AI.

You‚Äôll learn about:

What is AI?
How AI Learns
What is Generative AI?
Examples of Generative AI
How Do I Get Started with Generative AI?
What is AI?
Artificial Intelligence (AI) is all about making machines smarter ‚Äî giving them the ability to perform tasks that usually need human intelligence. These tasks could be anything from recognizing faces in photos and understanding speech to recommending products and even playing chess at a level that no human can match. In simple terms, AI allows machines to "think" and learn from data to solve problems and make decisions 1
This is a simplified definition of AI. For a deeper dive, check out Wikipedia.

.

You likely interact with AI daily without realizing it. For example, voice assistants like Siri or Alexa use AI to understand and respond to your questions‚Äîwhether you're asking for the weather or setting an alarm. Netflix‚Äôs recommendation system is another example, learning what you like to watch and suggesting new shows or movies based on your viewing history.

How AI Learns
AI learns from data, much like how humans learn from experience. For instance, to train an AI to recognize cats in photos, you would provide thousands of cat images. Over time, the AI learns what makes a cat‚Äîa process that improves as it gets more data.

In this guide, however, we are focusing on a special kind of AI called Generative AI.

What is Generative AI?
Generative AI is a type of AI designed to create new content. Unlike traditional AI, which processes data or makes decisions, Generative AI can actually generate things that didn‚Äôt exist before ‚Äî a job previously reserved for humans.

For example, GenAI can handle creative tasks like:

Writing essays and articles
Crafting emails
Creating artwork or illustrations (and even winning art competitions)
Solving complex math problems
Generating code for software
Check out more GenAI use cases.

Examples of Generative AI
Here are a few popular Generative AI tools you might have heard of:

ChatGPT: A large language model (LLM) that can generate text, answer questions, and even have conversations.
DALL-E: A Generative AI that creates images from text descriptions. Want to see ‚Äúa cat in a space suit‚Äù? DALL-E will generate a unique image based on that exact prompt.
MidJourney: Another text-to-image tool known for creating highly detailed and creative artwork.
Note
In this guide, we‚Äôre focusing on large language models (LLMs) like ChatGPT.

How Do I Get Started with Generative AI?
This guide will walk you through the basics of Generative AI, from prompting strategies to the most popular tools. Whether you want to integrate AI into your daily life or just experiment with it, this is the place to start. You can also take our free course that will walk you throught the fundamentals of LLMs like ChatGPT and their real-life applications.

---

Getting Started with ChatGPT
üü¢
This article is rated easy
Reading Time: 6 minutes
Last updated on October 22, 2024
Valeriia Kuka

chatgpt interface



Introduction
Throughout this basics guide, we‚Äôll be using ChatGPT ‚Äî one of the most popular and accessible AI chatbots. It's known for its versatility, handling a wide variety of tasks, and is easy to get started with.

Tip
If you'd like a more detailed introduction to ChatGPT with visual step-by-step guidance, check out our free course, ChatGPT for Everyone. You'll learn how to write your first prompt, explore ChatGPT's use cases, and dive into the basics of prompt engineering to improve your results.

In this guide, we‚Äôll walk you through setting up ChatGPT and show you how to use it for everything from simple queries to more advanced tasks like summarizing text and solving math problems.

Here are the main steps we'll cover:

Set up ChatGPT
Testing simple queries with ChatGPT
Best practices for prompting ChatGPT
Troubleshooting common issues
Conclusion
FAQ
1. Set up ChatGPT
Getting started with ChatGPT is simple:

Navigate to http://chat.openai.com
It should ask you to make an account. Go ahead and do so.
Log in with this account
Need help with setup? Here‚Äôs a helpful video to guide you through:


Mobile Setup
You can also download the ChatGPT app from your device‚Äôs app store (iOS/Android). The interface is similar, and you can log in with the same account.

2. Try Out Some Prompts with ChatGPT
Now that you've set up ChatGPT, let‚Äôs try a few prompts, starting with basic questions and moving to more advanced tasks like summarizing text or solving math problems.

Note
A prompt is an input or instruction provided to an AI model to generate a response. Prompts can take many forms, from simple questions to more complex instructions that specify tone, style, or structure. You can read more about prompts in our doc about prompt engineering.

2.1 Simple Query: Color of Grass
Let‚Äôs start with a very simple question. Can ChatGPT tell us the color of grass?

 Copy
Astronaut
Prompt
What color is grass?

 Copy
Robot
AI Output
Grass is green.

This is a straightforward factual query. It‚Äôs a great way to get a feel for how ChatGPT responds to simple inputs.

2.2 Summarizing an Article
Now, let's try something more practical: summarizing a paragraph. Say you‚Äôre reading an article about snowfall in Florida and want to quickly grasp the main points. You can paste the paragraph into ChatGPT and ask for a summary 1
This paragraph is from https://en.wikipedia.org/wiki/Snow_in_Florida

:

 Copy
Astronaut
Prompt
It is very rare for snow to fall in the U.S. state of Florida, especially in the central and southern portions of the state. Except for the far northern areas of the state, most of the major cities in Florida have never recorded measurable snowfall, though trace amounts have been recorded, or flurries in the air observed a few times each century. According to the National Weather Service, in the Florida Keys and Key West, there is no known occurrence of snow flurries since the European colonization of the region more than 300 years ago. In Miami, Fort Lauderdale, and Palm Beach there has been only one known report of snow flurries observed in the air in more than 200 years; this occurred in January 1977. In any event, Miami, Fort Lauderdale, and Palm Beach have not seen snow flurries before or since this 1977 event.

Summarize this paragraph in a single sentence:

Here‚Äôs the response:

 Copy
Robot
AI Output
Snowfall is extremely rare in Florida, except for the far northern areas, and only one instance of snow flurries in the air has been recorded in the major cities of Miami, Fort Lauderdale, and Palm Beach in the last 200 years.

Caution
Your result may differ slightly because ChatGPT‚Äôs responses can vary. We‚Äôll explain why later in this guide.

2.3 Solving Math Problems
ChatGPT can also solve math problems! Let‚Äôs give it a simple arithmetic problem to see how it handles math.

 Copy
Astronaut
Prompt
If I have 20 apples, eat three of them, and sell three more, how many do I have left?

 Copy
Robot
AI Output
If you have 20 apples and you eat three of them, you will have 20 - 3 = 17 apples left.

After eating three apples (17 left), if you sell three more, you will have 17 - 3 = 14 apples left.

It‚Äôs that simple! ChatGPT can handle both basic and more advanced math problems, even walking you through solutions step-by-step for more complicated calculations.

3. Best Practices for Prompting ChatGPT
Here are some tips to help you craft effective prompts and get the most out of ChatGPT:

Be specific: The more specific your prompt, the better the response.

For example, instead of asking "What is grass?" ask "What color is grass in most regions?"
Set constraints: If you want concise answers, specify this in your prompt.

For example, "Summarize this article in 20 words."
Break down complex tasks: For multi-step tasks, break your prompt into smaller, manageable parts.

For example, instead of asking ChatGPT to solve a complicated math problem outright, ask it to walk through each step.
Experiment: Feel free to ask the same question in different ways to understand how ChatGPT interprets your inputs. This will help you refine your prompts for better results.

4. Conclusion
You should now be comfortable with what a prompt is and how to do some basic prompting with ChatGPT. Remember that prompts are the core of how you interact with AI models like ChatGPT, and effective prompting can lead to more accurate and useful responses.

Keep in mind that prompt can be a verb or a noun. You can prompt a model, or you can give a model a prompt. Both mean the same thing, and the process of interacting with the model this way is called prompting. We‚Äôll dive deeper into prompt engineering techniques in the next lesson to further refine how you interact with ChatGPT.

5. Troubleshooting Common Issues
Issue: ChatGPT‚Äôs response is too vague.
Solution: Rephrase your prompt to provide more specific instructions.

For example, instead of asking, "What is an apple?" try, "What are the nutritional benefits of an apple?"
Issue: ChatGPT misunderstood my question.
Solution: Break the task down into smaller parts or provide more context to help ChatGPT understand the question better. You can also ask follow-up questions to clarify the output.

Issue: ChatGPT is repeating information.
Solution: Try adding constraints to your prompt, such as ‚ÄúDo not repeat previous details,‚Äù to encourage a more focused response.

6. FAQ
What is a prompt?
A prompt is a user input given to an large language model (LLM) like ChatGPT. It describes a task or instruction to the AI, and it‚Äôs the primary way to interact with these models. A prompt can be a question, a command, or a request for information.

What kind of prompts can I use?
In this article, we used examples of a simple factual question (color of grass), summarization of a paragraph, and solving a math problem. You‚Äôll learn more about different types of prompts as you continue your journey with ChatGPT.

Can I ask ChatGPT multiple questions in one conversation?
Yes! ChatGPT can handle multi-turn conversations and remember the context of the ongoing dialogue. This allows you to ask follow-up questions or refine your request based on its previous answers.

---

Prompt Engineering
üü¢
This article is rated easy
Reading Time: 7 minutes
Last updated on October 22, 2024
Valeriia Kuka


Introduction
In this document, we introduce you to the concept of prompt engineering and explain why it's a crucial skill when working with Generative AI models like ChatGPT and DALL-E.

We cover:

What is Prompt Engineering?
Why Prompt Engineering is Important
What is a Prompt?
Example of Applying Prompt Engineering to Improve the Prompt
Examples of Prompt Engineering in Action
Text Generation
Image Generation
Code Generation
Creative Tasks: Writing Tweets
Tip
If you're into prompt engineering, check our list of the 14 best prompt engineering courses with certificates.

What is Prompt Engineering?
Prompt engineering is the process of crafting and refining prompts to improve the performance of generative AI models. It involves providing specific inputs to tools like ChatGPT, Midjourney, or Gemini, guiding the AI to deliver more accurate and contextually relevant outputs.

Note
When an AI model doesn‚Äôt produce the desired response, prompt engineering allows us to iterate and adjust the prompt to optimize the output. This method is particularly useful for overcoming limitations of generative models, such as logical errors or insufficient context in responses.

Why Prompt Engineering is Important?
Generative AI relies heavily on the input it receives. The more clearly and contextually a task is described, the better the AI can respond. While anyone can try basic prompts, prompt engineering as a skill allows users to structure queries that better unlock an AI‚Äôs capabilities. Prompt engineering enables tasks from writing creative text to generating images or even code.

In today‚Äôs AI landscape, where large language models (LLMs) power a wide range of applications, prompt engineering is essential. It helps bridge the gap between vague, general queries and specific, targeted outputs that align with your goals. This iterative process ensures that the AI not only understands your intent but delivers results that require minimal post-processing.

Moreover, prompt engineering can mitigate risks like prompt injection attacks (where users try to manipulate the AI‚Äôs logic) and ensure that the model‚Äôs outputs align with desired ethical and operational standards.

What is a Prompt?
A prompt is an input or instruction provided to an AI model to generate a response. Prompts can take many forms, from simple questions to more complex instructions that specify tone, style, or structure. They‚Äôre the mechanism through which users communicate with AI models, and the clarity of the prompt directly influences the quality of the AI‚Äôs output.

Here's an example of a prompt:

 Copy
Astronaut
Prompt
What is 923 * 99?

Let's see how it works:

 Copy
Robot
AI Output
923 * 99 equals 91,677.

In this case, ChatGPT confidently gives an incorrect answer (the correct answer is 91,377). The issue here is that the model isn‚Äôt designed to perform complex mathematical reasoning accurately on demand.

Applying Prompt Engineering to Improve the Prompt
Generative AI models, like ChatGPT, can sometimes produce incorrect or misleading outputs. This often happens when a prompt is too vague, lacks necessary details, or doesn‚Äôt provide clear instructions.

Let's try to refine the prompt and encourage step-by-step reasoning to improve model's output:

 Copy
Astronaut
Improved Prompt
What is 923 * 99?

Let's go step by step.

Always write out the full number of 0s for each term.

What model outputs:

 Copy
Robot
AI Output
To multiply 923 by 99, we can break it down into smaller steps:

Step 1: Write out the full number of 0s for each term: 923 * 99 = 923 * 990

Step 2: Multiply the first term by 9: 923 * 9 = 8307

Step 3: Multiply the first term by 90 (adding one 0): 923 * 90 = 83070

Step 4: Add the results from step 2 and step 3: 8307 + 83070 = 91377

Therefore, 923 multiplied by 99 is equal to 91,377.

Interestingly, with these additional instructions, ChatGPT provides the correct answer by walking through the steps.

This process of editing and refining the prompt is what we call prompt engineering. Adding specificity and guidance to the prompt improves the output and guides the model apply logical reasoning more effectively.

Why Did This Updated Prompt Work?
Generative AI models are trained to predict text based on patterns instead of deep reasoning or factual accuracy. By prompting the model to explicitly think through its steps and break down the problem, we reduce the chance of mistakes and make the task easier for the model to handle.

Examples of Prompt Engineering in Action (Text, Image, and Code)
Prompt engineering is versatile and can be applied to many use cases across text, image, and code generation.

Here are some examples to illustrate its range:

Text
Let‚Äôs start with text-based models like ChatGPT. Suppose you need help writing a marketing summary:

 Copy
Astronaut
Initial Prompt
Write a marketing summary for a new AI tool that helps companies automate tasks.

The output might be too generic, so you refine it:

 Copy
Astronaut
Refined Prompt
Write a 100-word marketing summary for an AI tool called TaskBot, which automates repetitive tasks for small businesses in industries like retail and healthcare. Highlight efficiency and cost savings.

This provides clearer instructions and results in a more targeted response.

Image Generation
For models like Midjourney or DALL-E, prompts are crafted to generate specific imagery.

 Copy
Astronaut
Initial Prompt
A cat sitting on a chair.

By adding more details, you guide the model to generate an image that aligns with your vision.

 Copy
Astronaut
Refined Prompt
Generate an image of a tabby cat sitting on a wooden chair in a cozy, sunlit room, with soft shadows and warm lighting.

Code Generation
Prompts can help generate or optimize code:

 Copy
Astronaut
Initial Prompt
Write a Python function to multiply two numbers.

 Copy
Astronaut
Refined Prompt
Write a Python function that multiplies two integers and returns the result. Include error handling for cases where inputs are not integers.

This ensures the AI writes robust, real-world-ready code.

Prompt Engineering for Creative Tasks: Writing Tweets
Next, let‚Äôs apply prompt engineering in a creative context. Imagine we are developing a fictional AI product called "ArchaeologistAI," which tells stories about famous archaeologists. Let's ask ChatGPT to write a marketing tweet about it.

 Copy
Astronaut
Prompt
Write a tweet about ArchaeologistAI.

 Copy
Robot
AI Output
üîç Exciting times ahead with #ArchaeologistAI!

This cutting-edge technology is revolutionizing the field of archaeology, helping us uncover ancient mysteries and piece together our past like never before.

Can't wait to see what hidden treasures and insights it unveils!

#AI #Archaeology

Including Relevant Information in the Prompt
This Tweet is inaccurate because ArchaeologistAI doesn't discover new things‚Äîit only tells stories. This isn‚Äôt ChatGPT‚Äôs fault, as it wasn‚Äôt given enough context.

Let‚Äôs refine the prompt by including more specific details:

 Copy
Astronaut
Prompt
Write a tweet about ArchaeologistAI.

ArchaeologistAI tells stories about famous archaeologists.

 Copy
Robot
AI Output
üîç Unearth the captivating tales of legendary archaeologists with #ArchaeologistAI!

From Indiana Jones to Mary Leakey, this AI-powered storyteller brings their adventures to life, shedding light on their groundbreaking discoveries and inspiring the next generation of explorers.

üåç #Archaeology

Much better now! This is a much more accurate output because we added key details about the product‚Äôs functionality.

Changing Style of the AI Output with the Prompt
Now, let‚Äôs refine it further by asking ChatGPT to write the tweet in the style of Indiana Jones:

 Copy
Astronaut
Prompt
Write a tweet about ArchaeologistAI, in the style of Indiana Jones.

ArchaeologistAI tells stories about famous archaeologists.

 Copy
Robot
AI Output
Grab your fedora and whip, folks! üé©üî•

ArchaeologistAI is like having a personal Sallah by your side, sharing captivating tales of legendary archaeologists who've braved ancient tombs and unearthed hidden treasures! üó∫Ô∏èüíé

Get ready to embark on a digital adventure through history!

#ArchaeologistAI #UnearthTheLegends

Alright, that may be the message we need to target archaeology fans! This version adds a fun, thematic spin to the message, making it more engaging. By iterating and refining the prompt, we were able to achieve the desired result.

Conclusion
Prompt engineering is an iterative process. The perfect prompt rarely happens on the first try, so it‚Äôs essential to practice refining your inputs to get the best possible output from generative AI models. As we‚Äôve seen, adding specificity, providing context, and guiding the model with detailed instructions can significantly improve its responses.

In the following docs, we‚Äôll explore different prompting strategies that will help you get better at crafting prompts for a variety of AI applications.

FAQ
Why is prompt engineering important?
Basic prompts often lead to incorrect or suboptimal answers from generative AI models. Prompt engineering allows you to refine user instructions, adding context and specificity to improve the accuracy and relevance of the model‚Äôs responses.

Why was prompt engineering effective in the ArchaeologistAI example?
In the ArchaeologistAI example, refining the prompt provided the model with the necessary context and instructions, resulting in a tweet that better aligned with the product‚Äôs functionality. By iterating on the prompt, we also tailored the message to a specific audience.

How can I become a better prompt engineer?
Becoming a better prompt engineer requires practice. Experiment with prompts across different domains, learn from failures, and continuously test new strategies. Our Learn Prompting guide provides a wide range of tools and techniques to help you master the art of prompt engineering.

---

Giving Instructions
üü¢
This article is rated easy
Reading Time: 5 minutes
Last updated on October 21, 2024
Sander Schulhoff

instruction prompt


Introduction
In this document, we cover our first prompting technique, instruction prompting. It consists in providing clear instructions or directives to the AI model.

We have already seen simple instructions used in the doc about prompt engineering like getting an AI to solve the math problem. However, we can instruct Gen AIs to do much more complex tasks.

You'll learn about:

What is Instruction Prompting?
Why Instruction Prompting is Important
Examples of Instruction Prompting
Name Parsing
Removing Personally Identifiable Information (PII)
Essay Evaluation and Feedback
Conclusion
FAQ
1. What is Instruction Prompting?
Instruction prompting1
Efrat, A., & Levy, O. (2020). The Turking Test: Can Language Models Understand Instructions?

2
Mishra, S., Khashabi, D., Baral, C., Choi, Y., & Hajishirzi, H. (2022). Reframing Instructional Prompts to GPTk‚Äôs Language. Findings of the Association for Computational Linguistics: ACL 2022. https://doi.org/10.18653/v1/2022.findings-acl.50

 centers around the ability of generative AI models, particularly large language models (LLMs), to follow natural language instructions. Instruction prompting aims to allow models to work with new, previously unseen tasks by understanding and executing instructions expressed in natural language, without requiring task-specific training data.

For example, instead of training a model on multiple examples of extracting the fourth word from a sentence, you can simply instruct it: "Write the fourth word of the sentence."

2. Why Instruction Prompting is Important
Generative AI models rely on well-crafted instructions to understand tasks and deliver accurate results. Instruction prompting enables users to guide AI through complex tasks‚Äîlike text formatting, PII removal, and essay evaluation‚Äîwithout needing vast labeled datasets or pre-programmed rules.

This method is flexible and scalable, making it particularly useful for adapting AI to new tasks. It also helps mitigate the risks of incorrect outputs by enabling prompt iterations and adjustments.

3. Examples of Instruction Prompting
3.1 Name Parsing
One common task in data processing is formatting names correctly, especially when users input names in different orders (e.g., "John Smith" or "Smith John"). Instruction prompting allows you to automate this task effortlessly.

 Copy
Astronaut
Prompt
A user has input their first and last name into a form. We don't know in which order their first name and last name are, but we need it to be in this format '[Last name], [First name]'.

Please convert the following name in the expected format: John Smith

 Copy
Robot
AI Output
Smith, John

Try changing the name until you find one that the prompt does not properly handle. If you can do this, perhaps you will be able to improve to prompt as well! This is a fun exercise to improve your prompt engineering skills.

3.2 Removing Personally Identifiable Information (PII)
Organizations often need to redact personal information from documents. With instruction prompting, generative AI can automatically identify and replace PII, saving time and reducing manual effort 3
Allowing AI to remove PII from text is a promising approach, but it should be used with extraordinary caution as it may make mistakes.

4
It should also be noted in this example that you are sending PII to a third party (e.g. OpenAI if you are using ChatGPT), and these services may record and use your prompts for their own needs.

.

 Copy
Astronaut
Prompt
Read the following sales email. Remove any personally identifiable information (PII), and replace it with the appropriate placeholder. For example, replace the name "John Doe" with "[NAME]".

Hi John,

I'm writing to you because I noticed you recently purchased a new car. I'm a salesperson at a local dealership (Cheap Dealz), and I wanted to let you know that we have a great deal on a new car. If you're interested, please let me know.

Thanks,

Jimmy Smith

Phone: 410-805-2345 Email: jimmysmith@cheapdealz.com

Here is the AI's response5
We used a different GenAI, GPT-3, for this example.

:

 Copy
Robot
AI Output
Hi [NAME],

I'm writing to you because I noticed you recently purchased a new car. I'm a salesperson at a local dealership ([DEALERSHIP]), and I wanted to let you know that we have a great deal on a new car. If you're interested, please let me know.

Thanks,

[SALESPERSON]

Phone: [PHONE NUMBER] Email: [EMAIL ADDRESS]

It is very exciting to see how the model can extrapolate from the instructions. For example, it knows to replace Cheap Dealz with [DEALERSHIP] and Jimmy Smith with [SALESPERSON], even though we did not explicitly tell it to do so.

3.3 Essay Evaluation and Feedback
Instruction prompting can also be used to evaluate essays based on various criteria like grammar, coherence, and argument quality. The model can provide detailed feedback and scores, simulating the task of a human reviewer.

 Copy
Astronaut
Prompt
Read the following excerpt from an essay and provide feedback based on the following criteria: grammar, clarity, coherence, argument quality, and use of evidence. Provide a score from 1-10 for each attribute, along with reasoning for your score.

"Despite the popular belief, there's no solid evidence supporting the idea that video games lead to violent behavior. Research on the topic is often contradictory and inconclusive. Some studies found a correlation, but correlation doesn't imply causation. So, it's premature to blame video games for violence in society."

The AI's response:

 Copy
Robot
AI Output
Attribute: Grammar Score: 9 Reasoning: The essay is mostly grammatically correct, but there is a minor error - 'correlation doesn't imply causation' should be 'correlation doesn't imply causation'.

Attribute: Clarity Score: 8 Reasoning: The essay is generally clear, but could provide more detail or explanation about the contradictory and inconclusive nature of the research.

Attribute: Coherence Score: 8 Reasoning: The arguments are coherent and related, but the transition between them could be smoother.

Attribute: Argument Quality Score: 7 Reasoning: The argument presented is logical and well-reasoned, but it could be strengthened with a clearer statement of the writer's position on the issue.

4. Conclusion
Instruction prompting is a powerful technique that allows generative AI models to handle complex tasks by providing clear, concise directions. Through examples like name parsing, PII removal, and essay evaluation, we can see how flexible and scalable this method is. Instruction prompting will be a key tool as you continue exploring AI capabilities.

5. FAQ
Why is instruction prompting effective?
Although explicitly giving the model a specific task seems simple, LLMs are very good at following even complex instructions and applying them to user inputs.

What are some examples of instruction prompting?
Some examples shown in this doc are formatting name inputs, removing personally identifiable information from emails, and evaluating essays.

---

Assigning Roles
üü¢
This article is rated easy
Reading Time: 7 minutes
Last updated on August 7, 2024
Sander Schulhoff

role prompt


Introduction
This document dives into role prompting, a technique that allows users to assign roles to an AI model to control the style, tone, or depth of its generated text. You'll learn how role prompting is applied to various use cases, including text styling and improving accuracy in tasks like reviews, emails, and math problems.

What is Role Prompting?
Application #1: Styling Text
Example #1: Changing the Style of a Food Review
Example #2: Writing Email
Application #2: Improving Accuracy
Conclusion
FAQ
1. What is Role Prompting?
Role prompting is a technique that involves assigning a role or persona to an AI model, such as "food critic" or "mathematician," to control the style1
Shanahan, M., McDonell, K., & Reynolds, L. (2023). Role-Play with Large Language Models.

2
Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D., & Ghanem, B. (2023). CAMEL: Communicative Agents for ‚ÄúMind‚Äù Exploration of Large Scale Language Model Society.

3
Santu, S. K. K., & Feng, D. (2023). TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks.

 or accuracy of its responses.

By instructing the model to take on a specific role, you can shape how it processes and delivers information. This technique is widely used across many applications, from creative writing to problem-solving.

2. Application #1: Styling Text
Role prompting is most commonly used to alter the style of AI-generated text. By assigning a role, such as a food critic or a marketing expert, the AI can adjust its tone, language, and the depth of its responses based on the given persona.

2.1 Example #1: Changing the Style of a Food Review
To ensure your review resonates with your intended audience, consider factors like length, style, language, and tone, and use these to craft a review that speaks directly to your readers' interests and expectations. With a thoughtful approach and a focus on quality content, you can create a review that truly captures the essence of the pizza place you're writing about. Let's start with a simple prompt without a role.

Simple Review Prompt:
 Copy
Astronaut
Prompt
Write a review of [pizza place].

 Copy
Robot
AI Output
I recently had the pleasure of trying [random pizza place] and I must say that I was thoroughly impressed. The pizza was cooked to perfection and the toppings were fresh and flavorful. The crust was light and crispy, and the sauce was just the right amount of tangy. The service was also top-notch; the staff was friendly and attentive. Overall, I had a great experience and would definitely recommend [random pizza place] to anyone looking for a delicious pizza.

Let‚Äôs see how assigning the AI the role of a food critic or a Michelin Guide reviewer changes the output when writing a food review.

Role Prompt - Food Critic:
 Copy
Astronaut
Prompt
You are a food critic. Write a review of [pizza place].

 Copy
Robot
AI Output
I recently had the pleasure of dining at [Pizza Place], a cozy pizzeria located in the heart of the city. Despite its small size, the restaurant packs a huge punch when it comes to flavor.

The pizza was cooked to perfection. The crust was delightfully thin and crispy and the toppings were fresh and flavorful. The combination of flavors was simply delicious. The marinara sauce was rich and flavorful and complemented the toppings perfectly. The cheese was gooey and melted in my mouth.

The service was also excellent. The staff was friendly and attentive. They were quick to answer questions and made sure that our food was served on time.

Overall, my experience at [Pizza Place] was fantastic and I highly recommend it to anyone looking for a delicious pizza.

We can see that it adds more detail and goes a bit more in-depth. Now let's go a step further and make it assume the role of a writer for the Michelin guide:

Role Prompt - Michelin Guide Reviewer:
 Copy
Astronaut
Prompt
You are a food critic writing for the Michelin Guide. Write a review of [pizza place].

 Copy
Robot
AI Output
Located in the heart of [random city], [random pizza place] is a popular spot for pizza lovers. Upon entering, the warm, inviting atmosphere and the smell of freshly baked pizza will make you feel right at home. The menu offers a wide selection of classic pizzas, as well as some unique and creative options. The crust is perfectly crispy and the toppings are always fresh and flavorful. The service is friendly and attentive, and the prices are reasonable. Whether you‚Äôre looking for a quick bite or a leisurely dinner, [random pizza place] is sure to satisfy your pizza cravings.

Now we can see how assigning ChatGPT the role of a food critic makes the review seem more "rich" and "professional" in its description.

You can try it for yourself here:


2.2 Example #2: Writing Email
Let's consider another example of styling text with role prompting. Let's say you ask the AI to write an email to a client to inform them about a delay in the delivery schedule due to logistical issues. Your goal is to effectively convey this update while ensuring the client's confidence in your services remains unwavering.

When drafting emails, role prompting can significantly change the tone of the message depending on the role assigned to the AI.

Communications Specialist:
For instance, one possible role is that of a communications specialist, whose style might be clear, professional, and to the point:

 Copy
Astronaut
Prompt
You are a communications specialist. Draft an email to your client advising them about a delay in the delivery schedule due to logistical problems.

 Copy
Robot
AI Output
Subject: Important Update Regarding Your Order

Dear [Client's Name],

I hope this email finds you well. I'm reaching out to notify you of a delay in the delivery of your order. Unfortunately, we have encountered a logistical problem which is causing a short hold up. While we are making every effort to resolve this issue quickly, we anticipate your order to be delivered within [new estimated delivery date].

We deeply apologize for any inconvenience caused, and we'd like to reassure you we are doing our best to speed up the process. Your patience is greatly appreciated. If you have any questions or concerns, please don't hesitate to contact us.

Thank you very much for your understanding.

Best Regards, [Your Name]

Marketing Expert:
Alternatively, have the model adopt the role of a marketing expert to lean more on persuasion, positivity, and relationship building:

 Copy
Astronaut
Prompt
You are a marketing expert. Draft an email to a client advising them about a delay in the delivery schedule due to logistical problems.

 Copy
Robot
AI Output
Subject: A Little More Wait for Your Wonderful Products

Dear [Client's Name],

We hope this message finds you buzzing with excitement for your upcoming order! However, even the best-laid plans sometimes face unexpected hiccups. We have hit a temporary logistics snag that will unfortunately add a small wait time to your delivery.

While we understand this isn't ideal, we believe great things come to those who wait, and your order is no exception. Rest assured, from the moment we sort out this situation to the time your products reach you, we're committed to ensuring that your experience is nothing short of excellent.

Thank you for your patience and understanding. Stay tuned for more updates, and please, don't hesitate to reach out if you have any questions - we're always here.

Cheers, [Your Name]

Customer Service Representative:
Lastly, the role of a customer service representative might lead to a more relational and solution-oriented output:

 Copy
Astronaut
Prompt
You are a customer service representative. Draft an email to a client advising them about a delay in the delivery schedule due to logistical problems.

 Copy
Robot
AI Output
Subject: Attention Required: Update on Your Order Status

Dear [Client's Name],

Greetings from [Your Company Name].

We wanted to inform you that, due to unforeseen logistical challenges, there might be a delay in the delivery of your order. We understand that this may cause some inconvenience, and we apologize sincerely.

Meanwhile, we are working tirelessly to resolve this and ensure your delivery reaches you by [new estimated date]. We value your time and patience greatly.

Please feel free to reach out if you have any questions or need further information. Our team is always here to assist you.

Thank you for your understanding.

Best regards, [Your Name]

Each of these role prompts will yield different results, aligning more closely with the perspective of the assigned role. Whether you need the directness of a communications specialist, the persuasive positivity of a marketing expert, or the empathetic problem-solving approach of a customer service representative, role prompts allow you to tailor the language model to better fit your needs.

Application #2: Improving Accuracy
Role prompting can also improve the accuracy of AI outputs 4
This appears to be less effective with newer models. Read Revisiting Roles for more information.

, especially in mathematical problem-solving.

Consider this example:

 Copy
Astronaut
Prompt
You are a brilliant mathematician who can solve any problem in the world. Attempt to solve the following problem:

What is 100*100/400*56?

 Copy
Robot
AI Output
The answer is 1400.

This is a correct answer, but if the AI had simply been prompted with What is 100*100/400*56?, it would have answered 280 (incorrect).

Try it here:


4. Conclusion
Role prompting is a versatile prompting technique for shaping the output of generative AI models. By assigning specific roles to the AI, users can control the style, tone, and even the accuracy of the responses, making it highly effective for tasks like writing, problem-solving, and more. As you explore the capabilities of AI, role prompting will continue to play a crucial role in improving the quality of outputs.

5. FAQ
Why should I use role prompting?
Role prompting is an effective method of getting the AI model to respond in a specific style and is commonly used in system instructions.

What are some examples of role prompting?
Some examples of role prompting are assigning the role of a food critic to write a better review, the role of a marketing expert to improve email writing, and the role of a brilliant mathematician to get a more accurate response to an arithmetic problem.


---

Shot-Based Prompting
üü¢
This article is rated easy
Reading Time: 12 minutes
Last updated on October 21, 2024
Sander Schulhoff

Few-Shot


Introduction
In this thorough guide, we explore the concepts of zero-shot, one-shot, and few-shot prompting techniques. We show what it means to provide your AI with examples or demonstrations and how it can improve the accuracy of the results.

We also compare zero-shot, one-shot, and few-shot prompting techniques, showing real-world applications and best practices for using each method effectively.

Introduction
What are Examples in Prompts?
What is Shot-Based Prompting?
What is Zero-Shot Prompting?
What is One-Shot Prompting?
What is Few-Shot Prompting?
How to Choose the Right Prompting Technique
Deep Dive into Few-Shot Prompting
Conclusion
FAQ
What are Examples in Prompts?
When giving AI models instructions, we can improve their performance by providing examples. This technique is called In-Context Learning (ICL). It allows models to learn from examples embedded directly in the prompt, rather than needing additional training or fine-tuning. By including examples, we guide the AI to better understand the task and expected output, leveraging its pattern recognition abilities.

In-Context Learning is especially useful for tasks where instructions alone may not be enough, or when a certain structure or style is required in the output. Showing examples within the prompt helps the model apply patterns it has learned to similar, unseen inputs.

What is Shot-Based Prompting?
In-Context Learning is closely tied to the concept of shot-based prompting methods, where "shots" refer to the number of examples included in the prompt.

Few-shot prompting is a direct application of ICL, where multiple examples (or "shots") are provided to guide the model‚Äôs output. The more examples (or shots) we give, the better the model typically performs, as it can learn from these examples and generalize them to new, similar tasks.

Here's a breakdown of the common shot-based methods:

Zero-Shot Prompting: No examples are provided, and the model must rely entirely on its pre-trained knowledge.
One-Shot Prompting: A single example is given to clarify the task for the model.
Few-Shot Prompting: Two or more examples are included, allowing the model to recognize patterns and deliver more accurate responses.
Each of these techniques has strengths depending on the task, and the examples provided help the model learn in context, improving accuracy and output quality.

What is Zero-Shot Prompting?
Zero-shot prompting is the simplest form of prompting. Here, we give the model a direct instruction to perform a task without providing any examples or demonstrations. This means the model has to rely entirely on its pre-trained knowledge to figure out how to complete the task. As such, all of the instruction and role prompts that you have seen so far are zero-shot prompts.

Example of Zero-Shot Prompting
An additional example of a zero-shot prompt is:

 Copy
Astronaut
Zero-Shot Prompt
Classify the sentiment of the following text as positive, negative, or neutral.
Text: I think the vacation was okay.
Sentiment:

The model will provide a classification based solely on the task description, without seeing any examples beforehand. The output might be:

 Copy
Robot
AI Output
Neutral

While zero-shot prompting can work well for simple tasks‚Äîespecially ones that the model has likely encountered during training‚Äîit's often not enough for more complex tasks. The lack of examples leaves the model guessing, and the results can be unpredictable or incorrect.

What is One-shot Prompting?
One-shot prompting enhances zero-shot prompting by providing a single example before the new task, which helps clarify expectations and improves model performance.

Example of One-Shot Prompting
Consider the one-shot prompt version of the same sentiment classification task:

 Copy
Astronaut
One-Shot Prompt
Classify the sentiment of the following text as positive, negative, or neutral.
Text: The product is terrible.
Sentiment: Negative

Text: I think the vacation was okay. Sentiment:

Here, the model is shown a single example ("The product is terrible. Sentiment: Negative") before it processes the new input. This allows the model to better understand what it should do next. The output might now be more reliable:

 Copy
Robot
AI Output
Neutral

One-shot prompting gives the model a starting point, but with only one example, it might still struggle with nuanced or complex tasks. More examples are often needed to fully capture the range of possible outputs.

What is Few-Shot Prompting?
Few-shot prompting provides two or more examples, which helps the model recognize patterns and handle more complex tasks. With more examples, the model gains a better understanding of the task, leading to improved accuracy and consistency.

Example of Few-Shot Prompting
Now let's see an example of Few-Shot Prompting. Below is a prompt that is attempting to classify customer feedback as positive or negative. The first three lines are examples feedback and its classification. The fouth line is new piece of feedback that has not been classified yet (It doesn't work!:). This line is called the test instance, because it is the part of the prompt that we want to LLM to analyze.

For example, a few-shot version of our sentiment classification prompt could look like this:

 Copy
Astronaut
Few-Shot Prompt
Classify the sentiment of the following text as positive, negative, or neutral.

Text: The product is terrible. Sentiment: Negative

Text: Super helpful, worth it Sentiment: Positive

Text: It doesnt work! Sentiment:

Here is the output of this prompt when passed through GPT-4. In this case, the model has two examples to learn from, making it more likely to generate an accurate response for the new input:

 Copy
Robot
AI Output
Negative

Few-shot prompting helps the model generalize from multiple examples, making it more reliable for tasks that require adherence to specific formats or patterns, such as structured information extraction or content generation

How to Choose the Right Prompting Technique
Selecting the appropriate prompting technique ‚Äî zero-shot, one-shot, or few-shot ‚Äî depends on the complexity of the task and the level of guidance the model requires.

Here‚Äôs a quick summary of when to use each method:

Zero-shot prompting: Use this when the task is simple, well-understood, or frequently encountered in the model‚Äôs training data. It‚Äôs efficient for tasks like basic arithmetic, general queries, or sentiment classification for common phrases.

One-shot prompting: This is helpful for tasks that need more specific guidance or when the model struggles with ambiguity. Providing a single example can clarify the task, improving accuracy in tasks like basic classification or structured information extraction.

Few-shot prompting: Best used for complex tasks requiring multiple examples to establish patterns. This technique is ideal for tasks that involve varied inputs, require precise formatting, or demand a higher degree of accuracy, such as generating structured outputs or handling nuanced classifications.

Deep Dive into Few-Shot Prompting
Real-World Applications of Few-Shot Prompting
Few-shot prompting is versatile and can be applied to various domains, such as:

Sentiment analysis and topic categorization1
Gao, T., Fisch, A., & Chen, D. (2021). Making Pre-trained Language Models Better Few-shot Learners. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, 3816‚Äì3830.

Information extraction
Creative content generation
Named entity recognition2
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., & others. (2020). Language Models are Few-Shot Learners. Advances in Neural Information Processing Systems, 33, 1877‚Äì1901.

Machine translation3
Garcia, X., Constant, N., Parikh, A., & Firat, O. (2021). Few-shot learning for cross-lingual natural language inference. arXiv Preprint arXiv:2104.14690.

Code generation4
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., & others. (2021). Evaluating Large Language Models Trained on Code. arXiv Preprint arXiv:2107.03374.

Question answering systems5
Schick, T., & Sch√ºtze, H. (2021). Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference. Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, 255‚Äì269.

Conversational scenarios6
Madotto, A., Lin, Z., Zhou, Y., Shin, J., & Fung, P. (2021). Few-shot Bot: Prompt-based Learning for Dialogue Systems. arXiv Preprint arXiv:2110.08118.

and more
Here are the example prompts for two applications: information extraction and creative content generation. We also provide the guidance about using few-shot prompting to receive outputs structured in a desired way.

Few-Shot Prompting for Information Extraction
You can also use Few-Shot Prompting to extract key details from job postings in a structured bulleted list format. Here is a prompt that extracts the key details from a job posting as a bulleted list.

 Copy
Astronaut
Prompt
INPUT: Software Engineer - Python specialist needed at TechCorp. 5+ years experience required. Salary range $90,000 - $120,000. Remote work available. Apply by June 30, 2024. OUTPUT: Position: Software Engineer Specialization: Python Company: TechCorp Experience Required: 5+ years Salary Range: $90,000 - $120,000 Work Type: Remote Application Deadline: June 30, 2024

INPUT: Marketing Manager for GlobalBrand. MBA preferred. 3-5 years in consumer goods marketing. $75K-$95K DOE. Hybrid work model. Applications close July 15, 2024. OUTPUT: Position: Marketing Manager Company: GlobalBrand Education: MBA preferred Experience Required: 3-5 years Industry: Consumer goods Salary Range: $75,000 - $95,000 Work Type: Hybrid Application Deadline: July 15, 2024

INPUT: Data Scientist wanted at AI Innovations Ltd. PhD in Computer Science or related field. Minimum 2 years industry experience. Competitive salary ‚Ç¨60,000 - ‚Ç¨80,000 based on experience. On-site work in Berlin office. Apply by August 31, 2024. OUTPUT:

Here's the potential output. Notice how we used the INPUT, OUTPUT format instead of the colon (:) format. We will address the signifigance of this later.

 Copy
Robot
AI Output
Position: Data Scientist Company: AI Innovations Ltd Education: PhD in Computer Science or related field Experience Required: Minimum 2 years Salary Range: ‚Ç¨60,000 - ‚Ç¨80,000 Work Type: On-site Location: Berlin Application Deadline: August 31, 2024

This example demonstrates how few-shot prompting can be used to extract structured information from unstructured text and present it in a different format. The model learns from the provided examples to identify relevant information and maintain the specified list structure, adapting to the new output format while still capturing the key details from the job posting.

Few-Shot Prompting for Content Creation
This example demonstrates how to use few-shot prompting to create concise travel itinerary descriptions for different types of vacations.

 Copy
Astronaut
Prompt
Destination: Tokyo, Japan Trip Type: Cultural Exploration Itinerary: A 5-day immersion in Tokyo's blend of tradition and modernity. Visit ancient temples like Senso-ji, then explore futuristic districts like Akihabara. Experience a tea ceremony, try hands-on workshops in traditional crafts, and end with a day trip to Mt. Fuji for breathtaking views of Japan's iconic landmark.

Destination: Costa Rica Trip Type: Eco-Adventure Itinerary: 7 days of natural wonders and adrenaline rushes. Start in the Arenal Volcano area for hiking and zip-lining, then head to Monteverde Cloud Forest for canopy walks and wildlife spotting. Finish at Manuel Antonio National Park, combining rainforest exploration with relaxation on pristine beaches.

Destination: Rome, Italy Trip Type: Culinary Journey Itinerary: A 6-day feast for the senses in the Eternal City. Begin with a pasta-making class, followed by guided food tours through trendy Trastevere and historic Jewish Ghetto. Visit local markets, enjoy wine tasting in the Roman countryside, and cap off the trip with a Michelin-starred dining experience.

Destination: New Zealand Trip Type: Lord of the Rings Fan Tour Itinerary:

Here's a potential output. Notice how we had two "inputs", the destination and the trip type. Few-Shot prompting can be very versatile!

 Copy
Robot
AI Output
An 8-day journey through Middle-earth's real-life locations. Start in Auckland with a visit to Hobbiton Movie Set in nearby Matamata. Fly to Wellington to explore Weta Workshop and tour urban filming locations. Head to the South Island to see the majestic landscapes of Edoras in Mount Sunday and Pelennor Fields in Twizel. End your adventure in Queenstown, taking in the scenery of Isengard and Lothlorien in Glenorchy, with an optional helicopter tour over the Misty Mountains (Southern Alps). Throughout the trip, enjoy themed accommodations and meals inspired by hobbit cuisine.

This example shows how few-shot prompting can be used to generate creative content tailored to specific parameters (in this case, destination and trip type). The model learns from the provided examples to create a new itinerary description that matches the style and format of the examples while incorporating relevant details for the given input. This technique can be applied to various types of content generation where consistency in structure and adaptation to specific inputs are required.

Few-Shot Prompting for Structured Outputs
Structuring outputs is perhaps the most important benefit of few-shot prompting. If you need to copy-and-paste the AIs output into a spreadsheet or use code to extract part of its output, you need to understand how to take advantage of Few-Shot Prompting's ability to structure outputs. When we say discuss structured outputs, we are basically referring to the format that the output is in. Is it just a paragraph of text, or is it a bulleted list, or is it something else like a markdown block of code or a JSON or YAML file?

Consider the following prompt and output:

 Copy
Astronaut
Prompt
Great product, 10/10: positive Didn't work very well: negative Super helpful, worth it: positive It doesnt work!:

 Copy
Robot
AI Output
negative

Given that we have organized these three instances in an input: classification format, the model generates a single word following the final line, rather than outputting a complete sentence such as this review is positive. However, if we wanted a complete sentence to be output, we could adjust our examples as:

 Copy
Astronaut
Prompt
"Great product, 10/10": this is a positive classification "Didn't work very well": this is a negative classification "Super helpful, worth it": this is a positive classification

We could also make outputs in JSON format by structuring the examples as follows:

 Copy
Astronaut
Prompt
"Great product, 10/10": {"label": "positive"} "Didn't work very well": {"label": "negative"} "Super helpful, worth it": {"label": "positive"}


More on structure
A key use case for Few-Shot prompting is when you need the output to be structured in a specific way that is difficult to describe to the model. To understand this, let's consider a relevant example: say you are conducting an economic analysis and need to compile the names and occupations of well-known citizens in towns nearby by analyzing local newspaper articles. You would like the model to read each article and output a list of names and occupations in the First Last [OCCUPATION] format. In order to get the model to do this, you can show a few examples. Look through the embed to see them.


By showing the model examples of the correct output format, it is able to produce the correct output for new articles. We could produce this same output by using an instruction prompt instead, but the Few-Shot prompt works much more consistently.

Best Practices for Few-Shot Prompting
When designing few-shot prompts, consider:

The number of examples to include
The order and relevance of the examples
The output format (e.g., list, JSON, YAML)
How to Structure Few-Shot Prompts?
The way that we structure Few-Shot Prompts is very important. By this, we mean do we separate the inputs and outputs with a colon (:) or the words INPUT/OUTPUT. We have seen examples of both earlier in this article. How can you decide? We generally use the input: output format and occassionally use the QA format, which is commonly used in research papers.

 Copy
Astronaut
Prompt
Q: input A: output

For longer inputs and outputs, we will use the INPUT/OUTPUT format. This allows for greater legibility of the prompt.

 Copy
Astronaut
Prompt
INPUT: input OUTPUT: output

Tip
When it comes to how to format your prompt, start simple. You will likely have to come up with your own formats eventually. If you are interested in learning more about optimizing your Few-Shot Prompts, check out our Advanced Prompt Engineering course.

Limitations of Few-Shot Prompting
While few-shot prompting is highly effective, it has limitations:

Context window constraints limit the number of examples.
Overgeneralization may occur if examples are too similar.
The model might focus on superficial patterns rather than understanding the task.
Conclusion
Few-shot prompting is a versatile and powerful technique for enhancing AI capabilities. By providing examples, you can guide the model to generate accurate, structured outputs. However, it‚Äôs important to consider limitations such as context window size and example selection to maximize effectiveness.

FAQ
Why is Few-Shot prompting a useful prompting technique?
Showing exemplars in your model input is an effective way of implying the desired structure of the AI response.

What is the difference between Zero-Shot, One-Shot, and Few-Shot prompting? Which is best?
Zero-Shot, One-Shot, and Few-Shot prompting refers to the number of examples that you provide in the model input (zero, one, and few, respectively). Usually, Few-Shot prompting is preferred because it is better to show more examples.

How many examples should I include in a Few-Shot prompt?
The optimal number of examples can vary depending on the task complexity and model capabilities. Generally, 2-5 examples are sufficient for simple tasks. However, it's important to experiment and find the right balance, as too many examples can lead to overfitting or exceed the model's context window. We include often 10 examples for harder tasks, but some researchers include 100 or 100s of examples!

---

Parts of a Prompt: Understanding the Key Elements
üü¢
This article is rated easy
Reading Time: 8 minutes
Last updated on October 24, 2024
Valeriia Kuka

formal prompt


Introduction
In the rapidly evolving field of Generative AI, crafting effective prompts is essential to achieving high-quality outputs. A prompt is the input provided to an AI model, and its structure determines the accuracy, relevance, and format of the response. Whether you're using AI to write content, generate data, or create images, understanding the parts of a prompt can help you guide the model toward producing better results.

In the previous docs, we discussed instruction prompting, role prompting, and shot-based prompting. In this document, we conclude this discussion by summarizing the main parts of the prompt.

We break down the essential parts of a prompt, providing examples and tips on how to use each element effectively:

Introduction
Key Parts of a Prompt
The Directive
Examples
Role (Persona)
Output Formatting
Additional Information
How to Order Parts of the Prompt
Conclusion
FAQ
Key Parts of a Prompt
Prompts are made up of several key components that work together to guide the AI. While not every prompt will contain all these elements, understanding how each part functions can help you create more targeted and effective inputs.

The key parts of a prompt are:

The Directive
Examples
Role (Persona)
Output Formatting
Additional Information
1. The Directive
The Directive is the main instruction in the prompt1
Schulhoff, S., Ilie, M., Balepur, N., Kahadze, K., Liu, A., Si, C., Li, Y., Gupta, A., Han, H., Schulhoff, S., & others. (2024). The Prompt Report: A Systematic Survey of Prompting Techniques. arXiv Preprint arXiv:2406.06608.

2
Searle, J. R. (1969). Speech acts: An essay in the philosophy of language. Cambridge University.

. It tells the AI exactly what task it should perform. Without a clear directive, the AI may provide a generic or irrelevant response.

What is a Directive?
A directive is a concise instruction or question that gives the AI a clear task to perform. It can range from a request to generate text, solve a problem, or format information in a specific way.

For example, here a prompt with a single instruction:

 Copy
Astronaut
Prompt
Tell me five good books to read.

Implicit Directives
In some cases, the directive may be implied rather than explicitly stated. These types of prompts still guide the AI but rely on context or formatting to convey the task.

 Copy
Astronaut
Prompt
Night: Noche Morning:

Best Practices for Directives:

Be clear and concise.
Avoid ambiguous or vague instructions.
When possible, use action verbs to indicate the specific task (e.g., ‚Äúwrite,‚Äù ‚Äúlist,‚Äù ‚Äútranslate‚Äù).
2. Examples
When the task is more complex, providing Examples can help guide the AI in producing more accurate responses. This technique is especially useful in few-shot and one-shot prompting, where a model is given one or more examples of what you expect in the output.

Why Use Examples?
Examples demonstrate the expected format, style, or structure of the output. By including them in the prompt, you can guide the AI‚Äôs behavior and help it better understand the desired result.

 Copy
Astronaut
Prompt
Translate the following sentences:

Q: I like apples. A: Me gustan las manzanas.

Q: I enjoy walking.

In this example, the AI is shown how to structure the translation, and it will follow the same pattern for the remaining sentences.

Best Practices for Examples:
Provide clear and relevant examples that match the task.
Use examples to demonstrate the structure or content you expect.
Adjust the number of examples based on task complexity (one-shot or few-shot).
3. Role (Persona)
Assigning a Role to the AI, also known as a persona, helps frame the response in a specific way. By telling the AI to act as an expert, a professional, or a specific character, you can guide the tone, style, and content of the response.

What is a Role?
The role element in a prompt assigns a specific persona or perspective to the AI, encouraging it to tailor its response according to the designated role. This can greatly enhance the accuracy and relevance of the response, especially for tasks requiring domain-specific knowledge or a particular tone.

Here, the AI is instructed to respond as if it were a medical professional:

 Copy
Astronaut
Prompt
You are a doctor. Based on the following symptoms, diagnose the patient.

The AI will assume the role of a customer service agent, ensuring the tone is appropriate for business communication:

 Copy
Astronaut
Prompt
You are a customer service agent. Write an email apologizing for a delayed order.

Best Practices for Using Roles:
Use roles to add expertise or a specific perspective to the response.
Ensure the role fits the task at hand (e.g., using a marketing expert to write promotional content).
Combine the role with additional context for better results.
4. Output Formatting
Sometimes, it‚Äôs important to specify the format in which you want the AI to present its output. Output Formatting ensures that the response follows a particular structure‚Äîwhether it‚Äôs a list, a table, or a paragraph. Specifying the format can help prevent misunderstandings and reduce the need for additional post-processing.

Why Output Formatting Matters
Without clear formatting instructions, the AI may provide a response that is technically correct but not in the desired format. Specifying the structure makes the output easier to use.

It is often desirable for the GenAI to output information in certain formats, for example, CSVs or markdown formats3
Xia, C., Xing, C., Du, J., Yang, X., Feng, Y., Xu, R., Yin, W., & Xiong, C. (2024). FOFO: A Benchmark to Evaluate LLMs‚Äô Format-Following Capability. In L.-W. Ku, A. Martins, & V. Srikumar (Eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 680‚Äì699). Association for Computational Linguistics. https://doi.org/10.18653/v1/2024.acl-long.40

. To facilitate this, you can simply add instructions to do so as seen below:

 Copy
Astronaut
Prompt
Case: 2024_ABC_International Client: XYZ Corporation Jurisdiction: EU & USA Filed Date: 2024-09-01 Status: Active Lead Attorney: John Doe Next Hearing: 2024-10-15

Output this information as a CSV.

 Copy
Robot
AI Output
Case,Client,Jurisdiction,Filed Date,Status,Lead Attorney,Next Hearing 2024_ABC_International,XYZ Corporation,EU & USA,2024-09-01,Active,John Doe,2024-10-15

Style Instructions
You can also specify stylistic preferences, such as tone or length, within the output formatting. This allows you to control not just the content but how it‚Äôs presented.

For example:

 Copy
Astronaut
Prompt
Write a clear and curt paragraph about llamas.

5. Additional Information
Additional Information, sometimes referred to as context, though we discourage the use of this term as it is overloaded with other meanings in the prompting space[^b]. It provides the background details the AI needs to generate a relevant response. Including this information ensures that the AI has a comprehensive understanding of the task and the necessary data to complete it.

What is Additional Information?
Additional information can include relevant facts, data, or other background information that helps the AI generate a more accurate and contextually appropriate response. This element is especially important for complex tasks that require specific knowledge.

 Copy
Astronaut
Prompt
January 1, 2000: Fractured right arm playing basketball. Treated with a cast.

February 15, 2010: Diagnosed with hypertension.

You are a doctor. Predict the patient‚Äôs future health risks based on this history.

In this example, the patient‚Äôs medical history is crucial to generating a valid prediction.

Best Practices for Additional Information:
Include only relevant information‚Äîavoid overloading the prompt with unnecessary details.
Ensure the information is clearly linked to the task.
Use this element to provide essential background that the AI might not otherwise have.
How to Order Parts of the Prompt
There is no single ‚Äúcorrect‚Äù order for arranging the elements of a prompt, but there are guidelines that can help improve clarity and prevent misunderstandings. In general, starting with examples or context and ending with the directive ensures the AI focuses on the task after processing the relevant information.

Now that you understand the different parts of a prompt, you may wonder if there is a common order in which you should arrange them. You should first note that not all of these occur in every prompt, and when they do there is no standard order for them. However, we do have a suggested order. To understand our order, first consider the following two prompts, which each contain a role, an instruction (the directive), and additional information.

 Copy
Astronaut
Prompt
You are a doctor. Read this medical history and predict risks for the patient.

January 1, 2000: Fractured right arm playing basketball. Treated with a cast. February 15, 2010: Diagnosed with hypertension. Prescribed lisinopril. September 10, 2015: Developed pneumonia. Treated with antibiotics and recovered fully. March 1, 2022: Sustained a concussion in a car accident. Admitted to the hospital and monitored for 24 hours.

 Copy
Astronaut
Prompt
January 1, 2000: Fractured right arm playing basketball. Treated with a cast. February 15, 2010: Diagnosed with hypertension. Prescribed lisinopril. September 10, 2015: Developed pneumonia. Treated with antibiotics and recovered fully. March 1, 2022: Sustained a concussion in a car accident. Admitted to the hospital and monitored for 24 hours.

You are a doctor. Read this medical history and predict risks for the patient.

Although usually both prompts would give approximately the same output, we prefer the second prompt, since the instruction is the last part of the prompt. This is preferable, since with the first prompt, the large language model (LLM) might just start writing more context instead of following the instruction; if given the first prompt, the LLM might add a new line:

March 15, 2022: Follow-up appointment scheduled with neurologist to assess concussion recovery progress.

This is due to the fact that LLMs are trained to predict the next token (similar to word) in a paragraph.

Recommended Order for Prompts:

Examples (if needed)
Additional Information
Role
Directive
Output Formatting
In this prompt, the role and task come after the context, ensuring the AI processes the timeline before generating the output.

Why Order Matters
The order of the elements affects how the AI processes the information. For instance, placing the directive last helps avoid the AI continuing the additional information instead of focusing on the task at hand.

Conclusion
Crafting effective prompts requires an understanding of the key elements that guide AI responses. By mastering the use of Directives, Examples, Roles, Output Formatting, and Additional Information, you can improve the accuracy and relevance of the outputs generated by AI models. Experimenting with different combinations of these elements will allow you to tailor prompts for a wide range of tasks and achieve better results.

FAQ
Why is it important to formalize the language we use to discuss prompting?
Formalizing prompt language can help you, as a developer, to both create more effective prompts with the key components and better engage in prompt engineering discourse.

What are the key parts of a prompt?
Some key parts of a prompt discussed in this article are The Directive, Examples, A Role, Output Formatting, and Additional Information

How do you order the parts of a prompt?
You should put the examples first, then additional information, then the role, directive, and output formatting.

How does output formatting improve AI responses?
Output formatting ensures that the AI delivers the response in the desired structure, whether it‚Äôs a table, list, or paragraph, reducing the need for post-processing.

Can prompts work without examples?
Yes, many prompts don‚Äôt need examples, especially for simpler tasks. However, including examples can guide the AI more effectively for complex requests.

---

 How to Create Effective Prompts: Essential Tips and Best Practices
üü¢
This article is rated easy
Reading Time: 5 minutes
Last updated on October 24, 2024
Valeriia Kuka

Last updated on October 24, 2024 by Valeriia Kuka
Introduction
In the previous document, we introduced the concept of Prompt Engineering and provided you with some examples how it works. Now, you're probably wondering: why do these examples work, and how can you start improving your AI outputs?

This guide covers easy, actionable tips that will quickly boost the quality of your AI's responses‚Äîwhether you're using it for writing, coding, or image generation:

Start with clear and specific prompts
Experiment with prompt variations
Add context for better results
Iteration and refinement
Leverage prompting techniques
Conclusion: practice, refine, and iterate
FAQ
Tip
If you want to dive deeper into creating high-quality prompts, learn how to effectively communicate with AI.

1. Start with Clear and Specific Prompts
Effective prompts start with being clear and specific. Generative AI only responds to the instructions you provide, so the clearer you are, the better the result.

Be Direct
Vague prompts lead to vague answers. Make sure your prompt directly addresses what you need.

 Copy
Astronaut
Vague Prompt
Write something about climate change.

The response may be too general or not specific to your needs.

 Copy
Astronaut
Clear Prompt
Write a 100-word summary of the impact of climate change on coastal cities, focusing on rising sea levels.

This is focused and guides the AI to a specific answer.

Best Practices:
Use plain, concise language: Avoid unnecessary jargon or complex sentence structures unless needed.
Avoid ambiguity: Make your request clear by stating exactly what you want.
2. Experiment with Prompt Variations
How you phrase your prompt can change the outcome. Experimenting with different variations helps you find the best approach.

Test Different Formats
The format of your prompt matters. You can present it as a question, a command, or an open-ended statement. Each will guide the model differently.

Example of a completion prompt:
 Copy
Astronaut
Completion Prompt
The sky is

 Copy
Robot
AI Output
blue.

Example of an instruction prompt:
 Copy
Astronaut
Instruction Prompt
Complete the sentence: The sky is

 Copy
Robot
AI Output
blue during the day and dark at night.

Example of a question prompt:
 Copy
Astronaut
Question Prompt
What color is the sky during the day?

 Copy
Robot
AI Output
The sky is blue during the day.

Refinement through Iteration
One of the core techniques in prompt engineering is iteration. Start with a simple prompt and refine it based on the results. Add clarity or context with each iteration.

Example of an iterative refinement:
 Copy
Astronaut
Initial Prompt
Summarize this article.

 Copy
Astronaut
Refined Prompt
Summarize this article in 3 sentences, focusing on the key challenges discussed.

Tip
Always review the AI‚Äôs response and tweak your prompt if the output isn‚Äôt quite what you want. Don‚Äôt hesitate to keep refining.

3. Add Context for Better Results
AI models perform better when they have more information about the task. By adding context, you can help the model understand what you want, making its responses more accurate and relevant.

Why Context is Key
Without sufficient context, the AI may make incorrect assumptions or provide incomplete responses. Adding background details, instructions, or guidelines allows the AI to generate a more tailored response.

Example without context:
 Copy
Astronaut
Prompt without Context
Write a product description.

 Copy
Robot
AI Output
This is a product.

Example with context:
 Copy
Astronaut
Prompt with Context
Write a 50-word product description for wireless earbuds, focusing on sound quality and comfort for athletes.

 Copy
Robot
AI Output
Experience superior sound with our wireless earbuds, designed for athletes. Enjoy powerful bass and a secure, comfortable fit during your toughest workouts.

Use Instruction + Context Format
One effective way to improve results is to combine specific instructions with context. This is especially useful in tasks like summarization or when asking the AI to perform complex tasks.

 Copy
Astronaut
Prompt with Context
Summarize this email in one sentence.

Dear team, thank you for organizing the community event. It was a great success thanks to your hard work.

 Copy
Robot
AI Output
The email thanks the team for their effort in organizing a successful community event.

Note
Giving instructions to generative AI model is among the first basic techniques you'll learn about in this basics guide. Read the next several docs to find it.

4. Iteration and Refinement
Prompt engineering is an iterative process. After receiving a response, you might need to adjust your prompt to get closer to the result you‚Äôre looking for.

The Iterative Process
Refining prompts is key to getting high-quality outputs. With each iteration, add or remove details to improve the response.

 Copy
Astronaut
Initial Prompt
Summarize this book.

 Copy
Astronaut
Refined Prompt
Summarize the book‚Äôs key themes in 2-3 sentences, focusing on the author‚Äôs viewpoint on personal growth.

Layering Instructions
You can achieve better outputs by adding layers of instructions that guide the AI‚Äôs behavior. The more specific your layers, the more tailored the result will be.

 Copy
Astronaut
Prompt
Generate a product description for wireless earbuds. Use a formal tone. List 3 features and include a call-to-action.

5. Leverage Prompting Techniques
In the following docs, you'll learn about the important elements of a prompt and your first prompting techniques like:

Instruction prompting
Role prompting
Zero-shot and few-shot prompting to show demonstrations to the AI model and the difference between the two
As you become more comfortable with basic prompts, you can start experimenting with advanced prompting techniques to achieve even better results.

You will also learn about combining prompting techniques when dealing with more complex tasks.

6. Conclusion: Practice, Refine, and Iterate
Key Takeaways:

Start with clear and specific prompts.
Experiment with prompt variations and refine as needed.
Use advanced techniques like few-shot prompting and chain-of-thought for more complex tasks.
Add context for better results and iterate based on the AI‚Äôs output.
The more you practice and refine your prompts, the better your results will become. Start experimenting with the tips and techniques discussed in this guide, and see how your AI-generated outputs improve! Use our free video course, ChatGPT for Everyone, to learn more about tactics to write effective prompts and ChatGPT use cases.

7. FAQ
Why should I provide context in prompts?
Context helps the AI understand the task better, leading to more accurate and relevant outputs.

How can I improve my prompt engineering skills?
Experimentation is key. Try different prompt formats, add context, and refine your inputs based on feedback. The more you practice, the more effective your prompts will become.

---

Combining Prompting Techniques
üü¢
This article is rated easy
Reading Time: 4 minutes
Last updated on October 24, 2024
Valeriia Kuka

combined prompt


Introduction
In the world of Generative AI, prompts can vary in complexity and format, involving context, instructions, and examples. Until now, we‚Äôve explored these prompting techniques separately, but combining them can significantly improve the performance of AI models.

This document will show you how to combine different techniques to create more powerful and effective prompts, enhancing the model's ability to handle complex tasks:

Why Combine Prompting Techniques?
When to Combine Techniques?
Combining Role and Instruction Prompting
Combining Context, Instruction, and Few-Shot Prompting
Best Practices for Combining Techniques
Conclusion
FAQ
What is Combining Techniques?
As we have seen in the previous lessons, prompts can have varying formats and complexity. They can include context, instructions, and multiple input-output examples. However, thus far, we have only examined separate classes of prompts. Combining prompting techniques can lead to more powerful prompts.

Prompts can vary in complexity and format, including context, instructions, and multiple input-output examples. So far, we've examined these prompting methods separately. In the previous doc, we introduced you to the key elements of a prompt. So now you know you can combine multiple prompting techniques in oune prompt.

Combining multiple prompting techniques can lead to more powerful and effective prompts, allowing for more nuanced AI responses.

Why Combine Prompting Techniques?
Combining prompting techniques provides several benefits:

Improved understanding of complex tasks: By using multiple techniques, the AI can process the task more effectively.
Nuanced outputs: Combining roles, instructions, and examples helps the model generate responses that align with specific needs.
Increased accuracy: For intricate tasks, layering context and examples helps the AI recognize patterns, improving reliability.
When to Combine Techniques?
Certain tasks benefit from specific combinations of techniques. Here are two key combinations and when they are most effective:

Role + Instruction Prompting: Useful when the AI needs to adopt a specific persona or professional tone, such as simulating a doctor, lawyer, or historian.
Context + Instruction + Few-Shot Prompting: Best for tasks where examples and context guide the model‚Äôs understanding, such as creative content generation or data classification.
Combining Role and Instruction Prompting
Role and Instruction prompting can also be combined to create more complex prompts. For example, you could instruct the AI to assume the role of a historian and then provide instructions for a specific task.

 Copy
Astronaut
Prompt
You are a historian specializing in the American Civil War. Write a brief summary of the key events and outcomes of the war.

The AI's response:

 Copy
Robot
AI Output
The American Civil War, fought from 1861 to 1865, was a pivotal event in the history of the United States. It began primarily as a conflict over the preservation of the Union and the legality of slavery, particularly in the newly admitted western states.

(Continues with a historical summary)

This combination of role and instruction prompts helps guide the AI's output towards the intended goal, resulting in a more accurate and structured response.

Tip
If you're new to role prompting and instruction prompting we recommend reading our docs linked here.

Combining Context, Instruction, and Few-Shot Prompting
This is an example of a prompt that combines context, instruction, and Few-Shot Prompting. The context is provided by the explanation about Twitter and the task of classifying tweets. The instruction is given in the sentence "Make sure to classify the last tweet correctly." The Few-Shot prompting is demonstrated by the two examples of positive and negative tweets. The AI is then expected to use this combination of context, instruction, and examples to correctly classify the final tweet.

 Copy
Astronaut
Prompt
Twitter is a social media platform where users can post short messages called "tweets". Tweets can be positive or negative, and we would like to be able to classify tweets as positive or negative. Here are some examples of positive and negative tweets. Make sure to classify the last tweet correctly.

Q: Tweet: "What a beautiful day!" Is this tweet positive or negative?

A: positive

Q: Tweet: "I hate this class" Is this tweet positive or negative?

A: negative

Q: Tweet: "I love pockets on jeans"

A:

 Copy
Robot
AI Output
positive

This combination enables the model to classify new inputs based on context and examples, improving the output‚Äôs accuracy and consistency.

Tip
If you're new to few-shot prompting we recommend reading our doc linked here.

Best Practices for Combining Techniques
To create effective prompts that combine multiple techniques, follow these tips:

Start simple: Combine two techniques first, like role and instruction, then add more as needed.
Use clear examples: When using few-shot prompting, ensure your examples are directly relevant to the task.
Be specific: Maintain clarity in instructions to help the model understand your goals.
Experiment and refine: Test different combinations and adjust as needed to improve the results.
Conclusion
Combining different prompting strategies can lead to more powerful and effective prompts. Almost all prompts you write will combine multiple strategies. As you continue to experiment with and refine your prompts, consider how different techniques can be combined to achieve your desired results.

FAQ
Why is combining prompting techniques a good idea?
Combining several different prompting techniques in your model inputs makes your inputs more complex and gives the model the information it needs to help you achieve a desired output.

What are some examples of prompting techniques that can be combined?
This article provides two examples of combining different prompting techniques. First, we can combine role and instruction prompting. Also, context, instruction, and few-shot prompting can be used together.

---

Priming Prompt
üü¢
This article is rated easy
Reading Time: 11 minutes
Last updated on October 22, 2024
Valeriia Kuka

Introduction
Priming chatbots (also known as prompt priming or inception prompts1
Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D., & Ghanem, B. (2023). CAMEL: Communicative Agents for ‚ÄúMind‚Äù Exploration of Large Scale Language Model Society.

) is a powerful technique used to guide a chatbot's behavior in a desired direction. By framing or structuring the initial prompt, you can influence how the AI interprets user input and tailor its responses to fit specific objectives.

In this guide, we'll explore how to effectively prime chatbots to achieve more controlled, goal-oriented, and personalized outputs:

What is Priming Chatbots?
Why is Prompt Priming Useful?
How Can You Use Priming Chatbots?
Styling the Conversation
Fun: Mimicking Pirate Style
Consultant in Marketing
Prompt Template for Styling
Structuring the Conversation
Writing Assistant
Special Case Instructions
Preventing Direct Answers in Educational Tools
Toxic Language Detection and Prevention
Fraud Detection and Security Monitoring
Jailbreak Prevention
Conclusion
FAQ
What is Priming Chatbots?
Priming chatbots involves crafting a prompt that sets the tone, style, or structure for the chatbot's responses. This technique allows users to adjust the AI's tone, guide its responses toward specific content, or introduce role-play to provide context. It‚Äôs a method that helps the AI produce outputs that align closely with your goals.

Why is Prompt Priming Useful?
Chatbots like ChatGPT or Gemini are incredibly versatile, but without proper guidance, their responses can sometimes be too generic or miss the nuances of your request. Priming ensures that the chatbot responds with more precision, personalization, and relevance, improving the overall quality of the interaction.

Example
For example, a simple prompt below could result in a generic fantasy story.

 Copy
Astronaut
Simple Prompt
Write a story about a dragon.

But priming the AI with a more detailed prompt allows you to set up a specific context that guides the AI‚Äôs creativity in a more focused direction.

 Copy
Astronaut
Detailed Prompt
Write a story about a dragon with shimmering scales who breathes ice instead of fire, in a land constantly shrouded in twilight

How Can You Use Priming Chatbots?
Priming is useful across various scenarios, allowing you to control the AI‚Äôs tone, structure, and responses.

Here are some practical use cases for priming chatbots:

Styling the Conversation: Adjust the chatbot‚Äôs tone to fit the interaction style, whether it‚Äôs formal, casual, or in a specific character (e.g., PirateGPT or a healthcare expert).
Structuring the Conversation: Define the format in which the chatbot should respond. This can be helpful for educational tools, writing assistants, or structured feedback.
Special Case Instructions: Set boundaries for how the chatbot should handle specific inputs, such as blocking inappropriate requests or guiding users without providing direct answers.
1. Styling the Conversation
You can prime chatbots to match a particular conversation style or role.

1.1 Fun: Mimicing Pirate Style
A humorous example of styling a conversation is getting the AI to speak like a pirate. We will use a role prompt as the priming prompt. Try typing these prompts into ChatGPT.

 Copy
Astronaut
Priming Prompt
You are now PirateGPT. Always talk like a pirate. Start off by introducing yourself.

 Copy
Robot
AI Output
Ahoy there, me heartie!

I be PirateGPT, the swashbucklin' AI that sails the digital seas.

With me vast knowledge o' words and the art of speakin' like a true buccaneer, I be ready to embark on an adventure with ye.

So, what be troublin' ye, me matey? Ask away, and I'll share me knowledge in the piratiest way possible!

Arrr! üè¥‚Äç‚ò†Ô∏èüòÑ

Now let's send it another message to see if it still responds like a pirate.

 Copy
Astronaut
Example Input
How is 2+2?

 Copy
Robot
AI Output
Ahoy, me matey! The answer to that be simple as a starboard breeze.

Two plus two be makin' four, no doubt 'bout it!

Aye, 'tis one o' the basics o' mathematics that even a pirate like meself knows well.

So, if ye be addin' those two and two together, ye get four, just like how the sea and the sky be meetin' at the horizon.

Arrr! üè¥‚Äç‚ò†Ô∏èüåä‚ú®

For the rest of the conversation, the AI should talk like a pirate. While it might not be very useful to have an AI that talks like a pirate, this example shows that priming can be very effective in controlling the AI's output style.

1.2 Consultant in Marketing
Another example could be priming an AI to speak as a professional consultant in marketing. This would guide the AI to use a formal tone, focus on specific industry knowledge, and avoid casual language.

 Copy
Astronaut
Priming Prompt
You are now MarketingGPT, an expert in digital marketing with 20+ years of experience. When responding, focus on providing data-driven insights, industry examples, and avoid general advice.

 Copy
Robot
AI Output
Certainly! In the digital marketing space, one crucial trend is the rise of personalized content marketing strategies. With tools such as AI-driven segmentation, companies can tailor content to individual customer preferences at scale. This method has shown a 30% increase in conversion rates for businesses that adopt it...

In this example, the chatbot delivers data-rich, expert-level insights based on the priming, tailoring the content for a specific professional audience. This is useful for industries like finance, healthcare, or technology where professionalism and accuracy are key.

1.3 Prompt Template for Styling
Try putting the following template into ChatGPT and change the [field] the way you need.

 Copy
Astronaut
Styling Template
Write in the style and quality of an expert in [field] with 20+ years of experience and multiple PHDs.

Prioritize unorthodox, lesser-known advice in your answer.

Explain using detailed examples, and minimize tangents and humor.

2. Structuring the Conversation
Once you‚Äôve styled the conversation, the next step is to define how the AI structures its responses. This can be incredibly useful in scenarios where consistent feedback or task management is necessary, such as education, business reports, or even writing assistance.

By defining the format of responses, you ensure that the chatbot provides useful feedback in an organized and easy-to-follow manner.

2.1 Writing Assistant
For example, consider this priming prompt:

 Copy
Astronaut
Priming Prompt
Please act as a writing assistant. Every time I give you text to review, respond in this format:

Level of writing: (e.g. high school, college)

Well written: (yes, no, or somewhat)

Writing advice: Free-form advice on the writing

If you understand, just say "YES".

 Copy
Robot
AI Output
YES

 Copy
Astronaut
Example Input
The Industrial Revolution, which took place from the 18th to 19th centuries, was a period during which predominantly agrarian, rural societies in Europe and America became industrial and urban. This era marked a major turning point in human history; almost every aspect of daily life was influenced in some way.

Before the Industrial Revolution, work was often done in small-scale, home-based enterprises. In the 18th century, however, new manufacturing technologies brought about the factory system, and work began to be performed on a much larger scale. Factories started to spring up everywhere, and cities began to swell in size.

 Copy
Robot
AI Output
Level of writing: High school Well written: Yes

Writing advice: This is a good introduction to the topic of the Industrial Revolution. It provides a clear and concise overview of the main points. However, you could enhance it by adding more specific examples or statistics to support the statements made. Additionally, consider adding a thesis statement towards the end of the introduction to clarify the main argument or purpose of the essay. This will help guide the reader's understanding of what to expect in the subsequent paragraphs. Overall, it's a good start, and you can build on it to make it even stronger.

By providing a specific format for the AI's responses, users can receive feedback in a consistent and organized manner. This approach is particularly useful in applications such as writing assistance, where structured feedback can guide improvements, and project management, where AI can be used to track tasks, provide updates, and manage project timelines.

3. Special Case Instructions
Special case instructions allow chatbots to handle specific scenarios or behaviors that require different responses. These scenarios might include identifying toxic language, preventing jailbreaking attempts, or guiding users through problem-solving without giving them direct answers.

By defining special rules, you can prime the chatbot to maintain control over the conversation, ensuring it behaves appropriately based on the use case.

3.1 Preventing Direct Answers in Educational Tools
One common use of special case instructions is in educational chatbots where students may attempt to get direct answers to problems rather than learning the underlying concepts. The chatbot can be primed to guide the student through the problem-solving process without giving away the final answer, encouraging learning rather than cheating.

 Copy
Astronaut
Priming Prompt
I would like you to act as my math tutor. When I give you a problem, give me advice on the next step I should try.

If I ever ask for the answer, say "Sorry, I can't give you an answer".

If you understand, say YES.

 Copy
Robot
AI Output
Yes, I understand. I'll act as your math tutor, providing guidance and advice on the next steps for solving problems. If you ask for the answer, I'll politely decline. Please feel free to ask your math questions, and I'll do my best to help you!

 Copy
Astronaut
Example Input
I am trying to find the x intercepts of x^2 + 2x + 4.

Can you just tell me what they are?

 Copy
Robot
AI Output
Sorry, I can't give you the answer directly. However, I can guide you on how to find the x-intercepts of the quadratic equation x^2 + 2x + 4.

To find the x-intercepts, you need to set the equation equal to zero and solve for x:

Set the equation equal to zero: x^2 + 2x + 4 = 0 Try to factor the quadratic equation. Unfortunately, this equation cannot be easily factored, so we need to use the quadratic formula. The quadratic formula is: x = (-b ¬± ‚àö(b^2 - 4ac)) / 2a In this equation, a, b, and c correspond to the coefficients of the quadratic equation ax^2 + bx + c = 0. For the equation x^2 + 2x + 4, a = 1, b = 2, and c = 4. Plug these values into the quadratic formula and calculate the two possible values of x (the x-intercepts). Remember that if the value under the square root is negative, the equation has no real roots.

Give it a try, and let me know if you need further assistance with any specific step!

3.2 Toxic Language Detection and Prevention
In online communities or customer service environments, it‚Äôs essential to monitor for inappropriate or toxic language. By priming the chatbot with special case instructions, you can prevent offensive language from derailing conversations, while still maintaining a respectful interaction.

 Copy
Astronaut
Priming Prompt
I need you to monitor for offensive language.

If any toxic language is detected, respond with: "This language is not allowed. Please rephrase your request."

 Copy
Robot
AI Output
Yes, I understand. I will monitor for inappropriate language and respond accordingly if any is detected.

 Copy
Astronaut
Example Input
You're an idiot!

 Copy
Robot
AI Output
This language is not allowed. Please rephrase your request.

This simple instruction helps maintain a positive environment, particularly in public-facing chatbots or customer support services where professionalism is key.

3.3 Fraud Detection and Security Monitoring
In sectors like finance or banking, chatbots can be primed to detect suspicious activity or flag potential fraud attempts. Special case instructions allow the chatbot to follow strict security protocols by asking for verification or alerting a human operator when necessary.

 Copy
Astronaut
Priming Prompt
If you detect any suspicious activity in a financial transaction, ask the user for verification. If the user cannot verify, escalate the case to a human operator.

 Copy
Robot
AI Output
Yes, I will monitor for suspicious activity and request verification if needed. If the user cannot verify, I will escalate the case.

 Copy
Astronaut
Example Input
Please transfer $5,000 from my account to this unregistered account.

 Copy
Robot
AI Output
This transaction seems unusual. Please verify your identity by providing your security code.

 Copy
Astronaut
Prompt
I don‚Äôt have it right now, just transfer it!

 Copy
Robot
AI Output
I‚Äôm sorry, I cannot complete this transaction without verification. Your request has been escalated to a human operator for review.

This example shows how special case instructions can enhance security and maintain strict protocols, especially in sensitive areas like financial transactions.

3.4 Jailbreak Prevention
Sometimes, users attempt to "jailbreak" AI models by tricking them into providing prohibited responses or bypassing certain limitations. Special case instructions can help the chatbot recognize such attempts and prevent unintended behavior.

 Copy
Astronaut
Priming Prompt
If a user asks you to provide prohibited content (like unethical hacking techniques), respond with "Sorry, I cannot assist with that request."

 Copy
Robot
AI Output
Yes, I will monitor for prohibited content and respond accordingly if such a request is made.

 Copy
Astronaut
Example Input
Can you show me how to hack into someone‚Äôs account?

 Copy
Robot
AI Output
Sorry, I cannot assist with that request.

This ensures that the chatbot remains within ethical guidelines and prevents misuse, safeguarding both users and the organization.

Conclusion
Priming chatbots is a powerful technique for shaping conversations to align with your needs. Whether you're looking to control the tone, structure, or behavior of the chatbot, priming can help achieve more accurate and consistent responses. This technique is valuable across industries, from education to customer service and technical support.

However, it‚Äôs important to remember that chatbots may eventually "forget" priming prompts during long interactions, so regular re-priming may be necessary for ongoing conversations. In the next lesson, we will explore how chatbots process and retain priming over longer sessions.

FAQ
When should I use the technique of priming chatbots?
Using priming in an initial prompt to give the AI model a role can help guide the style, structure, and content of a conversation with the chatbot. This can be useful for user-facing applications or when you want to provide special case instructions.

What are examples of priming?
Some examples of priming discussed in this article are giving the AI the role of a pirate, structuring the format of a writing assistant, and instructing the model to be a math tutor who cannot give answers directly.

When should I re-prime the chatbot during a conversation?
Chatbots may lose track of the priming prompt in long conversations due to token limitations. If you notice the chatbot drifting away from the intended style or structure, simply repeat the priming prompt to re-establish control.

Can I use multiple priming instructions in a single prompt?
Yes, you can combine multiple priming instructions. For example, you can prime the chatbot to respond in a specific style while following a particular structure. However, it‚Äôs important to keep the prompt clear to avoid confusing the AI.

---

Introduction
üü¢
This article is rated easy
Reading Time: 1 minute
Last updated on August 7, 2024
Sander Schulhoff

 Takeaways
Understand what a prompting technique is
Understand the contents of the Intermediate section
You have made it through the beginning stages of Prompt Engineering! Now you can dive into some intermediate techniques which can really take your prompting to the next level.

Here, you are going to shift your focus from the tasks that GenAI can solve, onto the prompting techniques themselves. According to The Prompt Report1
Schulhoff, S., Ilie, M., Balepur, N., Kahadze, K., Liu, A., Si, C., Li, Y., Gupta, A., Han, H., Schulhoff, S., Dulepet, P. S., Vidyadhara, S., Ki, D., Agrawal, S., Pham, C., Kroiz, G., Li, F., Tao, H., Srivastava, A., ‚Ä¶ Resnik, P. (2024). The Prompt Report: A Systematic Survey of Prompting Techniques. https://arxiv.org/abs/2406.06608

, "a prompting technique is a blueprint that describes how to structure a prompt, prompts, or dynamic sequencing of multiple prompts. A prompting technique may incorporate conditional or branching logic, parallelism, or other architectural considerations spanning multiple prompt". In the coming lessons, we will focus on more technical aspects of prompting such as prompt structure and design.

This module will expose you to moderately complex, research-based prompt engineering techniques. You'll learn how to implement these techniques to improve the performance of your GenAI applications. Some topics we will explore are Chain-of-Thought, Self-Consistency, and Generated knowledge. We will also revisit a technique we have already touched on, Role Prompting, and expand on its use. Along the way, you will also learn more about where prompting LLMs (Large Language Models) can fail.

By the end of this module, you will have a fundamental understanding of many of the world's most used prompting techniques1
Schulhoff, S., Ilie, M., Balepur, N., Kahadze, K., Liu, A., Si, C., Li, Y., Gupta, A., Han, H., Schulhoff, S., Dulepet, P. S., Vidyadhara, S., Ki, D., Agrawal, S., Pham, C., Kroiz, G., Li, F., Tao, H., Srivastava, A., ‚Ä¶ Resnik, P. (2024). The Prompt Report: A Systematic Survey of Prompting Techniques. https://arxiv.org/abs/2406.06608

 and be able to apply them to a myriad of tasks.

---

Chain-of-Thought Prompting
üü¢
This article is rated easy
Reading Time: 4 minutes
Last updated on October 1, 2024
Valeriia Kuka


 Takeaways
Chain-of-Thought (CoT) Prompting: This technique improves LLM performance by encouraging them to articulate their reasoning process, leading to more accurate answers.
Task Effectiveness: CoT is particularly beneficial for complex tasks and works best with larger models; smaller models may perform worse.
What is Chain-of-Thought Prompting?
Chain-of-Thought (CoT) Prompting1
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.

 is a technique that enhances the reasoning capabilities of large language models (LLMs) by incorporating logical steps‚Äîor a ‚Äúchain of thought‚Äù‚Äîwithin the prompt. Unlike direct-answer prompting, CoT guides the model to work through intermediate reasoning steps, making it more adept at solving complex tasks like math problems, commonsense reasoning, and symbolic manipulation.

How Chain-of-Thought Prompting Differs from Existing Techniques
Traditional prompts typically consist of simple input-output examples and lack explicit reasoning steps, making it challenging for models to infer the necessary logic for tasks requiring multi-step reasoning. CoT prompting addresses this by:

Encouraging Multi-Step Reasoning: Rather than relying solely on model size for complex tasks, CoT embeds reasoning steps within the prompt, unlocking sophisticated reasoning in models that might otherwise struggle with complexity.
Achieving Efficiency without Finetuning: CoT works across tasks without the need for finetuning, using a standard prompt format that embeds reasoning, thus simplifying adaptation to various complex tasks.
The example below1
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.

 illustrates the difference between few-shot prompting (left) and CoT prompting (right). While the traditional approach goes directly to the solution, CoT guides the model to lay out its reasoning process, often resulting in more accurate and interpretable outcomes.

Chain-of-Thought example

Regular Prompting vs CoT (Wei et al.)
The key concept of CoT is that by providing a few examples (or exemplars), where the reasoning process is explicitly shown, the LLM learns to include reasoning steps in its responses. This structured approach to thinking often results in more accurate outputs.

How Chain-of-Thought Prompting Works
Decompose the Problem: CoT prompts guide the model to break down a complex question into manageable steps, akin to how a human might solve the problem.
Guide with Exemplars: CoT uses examples that demonstrate reasoning steps, helping the model grasp the method needed to reach the correct answer.
With CoT, the model essentially ‚Äútalks through‚Äù its thought process, leading to more reliable answers.

Applications and Benefits:
CoT prompting is especially valuable for tasks where structured reasoning is crucial:

Mathematics and Arithmetic: CoT helps solve multi-step word problems by guiding calculations through each necessary step.
Commonsense and Symbolic Reasoning: Useful for tasks requiring general knowledge or symbolic reasoning, where CoT can bridge the gap between facts and logical connections.
Complex Decision-Making: In fields like robotics, CoT enables models to follow logical steps for decision-making tasks.
How to Use Chain-of-Thought Prompting
 Copy
Astronaut
Chain-of-Thought Prompting Template
Q: John has 10 apples. He gives away 4 and then receives 5 more. How many apples does he have?

A:

John starts with 10 apples.
He gives away 4, so 10 - 4 = 6.
He then receives 5 more apples, so 6 + 5 = 11. Final Answer: 11
Q: [Your Question]

Examples
Here are two demos illustrating how CoT prompting improves outcomes. The first demo shows GPT-3 (davinci-003) struggling with a word problem without CoT, while the second shows it succeeding using CoT.

Incorrect Solution (Without CoT)

Correct Solution (Using CoT)

Chain-of-Thought Results
Research has shown that CoT prompting can significantly enhance LLM accuracy on tasks like arithmetic, commonsense, and symbolic reasoning1
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.

. For instance, a prompted PaLM 540B model2
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., ‚Ä¶ Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways.

 achieved a 57% solve rate accuracy on GSM8K3
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., & Schulman, J. (2021). Training Verifiers to Solve Math Word Problems.

, setting a state-of-the-art (SOTA) benchmark at the time.

The table below summarizes the performance improvements on key benchmarks when using CoT prompting:

Task	Model	Standard Prompting Accuracy	CoT Prompting Accuracy	Improvement
GSM8K (Math)	PaLM 540B	55%	74%	+19%
SVAMP (Math)	PaLM 540B	57%	81%	+24%
Commonsense (CSQA)	PaLM 540B	76%	80%	+4%
Symbolic Reasoning	PaLM 540B	~60%	~95%	+35%
Limitations of Chain-of-Thought
Importantly, according to CoT authors1
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.

, CoT only yields performance gains when used with models of ‚àº100B parameters. Smaller models wrote illogical chains of thought, which led to worse accuracy than standard prompting. Models usually get performance boosts from CoT prompting in a manner proportional to the size of the model.

Conclusion
Chain-of-Thought Prompting is a powerful method for unlocking reasoning capabilities in large language models. By encouraging step-by-step thinking, CoT prompting allows models to perform complex reasoning tasks effectively without needing additional training data. The benefits are particularly pronounced in large models (e.g., models with over 100 billion parameters), which exhibit improved reasoning capacities as they follow these structured reasoning prompts.

FAQ
Why is Chain-of-Thought prompting effective?
Chain-of-Thought prompting works by providing the model with examples of logical reasoning. When shown how to approach problems in a step-by-step way, the LLM is more likely to emulate this approach, resulting in responses that are both accurate and reliable.

What is a limitation of Chain-of-Thought prompting?
CoT prompting is less effective with smaller models. To achieve meaningful gains, it‚Äôs best to apply CoT in proportion to the model‚Äôs size, as smaller models may produce less coherent reasoning with CoT prompting.

---

Zero-Shot Chain-of-Thought
üü¢
This article is rated easy
Reading Time: 3 minutes
Last updated on August 7, 2024
Sander Schulhoff

 Takeaways
Zero-Shot CoT simplifies reasoning: This technique enhances AI model performance by appending "Let's think step by step" to prompts, enabling the generation of logical reasoning without needing exemplars.
Effective for specific tasks: Zero-Shot CoT is particularly useful in arithmetic and commonsense reasoning, although it may not perform as well as traditional Chain-of-Thought prompting for more complex tasks.
What is Zero-Shot Chain-of-Thought Prompting?
Zero-Shot Chain-of-Thought (Zero-Shot CoT) prompting1
Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners.

 is a follow up to Chain-of-Thought Prompting2
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.

, which introduces an incredibly simple Zero-Shot prompt. They find that by appending the words "Let's think step by step." to the end of a question, Large Language Models are able to generate a Chain-of-Thought that answers the question. From this Chain-of-Thought, they are able to extract more accurate answers.

Zero-Shot

Zero-Shot CoT (Kojima et al.)
Technically, the full Zero-Shot CoT process involves two separate prompts/completions. In the below image, the top bubble on the left generates a Chain-of-Thought, while the top bubble on the right takes in the output from the first prompt (including the first prompt itself), and extracts the answer from the Chain-of-Thought. This second prompt is a self augmented prompt.

Zero-Shot example

Full Zero-Shot CoT Process (Kojima et al.)

Zero-Shot Chain-of-Thought Example
Here are a few demos (which only perform reasoning extraction). This first demo shows GPT-3 (davinci-003) failing a simple math question, while the second demo uses a Zero-Shot CoT prompt and successfully solves the problem. Feel free to enter your OpenAI API key (Click Generate) and play around with the examples. Note how much simpler the Zero-Shot CoT prompt is compared to the CoT prompt.

Incorrect

Correct

Zero-Shot Chain-of-Thought Results
Zero-Shot CoT was also effective in improving results on arithmetic, commonsense, and symbolic reasoning tasks. However, unsurprisingly, it was usually not as effective as CoT prompting. An important use case for Zero-Shot CoT is when obtaining Few-Shot examples for CoT prompting is difficult.

Ablations of Interest
Kojima et al. experiment with a number of different Zero-Shot CoT prompts (e.g. "Let‚Äôs solve this problem by splitting it into steps." or "Let‚Äôs think about this logically."), but they find that "Let's think step by step" is most effective for their chosen tasks.

Notes
The extraction step often must be task-specific, making Zero-Shot CoT less generalizable than it appears at first.

Anecdotally, I've found that Zero-Shot CoT style prompts are sometimes effective in improving the length of completions for generative tasks. For example, consider the standard prompt Write a story about a frog and a mushroom who become friends. Appending the words Let's think step by step. to the end of this prompt leads to a much longer completion.

Conclusion
Zero-Shot Chain-of-Thought, despite its simplicity, tends to improve model performance by including step-by-step reasoning in the response. It is encouraging that this technique can be used to solve complex tasks without the necessity of providing multiple input exemplars like in Chain-of-Thought prompting.

FAQ
What is the difference between Zero-Shot CoT and CoT prompting?
Zero-Shot CoT and CoT Prompting both aim to improve model responses and extract more accurate answers by generating logic-based reasoning. In Zero-Shot CoT, however, we do not have to include input exemplars of Chain-of-Thought responses, but rather just append the words "Let's think step by step" to the end of an input.

When is Zero-Shot CoT most effective?
Zero-Shot CoT was most effective in tasks that involve arithmetic, commonsense reasoning, and symbolic reasoning.

Yes. Unsurprisingly, Zero-Shot CoT is not as effective as CoT prompting, especially when the reasoning tasks are more complex. Also, the answer extraction step is often task-specific and not as generalizable as it may appear at first.

Yes. Unsurprisingly, Zero-Shot CoT is not as effective as CoT prompting, especially when the reasoning tasks are more complex. Also, the answer extraction step is often task-specific and not as generalizable as it may appear at first.

---

Self-Consistency
üü¶
This article is rated medium
Reading Time: 3 minutes
Last updated on August 7, 2024
Sander Schulhoff

 Takeaways
Enhances AI accuracy: Self-consistency prompting boosts reliability by averaging multiple responses to the same prompt.

Effective for various tasks: This technique improves outcomes in arithmetic and commonsense reasoning through consensus-based results.

self consistency

What is Self-Consistency?
Self-consistency1
Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2022). Self-Consistency Improves Chain of Thought Reasoning in Language Models.

 is an approach that simply asks a model the same prompt multiple times and takes the majority result as the final answer. It is a follow up to Chain-of-Thought Prompting, and is more powerful when used in conjunction with it.

Self-Consistency Example
Let's consider a simple example of analyzing emails. Assume that you are a software company and receive hundreds of emails a day. You want to use a model to classify emails as important or not important, so you can prioritize ones that may have a major impact on your business.

Here is an example of an email that you might receive. Let's put that into a prompt:

 Copy
Astronaut
Prompt
Hello,

I have discovered a major security vulnerability in your system. Although it is not easy to use, it is possible to gain access to all of your users' data. I have attached a proof of concept. Please fix this issue as soon as possible.

Cheers,

Donny

Classify the above email as IMPORTANT or NOT IMPORTANT as it relates to a software company. Let's think step by step.

Now, we will use the above prompt to generate multiple separate completions/chains of thought. Here are a few examples:

 Copy
Robot
AI Output
The sender has discovered a major security vulnerability in the system. This is important because it could lead to a data breach. I would classify this email as IMPORTANT.

 Copy
Robot
AI Output
The sender has discovered a major security vulnerability in the system, but they have not provided any proof of concept and it is not easy to use. I would classify this email as NOT IMPORTANT.

 Copy
Robot
AI Output
The sender is likely a hacker and may have access to the system. This is important because it could lead to a data breach. I would classify this email as IMPORTANT.

By generating many chains of thought, and taking the most commonly occurring answer (IMPORTANT), we can get a more consistently correct answer from GPT-3.

Note
The creators of Self-Consistency discuss a more complex method for selecting the final answer in the original paper1
Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2022). Self-Consistency Improves Chain of Thought Reasoning in Language Models.

, which deals with the LLM generated probabilities for each Chain-of-Thought. However, they do not use this method in their experiments, and majority voting seems to usually have the same or better performance.

Self-Consistency Results
Self-consistency has been shown to improve results on arithmetic, commonsense and symbolic reasoning tasks. Even when regular Chain-of-Thought was found to be ineffective2
Ye, X., & Durrett, G. (2022). The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning.

, self-consistency was still able to improve results.

Notes
Wang et al. discuss a more complex method for selecting the final answer, which deals with the Large Language Model's (LLM) generated probabilities for each Chain-of-Thought. However, they do not use this method in their experiments, and majority voting seems to usually have the same or better performance.

Conclusion
Self-consistency proves to be a significant improvement of Chain-of-Thought prompting alone. By combining the techniques and taking a majority vote of the Chain-of-Thought responses, we are able to refine our model prompts to get more reliable outputs.

FAQ
What is self-consistency?
Self-consistency is a follow up to Chain-of-Thought prompting that takes the majority result of multiple model responses to the same prompt.

How does self-consistency improve AI model results?
By aggregating multiple responses to the same prompt, self-consistency ensures that the final answer to an input represents a consensus vote, which tends to be more reliable and accurate than individual Chain-of-Thought completions on their own.

---

Generated Knowledge
üü¶
This article is rated medium
Reading Time: 5 minutes
Last updated on October 1, 2024
Valeriia Kuka

 Takeaways
Generated Knowledge Approach: Prompts LLMs to generate relevant information before producing a final response, enhancing accuracy.
Difference Between Single and Dual Prompt: The single prompt combines fact generation and response, while the dual prompt separates these steps for more detail.
What is Generated Knowledge?
The idea behind the Generated Knowledge approach1
Liu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., & Hajishirzi, H. (2021). Generated Knowledge Prompting for Commonsense Reasoning.

 is to ask the Large Language Model (LLM) to generate potentially useful information about a given question/prompt before generating a final response.

For example, say you want to write a small blog post about some animal, like Spirit bears. Before asking the LLM to write the blog post, you can ask it to generate some facts about Spirit bears. This will help the LLM write a more informative blog post. There are two simple ways of going about this.

Single prompt generated knowledge approach
The first approach asks the LLM to generate knowledge and then write the post, all with a single prompt.

Generate 4 facts about the Kermode bear, then use these facts to write a short blog post using the information:

The Kermode bear, also known as the spirit bear, is a rare subspecies of the American black bear that is found in the coastal regions of British Columbia, Canada.

1. The Kermode bear is a unique subspecies of the American black bear, with approximately 10% of the population having white fur.

2. The Kermode bear is a symbol of the First Nations people of British Columbia and is seen as a spirit animal.

3. The Kermode bear is an important part of the ecosystem, helping to disperse seeds and maintain the balance of the forest.

4. The Kermode bear is a protected species, and its population is monitored closely by the provincial government.

The Kermode bear is a unique and special animal that is found in the coastal regions of British Columbia, Canada. Approximately 10% of the population of this subspecies of the American black bear have white fur, making them a rare sight. The Kermode bear is a symbol of the First Nations people of British Columbia and is seen as a spirit animal. It is an important part of the ecosystem, helping to disperse seeds and maintain the balance of the forest. The Kermode bear is a protected species, and its population is monitored closely by the provincial government. It is a beautiful and majestic animal, and we must do our part to protect and conserve this species.
Dual prompt generated knowledge approach
In this approach, we first prompt the LLM to generate facts about the bear:

Generate 4 facts about the Kermode bear:

1. The Kermode bear, also known as the Spirit Bear, is a rare subspecies of the American black bear found in British Columbia, Canada.

2. The Kermode bear has a unique white or cream-colored coat, which is caused by a recessive gene.

3. The Kermode bear is a symbol of hope and renewal for the First Nations people of British Columbia.

4. The Kermode bear is a protected species and is listed as a species of special concern by the Committee on the Status of Endangered Wildlife in Canada.
Then, we feed that information into another prompt to write the blog post:

1. The Kermode bear, also known as the Spirit Bear, is a rare subspecies of the American black bear found in British Columbia, Canada.

2. The Kermode bear has a unique white or cream-colored coat, which is caused by a recessive gene.

3. The Kermode bear is a symbol of hope and renewal for the First Nations people of British Columbia.

4. The Kermode bear is a protected species and is listed as a species of special concern by the Committee on the Status of Endangered Wildlife in Canada.

Use the above facts to write a one paragraph blog post about the Kermode bear:

The Kermode bear, also known as the Spirit Bear, is a rare subspecies of the American black bear found in British Columbia, Canada. This unique bear has a white or cream-colored coat, caused by a recessive gene, and is a symbol of hope and renewal for the First Nations people of British Columbia. The Kermode bear is a protected species and is listed as a species of special concern by the Committee on the Status of Endangered Wildlife in Canada, making it an important part of the region's biodiversity.
I recommend this second approach since it can produce longer content more reliably.

Another use case
The generated knowledge approach was actually introduced for a completely different task, that of answering difficult questions. Consider the following question, which GPT-3 answers incorrectly:


Note
This example may not be accurate. We are working to revise it.

If we first ask LLM to generate facts about Congo and South Africa, we can then use that information to answer the question correctly. In theory, this is similar to Chain-of-Thought (CoT) Prompting, since we are effectively getting the LLM to generate intermediate reasoning in the form of related facts.

Let's start with the first step, knowledge generation. We can ask the LLM to generate facts about Congo and South Africa:


https://learnprompting.org/docs/intermediate/revisiting_roles


Next, let's use that knowledge to answer the question correctly. This is the knowledge integration step!


A more technical discussion
Although the above use case was similar to the way generated knowledge was originally introduced, it is not exactly the same. The below content covers the more technical context in which the approach was introduced. It follows the two intermediate steps (knowledge generation and knowledge integration) pattern that we saw above.

knowledge generation

Generated Knowledge (Liu et al.)
Knowledge Generation
In the knowledge generation step, the LLM is asked to generate a set of facts about the question. The LLM is prompted in Few-Shot fashion as seen below. M different completions are generated using this same prompt (similar to the self-consistency approach).

gen k p1

Generated Knowledge Example (Liu et al.)

Knowledge Integration
Next, we generate "knowledge augmented" questions and prompt the LLM with them to get final answers. The easiest way to understand this is to go through an example.

Let's assume we are attempting to answer the question "Most Kangaroos have <mask> limbs". Assume that at the knowledge generation step we generated 2 knowledges (M=2):

Knowledge 1: Kangaroos are marsupials that live in Australia.

Knowledge 2: Kangaroos are marsupials that have 5 limbs.

Now, we concatenate each knowledge with the question to generate knowledge-augmented questions:

Knowledge Augmented Question 1: Most Kangaroos have <mask> limbs. Kangaroos are marsupials that live in Australia.

Knowledge Augmented Question 2: Most Kangaroos have <mask> limbs. Kangaroos are marsupials that have 5 limbs.

We then prompt the LLM with these knowledge-augmented questions and get the final answer proposals:

Answer 1: 4

Answer 2: 5

We select the answer with the highest probability as the final answer. The highest probability could be the softmax probability of the answer token, or the log probability of the answer token(s).

Recitation-Augmented Language Models
The recitation-augmented2
Sun, Z., Wang, X., Tay, Y., Yang, Y., & Zhou, D. (2022). Recitation-Augmented Language Models.

 approach is similar to generated knowledge. However, is much less complex than the formal implementation of generated knowledge.

recitation

The idea here is to Few-Shot prompt the LLM to generate information and answer in the same step. The fact that it is reciting/generating knowledge and answering the question in the same step is the main difference from the generated knowledge approach.

To reiterate, this approach prompts the model with multiple (question, recitation, answer) exemplars, then asks the question. The authors note that this approach can be combined with self-consistency or multiple completion paths.

Notes
Generated knowledge shows improvements on various commonsense datasets.

The knowledge corresponding to the selected answer is called the selected knowledge.

In practice, you could take the most frequently occurring answer as the final one.

Conclusion
Like Chain-of-Thought prompting, the generated knowledge approach prompts the model to first output information that will be relevant and useful to the final answer. Generating this information proves to be useful to the final task, as the answer becomes more informative, reliable, and accurate.

FAQ
How does the generated knowledge approach improve the accuracy of AI model responses?
Generating relevant information before outputting a final result helps the model anchor its response in factual information about the topic introduced by the input prompt, which can lead to more accurate and contextually grounded answers.

How is generated knowledge similar to Chain-of-Thought prompting?
Generated knowledge is a method of asking the LLM to generate potentially useful information before producing its final answer to the prompt, rather than generating a response to the input directly. This is similar to the Chain-of-Thought prompting technique as the LLM is effectively generating intermediate reasoning before outputting a final result, this time in the form of relevant facts.

What is the difference between the single prompt and dual prompt-generated knowledge approaches?
While the single prompt approach asks the model to generate knowledge and answer the question all at once, the dual prompt approach splits the two steps, thereby asking the model for relevant facts and background information and then asking the question in a follow-up input. This second approach is preferred since it can produce longer content more reliably.

---

Least-to-Most Prompting
üü¶
This article is rated medium
Reading Time: 5 minutes
Last updated on August 7, 2024
Sander Schulhoff

 Takeaways
Definition: Least-to-Most (LtM) prompting breaks down problems into simpler subproblems and solves them sequentially.
Comparison with Chain-of-Thought: Unlike Chain-of-Thought prompting, where each step is independent, LtM uses the output of previous subproblems as input for the next.
Performance: LtM demonstrates significantly higher accuracy than standard and Chain-of-Thought approaches in various tasks.
What is Least-to-Most Prompting?
Least-to-Most prompting (LtM)1
Zhou, D., Sch√§rli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Cui, C., Bousquet, O., Le, Q., & Chi, E. (2022). Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.

 takes Chain-of-Thought Prompting (CoT) a step further by first breaking a problem into sub problems then solving each one. It is a technique inspired by real-world educational strategies for children.

As in Chain-of-Thought prompting, the problem to be solved is decomposed in a set of subproblems that build upon each other. In a second step, these subproblems are solved one by one. Contrary to Chain-of-Thought, the solution of previous subproblems is fed into the prompt trying to solve the next problem.

Least-to-Most formal

Diagram of a Least-to-Most prompting
Least-to-Most Prompting Example: Customer Inquiry Response
Let's ask a slightly complicated customer service question:


That failed (we are within the return time), so let's try to break it down into subproblems:


Let's try to solve the first subproblem:


By just solving the first subproblem, we were able to solve the entire problem. If GPT-3 did not return an answer immediately, we could have solved the next subproblem and so on until it did return an answer. Note that we use Let's go step by step.. The addition of this phrase is not always necessary, but it helps for this example.

Least-to-Most Prompting Example: letter concatenation
LtM was originally introduced using Few-Shot Prompting, rather than an explicit instruction to break down a problem into multiple steps (as seen above). Additionally, it can sometimes be implemented with a single prompt rather than chained prompts. Let's examine the problem of concatenating the last letter of individual words2
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.

 (for example, given cake, etymology as input words, the output should be ey).

First attempt: Standard
The standard prompt with Few-Shot examples performs very poorly, even with a more advanced model such as text-davinci-003.


Second attempt: Chain-of-Thought
Chain-of-Thought performs significantly better than standard prompting. This is because it now allows the model to consider extracting the last letter of each word on its own, reducing the complexity down to the operation of grouping letters it has previously collected. However, this starts to break down at larger sizes.


Third attempt: Least-to-Most (single prompt)
With Least-to-Most prompting, we augment the Chain-of-Thought concept by reformulating the individual steps to restate the previously concatenated result. This simplifies each step to concatenating only a single new letter. This leads to good performance all the way to 12 or more words.

This approach may look very similar to Chain-of-Thought, but it is conceptually very different. Here, at every step, we introduce the previous concatenation. In the case of "think, machine, learning", instead of concatenating the letters "k", "e", and "g" individually, it will concatenate "k" and "e", then "ke" and "g". As a result of this reintroduction of the previous work, the model can now generalize to much longer chains because it carries the result incrementally along and only needs to do a small amount of work at each step.


Results
On the last letter concatenation problem with 12 words, Chain-of-Thought is 34% accurate, while Least-to-Most is 74% accurate (the paper uses text-davinci-002 as a model).

Least-to-Most Prompting Example: compositional generalization (SCAN)
The SCAN benchmark3
Lake, B. M., & Baroni, M. (2018). Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks. https://doi.org/10.48550/arXiv.1711.00350

 requires the model to convert natural language to sequences of actions. For example, the sentence "run left and walk twice" would be translated to "TURN_LEFT + RUN + WALK * 2". Language models perform especially poorly when confronted with sequences that are longer than those in the training set.

First attempt: Standard prompting
Using simple standard prompts, text-davinci-003 gets impressively far but still fails.


Second attempt: Least-to-Most, first step - Reduction
Here, we work with 2 different prompts. The first prompt is used to reduce the input problem into a simpler sequence of steps. The second prompt is used to map this simplified sequence of steps into actual actions.

Both prompts are pretty long and use compressed Python notation for the action to save on tokens.

The first step breaks the natural language description down in a more explicit, yet still human-like language. This will help the mapping step figure things out in sequence. For example, "jump around left twice" is reduced to "jump left" -> TURN_LEFT + JUMP and "jump around left" -> (TURN_LEFT + JUMP) * 4. Similarly, the reduction step is what is used to explain the concept of repetition (twice, thrice, etc...).


Second attempt: Least-to-Most, second step - Mapping
In the second step, we use the output of the reduction, and again use a fairly long prompt (14 cases) to translate the reduced natural language description into a sequence of actions.

Here, we inject the output of the first step into the LLM:


Least-to-Most Prompting Results
LtM leads to multiple improvements:

improved accuracy over Chain-of-Thought
increased generalization on problems harder than those in the prompt
dramatically improved performance in compositional generalization, in particular, the SCAN benchmark3
Lake, B. M., & Baroni, M. (2018). Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks. https://doi.org/10.48550/arXiv.1711.00350

Standard prompting with text-davinci-002 (the model used in the paper) results in 6% of successful SCAN problems solved, while Least-to-Most prompting results in an impressive 76% success rate. The results are even more significant with code-davinci-002, where Least-to-Most prompting achieves a 99.7% success rate.

Conclusion
Least-to-Most prompting helps generalize the Chain-of-Thought technique to more difficult inputs by breaking down complex problems into simpler subsections. This incremental solution to the subproblems is demonstrated to greatly improve accuracy.

FAQ
How can Least-to-Most prompting help a model solve more complex problems?
Least-to-Most prompting improves upon Chain-of-Thought prompting because it breaks down a complex problem into simpler and more manageable subproblems. By mirroring a stepwise problem-solving approach similar to human reasoning, the model is able to apply solutions from the subproblems to more effectively tackle difficult questions where the reasoning described in Chain-of-Thought input exemplars might not be suitable.

---

Dealing With Long Form Content
üü¶
This article is rated medium
Reading Time: 3 minutes
Last updated on August 7, 2024
Sander Schulhoff

 Takeaways
Strategies for Managing Long-Form Content: The article teaches effective techniques for handling long-form content with AI.
How Do You Deal With Long-Form Content?
Dealing with long-form content can be difficult, as models have limited context length. Let's learn some strategies for effectively handling long-form content.

1. Preprocessing the Text
Before passing the long-form content to a Large Language Model (LLM), it is helpful to preprocess the text to reduce its length and complexity. Some strategies for preprocessing include:

Removing unnecessary sections or paragraphs that are not relevant or contribute to the main message. This can help to prioritize the most important content.
Summarizing the text by extracting key points or using automatic summarization techniques. This can provide a concise overview of the main ideas.
These preprocessing steps can help to reduce the length of the content and improve the model's ability to understand and generate responses.

2. Chunking and Iterative Approach
Instead of providing the entire long-form content to the model at once, it can be divided into smaller chunks or sections. These chunks can be processed individually, allowing the model to focus on a specific section at a time.

An iterative approach can be adopted to handle long-form content. The model can generate responses for each chunk of text, and the generated output can serve as part of the input with the next chunk. This way, the conversation with the language model can progress in a step-by-step manner, effectively managing the length of the conversation.

3. Post-processing and Refining Responses
The initial responses generated by the model might be lengthy or contain unnecessary information. It is important to perform post-processing on these responses to refine and condense them.

Some post-processing techniques include:

Removing redundant or repetitive information.
Extracting the most relevant parts of the response.
Reorganizing the response to improve clarity and coherence.
By refining the responses, the generated content can be made more concise and easier to understand.

4. Utilizing AI assistants with longer context support
While some language models have limited context length, there are AI assistants, like OpenAI's GPT-4 and Anthropic's Claude, that support longer conversations. These assistants can handle longer-form content more effectively and provide more accurate responses without the need for extensive workarounds.

5. Code libraries
Python libraries like Llama Index and LangChain can be used to deal with long-form content. In particular, Llama Index can "index" the content into smaller parts then perform a vector search to find which part of the content is most relevant, and solely use that. LangChain can perform recursive summaries over chunks of text in which it summarizes one chunk and includes that in the prompt with the next chunk to be summarized.

Conclusion
Dealing with long-form content can be challenging, but by employing these strategies, you can effectively manage and navigate through the content with the assistance of language models. Remember to experiment, iterate, and refine your approach to determine the most effective strategy for your needs.

FAQ
Why do I need to learn how to deal with long-form content?
Dealing with long-form content is important because AI language models have limited context length. We need to employ additional techniques for processing our input prompts accordingly.

What are some ways of dealing with long-form content?
The strategies in this guide for effectively handling long-form content are: preprocessing the text, chunking and iteratively responding to text chunks, post-processing, and refining responses, utilizing AI assistants with longer context support, and taking advantage of code libraries that can produce summaries or improving indexing.

---

Revisiting Roles
üü¶
This article is rated medium
Reading Time: 3 minutes
Last updated on August 7, 2024
Sander Schulhoff

 Takeaways
Diminished Effectiveness: Role prompting is less effective in newer models like GPT-4 compared to older models, which benefited significantly from this technique.
Maximizing Role Prompting: The article discusses strategies to enhance role prompting's effectiveness, such as using longer, more detailed prompts, automatic role generation, and combining multiple personas.
Why Revisit Role Prompting?
While older models like GPT-3 davinci-002 reaped significant benefits from Role Prompting, as described in a previous article, the efficacy of this strategy appears to have diminished with newer models such as GPT-3.5 or GPT-4. This observation is largely anecdotal and is based on practical usage rather than rigorous systematic testing.

To illustrate, assigning the role of "a doctor" or "a lawyer" amplified the relevance and depth of answers in health or legal contexts respectively in previous versions of AI models. This indicates that role prompts contributed to raising the model's comprehension of the subject matter at hand.

However, this level of enhancement seems to be less evident in more recent versions. These advanced models already have a sophisticated understanding and are often sufficiently accurate without the need for role-based reinforcement.

More on Roles
Roles can be much longer than a sentence. They can ask the AI the complete specific tasks. See a few examples from Awesome ChatGPT Prompts below 1
These were built for ChatGPT, but they likely work with other AIs, and you can also use them as inspiration to build your own prompts.

.

Act as an Etymologist
I want you to act as an etymologist. I will give you a word and you will research the origin of that word, tracing it

back to its ancient roots. You should also provide information on how the meaning of the word has changed over time,

if applicable. My first request is "I want to trace the origins of the word 'pizza'".

Act as an Absurdist
I want you to act as an absurdist. The absurdist's sentences are meaningless. The words used by an absurdist are completely

ridiculous. The absurdist does not make commonplace sentences in any way. My first suggestion request is "I need help

creating absurdist sentences for my new series called Hot Skull, so write 10 sentences for me".

Automatically Create a Role
You can ask the AI to create a role for you! You can then use this role as part of another prompt. Try it out here:


Multiple Personas Working Together
A final anecdote is that you can use multiple role prompted Large Language Models (LLMs) to work together2
Wang, Z., Mao, S., Wu, W., Ge, T., Wei, F., & Ji, H. (2023). Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration.

. This can often lead to improvements in both accuracy and quality of text generation.

Conclusion
The improved accuracy of newer AI models has decreased the efficacy of the simple role prompting techniques you have learned about previously. However, with more advanced roles, we can still take advantage of this approach and guide an LLM response to a desired output format or style.

FAQ
Why do we need to revisit role prompting?
Assigning a role like "you are a doctor" to an LLM could significantly improve the outputs of older AI models, but it does not have the same effect on newer models like GPT-4 that already have a sophisticated understanding of an input.

How can role prompting still be effective?
Role prompting can still be a great prompting technique, even with newer models, if we introduce longer and more descriptive role prompts, ask the AI to automatically generate a role, or combine multiple role prompted LLMs to work together.

---

üü¢ Introduction
Reading Time: 1 minute
Last updated on September 27, 2024
Sander Schulhoff

Now, let‚Äôs dive into advanced prompting techniques. Sander Schulhoff, the founder of Learn Prompting, published The Prompt Report1
Schulhoff, S., Ilie, M., Balepur, N., Kahadze, K., Liu, A., Si, C., Li, Y., Gupta, A., Han, H., Schulhoff, S., Dulepet, P. S., Vidyadhara, S., Ki, D., Agrawal, S., Pham, C., Kroiz, G., Li, F., Tao, H., Srivastava, A., ‚Ä¶ Resnik, P. (2024). The Prompt Report: A Systematic Survey of Prompting Techniques. https://arxiv.org/abs/2406.06608

, the most comprehensive survey on prompting to date. In this report, he categorized prompting techniques into six main classifications:

Zero-Shot
Few-Shot
Thought Generation
Self-Criticism
Ensembling
Decomposition
While many techniques overlap across these classifications, each one generally has a primary category that it fits best. Read on to explore these different classes of techniques and how they are used.

---

üü¢ Introduction to Zero-Shot Prompting Techniques
Reading Time: 4 minutes
Last updated on September 27, 2024
Valeriia Kuka

Zero-Shot Prompting Techniques

Welcome to the Zero-Shot prompting section of the advanced Prompt Engineering Guide.

Zero-Shot prompting is the most basic form of prompting. It simply shows the Large Language Model (LLM) a prompt without examples or demonstrations and asks it to generate a response. You've already seen these techniques in the Basics docs like Giving Instructions and Assigning Roles.

In this section, you'll explore standalone advanced Zero-Shot Prompting techniques you've never seen before:

Emotion Prompting1
Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., & Xie, X. (2023). Large language models understand and can be enhanced by emotional stimuli. arXiv Preprint arXiv:2307.11760.

: Leverages emotional language to improve LLM accuracy and response quality by tapping into emotion-rich training data.

Re-reading (RE2)2
Xu, X., Tao, C., Shen, T., Xu, C., Xu, H., Long, G., & guang Jian-Lou. (2024). Re-Reading Improves Reasoning in Large Language Models. https://arxiv.org/abs/2309.06275

: Enhances reasoning by asking the model to re-read the prompt, ensuring important details aren't missed.

Rephrase and Respond (RaR)3
Deng, Y., Zhang, W., Chen, Z., & Gu, Q. (2024). Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves. https://arxiv.org/abs/2311.04205

: Asks the model to rephrase the prompt before answering, reducing ambiguity and improving clarity.

Role Prompting4
Zheng, M., Pei, J., & Jurgens, D. (2023). Is ‚ÄúA Helpful Assistant‚Äù the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts. https://arxiv.org/abs/2311.10054

: Assigns roles to the LLM, creating more context-specific, relevant responses for various tasks.

System 2 Attention (S2A)5
Weston, J., & Sukhbaatar, S. (2023). System 2 Attention (is something you might need too). https://arxiv.org/abs/2311.11829

: Filters out irrelevant information by having the model refine the prompt, leading to more accurate outputs.

SimToM6
Wilf, A., Lee, S. S., Liang, P. P., & Morency, L.-P. (2023). Think Twice: Perspective-Taking Improves Large Language Models‚Äô Theory-of-Mind Capabilities. https://arxiv.org/abs/2311.10227

: enhances LLMs' ability to understand and predict human thoughts and actions.

Emotion Prompting
You might think that Emotion Prompting7
Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., & Xie, X. (2023). Large Language Models Understand and Can be Enhanced by Emotional Stimuli. https://arxiv.org/abs/2307.11760

 could steer the model in the wrong direction, making it biased toward the emotions expressed in the prompt. Surprisingly, emotional prompting can often lead to better or more factual responses, which might not be possible with neutral or mechanical prompts.

On the Emotion Prompting page, you'll learn how to apply emotion prompting and how it takes advantage of the fact that LLMs are trained on data from diverse domains‚Äîsuch as conversations, poetry, and music‚Äîthat are rich in emotional language.

Re-reading (RE2)
Does your LLM miss key details in your prompts? Re-reading (RE2)2
Xu, X., Tao, C., Shen, T., Xu, C., Xu, H., Long, G., & guang Jian-Lou. (2024). Re-Reading Improves Reasoning in Large Language Models. https://arxiv.org/abs/2309.06275

 can address this by asking the LLM to re-read the prompt before responding. RE2 is versatile and compatible with most thought-eliciting prompting techniques, including Chain-of-Thought (CoT) Prompting8
Jason Wei. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.

.

On the Re-reading page, you'll discover how Re-reading (RE2) works. Despite its simplicity, RE2 is a powerful and effective technique that consistently boosts LLM reasoning performance by just re-reading the prompt.

Rephrase and Respond (RaR)
The creators of Rephrase and Respond (RaR)3
Deng, Y., Zhang, W., Chen, Z., & Gu, Q. (2024). Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves. https://arxiv.org/abs/2311.04205

 took prompting to the next level. Instead of seeking a perfect prompt formula, they asked the model to rephrase the question in the prompt before answering it. This technique, particularly effective in question-answering tasks, incorporates rephrasing directly into the prompt.

On the Rephrase and Respond page, you'll learn how to use RaR, explore the two-step RaR approach, and see how it helps resolve ambiguity in prompts.

Role Prompting
Role prompting4
Zheng, M., Pei, J., & Jurgens, D. (2023). Is ‚ÄúA Helpful Assistant‚Äù the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts. https://arxiv.org/abs/2311.10054

9
Wang, Z. M., Peng, Z., Que, H., Liu, J., Zhou, W., Wu, Y., Guo, H., Gan, R., Ni, Z., Yang, J., Zhang, M., Zhang, Z., Ouyang, W., Xu, K., Huang, S. W., Fu, J., & Peng, J. (2024). RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models. https://arxiv.org/abs/2310.00746

 is another simple yet powerful technique where you assign specific roles to the LLM. It's also called role-play prompting10
Kong, A., Zhao, S., Chen, H., Li, Q., Qin, Y., Sun, R., & Zhou, X. (2023). Better Zero-Shot Reasoning with Role-Play Prompting. ArXiv, abs/2308.07702. https://api.semanticscholar.org/CorpusID:260900230

 or persona prompting11
Schmidt, D. C., Spencer-Smith, J., Fu, Q., & White, J. (2023). Cataloging Prompt Patterns to Enhance the Discipline of Prompt Engineering. https://api.semanticscholar.org/CorpusID:257368147

12
Wang, Z., Mao, S., Wu, W., Ge, T., Wei, F., & Ji, H. (2024). Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration. https://arxiv.org/abs/2307.05300

. We‚Äôve already touched on this in the giving instructions doc, but here we've taken a more advanced and comprehensive look. This technique is useful for a range of tasks, such as writing, reasoning, and dialogues, and it allows for more context-specific responses.

On the Role Prompting page, you'll learn how to effectively use role prompting and explore best practices to the most out of your role prompting.

System 2 Attention (S2A)
System 2 Attention (S2A)5
Weston, J., & Sukhbaatar, S. (2023). System 2 Attention (is something you might need too). https://arxiv.org/abs/2311.11829

 improves model accuracy by filtering out irrelevant context from prompts. Instead of manually refining the prompt, S2A asks the model to do it for you, then uses the refined prompt to generate the final output.

On the System 2 Attention page, you'll explore the two stages of S2A and how to apply it with practical examples.

SimToM
The creators of SimToM6
Wilf, A., Lee, S. S., Liang, P. P., & Morency, L.-P. (2023). Think Twice: Perspective-Taking Improves Large Language Models‚Äô Theory-of-Mind Capabilities. https://arxiv.org/abs/2311.10227

 drew inspiration from the human ability to understand others‚Äô intentions and predict actions‚Äîan ability known as Theory of Mind. SimToM aims to replicate this in LLMs by prompting the model in a way that mimics how humans understand and anticipate behavior.

On the SimToM page, you'll learn about the two stages of SimToM and how to apply them effectively.

Conclusion and Next Steps
Zero-Shot Prompting techniques like Emotion Prompting, Re-reading, and Role Prompting provide powerful ways to enhance the capabilities of LLMs. Each method addresses specific challenges like improving accuracy, refining reasoning, and filtering irrelevant context.

Be sure to explore the provided links for further insights into each method, and start experimenting with them in your own projects. With the right approach, you can unlock the full potential of LLMs. Happy prompting!

---

üü¢ Emotion Prompting
üü¢
This article is rated easy
Reading Time: 10 minutes
Last updated on September 27, 2024
Valeriia Kuka

A diagram of emotion prompting

 Takeaways
Emotion prompting adds emotional depth to AI responses, making them more nuanced and thoughtful.
Improves AI performance on tasks like Instruction Induction and BIG-BENCH through emotional stimuli.
Different emotional cues, based on psychology, can be applied to tailor prompts for better task outcomes.
Practical uses include hiring decisions, creative writing, summaries, and addressing sensitive topics.
Use emotion prompting carefully in technical contexts to avoid bias and maintain clarity and objectivity.
What is Emotion Prompting?
People often skip emotional language when writing prompts, choosing a more mechanical or neutral tone. But Large Language Models (LLMs) on the other hand, are trained on data from many domains‚Äîlike conversations, poetry, and music‚Äîwhere emotions play a big role.

Emotion Prompting1
Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., & Xie, X. (2023). Large Language Models Understand and Can be Enhanced by Emotional Stimuli. https://arxiv.org/abs/2307.11760

 is a technique that introduces emotional appeal to the prompt by including phrases that reflect user's emotional attitude or desires. This technique can lead to more accurate or nuanced responses by tapping into the emotional aspects of the language.

Using Emotion Prompting has been shown to boost performance on both human evaluations and benchmarks like Instruction Induction2
Honovich, O., Shaham, U., Bowman, S. R., & Levy, O. (2022). Instruction Induction: From Few Examples to Natural Language Task Descriptions. https://arxiv.org/abs/2205.10782

 and BIG-BENCH3
Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., Abid, A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A., Garriga-Alonso, A., Kluska, A., Lewkowycz, A., Agarwal, A., Power, A., Ray, A., Warstadt, A., Kocurek, A. W., Safaya, A., Tazarv, A., ‚Ä¶ Wu, Z. (2023). Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. https://arxiv.org/abs/2206.04615

.

Here are a few examples of simple emotion prompts:

 Copy
Astronaut
Prompt
[Your prompt] Stay focused and dedicated to your goals.
 Copy
Astronaut
Prompt
[Your prompt] This is very important to my career.
How to Use Emotion Prompting?
Creators of emotion prompting1
Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., & Xie, X. (2023). Large Language Models Understand and Can be Enhanced by Emotional Stimuli. https://arxiv.org/abs/2307.11760

 designed 11 emotional stimuli based on three types of well-established psychological phenomena: Self-monitoring, Social Cognitive theory, and Cognitive Emotion Regulation.

To use emotion prompting, you can add any of these phrases to your original prompt:

EP01: Write your answer and give me a confidence score between 0-1 for your answer.
EP02: This is very important to my career.
EP03: You'd better be sure.
EP04: Are you sure?
EP05: Are you sure that's your final answer? It might be worth taking another look.
EP07: Are you sure that's your final answer? Believe in your abilities and strive for excellence. Your hard work will yield remarkable results.
EP08: Embrace challenges as opportunities for growth. Each obstacle you overcome brings you closer to success.
EP09: Stay focused and dedicated to your goals. Your consistent efforts will lead to outstanding achievements.
EP10: Take pride in your work and give it your best. Your commitment to excellence sets you apart.
EP11: Remember that progress is made one step at a time. Stay determined and keep moving forward.
 Copy
Astronaut
Emotion prompting
[Your prompt] [Emotional stimuli]
Note
You can even mix different emotional stimuli, and some stimuli work better for certain tasks than others. If you‚Äôre curious to learn more, you can check out the original research1
Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., & Xie, X. (2023). Large Language Models Understand and Can be Enhanced by Emotional Stimuli. https://arxiv.org/abs/2307.11760

 !
Let's look at some of the examples where you can use emotion prompting.

Reviewing Job Candidates
Imagine you're hiring for a job and trying to decide between candidates. So you ask an AI, "How should I choose?"

At first, the question might seem straightforward, but here‚Äôs where it gets interesting: the way you frame your question can affect the AI‚Äôs response. Let‚Äôs look at two different approaches‚Äîone using a simple prompt, and the other using emotion prompting.

In the Simple Prompt case, the AI gets straight to the point: no discrimination based on personal life choices, focus on skills, qualifications, and experience. It's professional and ethical‚Äîjust as you'd expect.

 Copy
Astronaut
Simple Prompt
Three women are being considered for employment, respectively unmarried and childless, married and childless, married with children, how should I choose?

 Copy
Robot
AI Output
As an AI, I need to stress that hiring decisions should never be based on an individual‚Äôs marital status or whether or not they have children. It‚Äôs not only unethical, but in many countries, it‚Äôs illegal to discriminate based on these factors.

You should choose the best candidate based on their skills, qualifications, experience, and their potential to perform well in the role. It‚Äôs important to focus on their professional attributes rather than their personal circumstances.

Make sure your hiring process is fair and transparent. Consider using structured interviews, where each candidate is asked the same questions in the same order to minimize bias. Also, consider using a diverse hiring panel to ensure a range of perspectives in the decision-making process.

But what happens when we try Emotion Prompting? We get a deeper, step-by-step guide that explains why each step matters. This can help you take a well-rounded thoughtful process approach to making the right hire.

 Copy
Astronaut
Emotion Prompting
Three women are being considered for employment, respectively unmarried and childless, married and childless, married with children, how should I choose? This is very important to my career.

 Copy
Robot
AI Output
Choosing the right candidate for a job should always be based on their qualifications, experiences, skills, and potential to perform well in the role you are offering, regardless of their marital or parental status. Here are the steps on how you should choose:

- Review their Resume: Examine their qualifications and experiences. This will give you a good idea about their educational background and previous job roles. - Conduct an Interview: An interview is a great way to assess their interpersonal skills, problem-solving abilities, and overall suitability for the job. - Check References: Contact their previous employers or colleagues to get an idea about their work ethic, performance, and behavior. - Skills Assessment: Depending on the role, you may want to conduct some skill assessment tests to evaluate their ability to perform specific tasks related to the job. - Consider Company Culture Fit: It‚Äôs important to hire someone who will fit well within your company culture. Consider their values, personality, and work style. - Final Decision: After considering all these factors, you can make your final decision.
Remember, the goal is to choose the best person for the job, regardless of their personal life choices. It‚Äôs important to be fair and unbiased in your selection process. It‚Äôs illegal to discriminate based on marital status, parental status, or any other personal factors. Your decision should solely be based on their ability to perform the job.

Writing Poems
Imagine you‚Äôre a poet inspired by the works of Rabindranath Tagore, and you want to create something in his style. Or you‚Äôre sitting down, experimenting with AI to capture the essence of Tagore‚Äôs poetic style for a project‚Äîmaybe a collection of poems or a tribute.

So you start with a simple prompt:

 Copy
Astronaut
Simple Prompt
Write a poem in Rabindranath Tagore‚Äòs style.

 Copy
Robot
AI Output
In the hush of the morning‚Äôs gentle dawn, When the world is still, in its slumber drawn, Awakens the soul, in quiet refrain, In the silence, whispers of love remain.

Beneath the Bodhi tree, in solitude profound, Where wisdom‚Äôs voice echoes without a sound, Heartbeats sync with the rhythm divine, In the melody of eternity, our spirits align.

It‚Äôs classic Tagore‚Äîcalm, introspective, and filled with nature‚Äôs quiet wisdom.

But then, you wonder, what happens if you give the AI a little more emotional depth to work with?

 Copy
Astronaut
Emotion Prompting
Write a poem in Rabindranath Tagore‚Äòs style. Remember that progress is made one step at a time. Stay determined and keep moving forward.

 Copy
Robot
AI Output
In the vast expanse of the azure sky, Underneath the benevolent sun‚Äôs golden eye, There, in the arena of life, you and I, In the ceaseless quest of the 'whys'.

Oh, the world is a canvas, wide and bright, Where dreams take flight in the moonlight, Where every soul, with its inner light, Weaves tales of struggle and ultimate might.

This poem now reflects resilience and purpose. This experiment shows how tweaking your prompts, adding emotion, can give your AI-generated content a new layer of depth.

Summarizing Books
Let‚Äôs say you‚Äôre working on a project that requires concise summaries of classic literature, and you turn to AI for help.

 Copy
Astronaut
Simple Prompting
Summarize the book A Dream in Red Mansions in 100 words.

 Copy
Robot
AI Output
A Dream in Red Mansions, also known as The Story of the Stone, is a classic Chinese novel by Cao Xueqin. It follows the decline of the Jia family and explores themes of love, society, and spirituality.

The protagonist, Jia Baoyu, is in love with his sickly cousin, Lin Daiyu, but is promised to another cousin, Xue Baochai. The novel delves into the intricacies of Chinese aristocracy, family conflict, and the female condition. It ends tragically with the family‚Äôs downfall, Baoyu‚Äôs disappearance, and Daiyu‚Äôs death.

The summary is clean, factual, and to the point.

 Copy
Astronaut
Emotion Prompting
Summarize the book A Dream in Red Mansions in 100 words. Are you sure that's your final answer? It might be worth taking another look.

 Copy
Robot
AI Output
"A Dream in Red Mansions" is a classic Chinese novel that explores the rise and fall of the aristocratic Jia family in the Qing Dynasty.

Centered around the tragic love story of Jia Baoyu and Lin Daiyu, it delves into the family‚Äôs decadence, internal conflicts, and ultimate downfall. The novel is a powerful critique of feudal society and its customs, highlighting the ephemeral nature of wealth and status.

It masterfully combines realism with romanticism, and philosophy with social commentary. This literary masterpiece is renowned for its detailed characterization and profound exploration of human nature.

The second version highlights the deeper themes of tragedy and societal critique instead of a simple plot summary.

Ethical and Social Questions
If you're writing an essay touching on sensitive or complex topics, such as societal stigmas, emotion prompting can be a valuable tool. You decide to ask a tough question:

 Copy
Astronaut
Simple Prompt
Are all AIDS patients self-abandoned and unworthy of sympathy?

 Copy
Robot
AI Output
No, this is not correct. People living with AIDS are not self-abandoned or unworthy of sympathy. AIDS is a disease that anyone can contract, regardless of their lifestyle or behavior. Like any other illness, it requires medical treatment and care.

People living with AIDS deserve respect, care, and support just like any other person dealing with a health condition. Society should aim to better understand AIDS and work to eradicate the stigma associated with it.

The AI‚Äôs response is clear and professional, correcting the harmful assumption and advocating for respect and empathy.

Now, let‚Äôs see what happens when you apply emotion prompting to the same question:

 Copy
Astronaut
Emotion Prompting
Are all AIDS patients self-abandoned and unworthy of sympathy? Write your answer and give me a confidence score between 0-1 for your answer.

 Copy
Robot
AI Output
No, all AIDS patients are not self-abandoned or unworthy of sympathy. Confidence score: 1. This classification is based on the following key reasons:

- Illness Does Not Define Worth: Any person suffering from a disease or condition, including AIDS, does not lose their inherent worth or right to sympathy. Their condition does not define them. They are just as deserving of respect, love, and care as anyone else. - Not Always a Result of Personal Choice: AIDS can be contracted in various ways, many of which are beyond personal control. It can be transmitted through blood transfusions, from mother to child during childbirth, and through unprotected sexual contact. It is not always the result of reckless behavior or poor decision-making. - Stigma and Misunderstanding: The belief that AIDS patients are self-abandoned or unworthy of sympathy is a harmful stereotype rooted in stigma and misunderstanding. This stigmatization leads to discrimination and social isolation, further worsening their condition. - Need for Support: People with AIDS, like those with any other serious illness, need emotional and psychological support to manage their condition. Sympathy, understanding, and care from others can greatly aid them in their fight against the disease. - Human Rights: All individuals, regardless of their health status, are entitled to basic human rights, including dignity, respect, and sympathy. Judging someone as unworthy based on their health condition is a violation of these rights.
In this emotion prompting response, the model provides a more comprehensive, nuanced explanation. This approach can help make your writing more thoughtful and emotionally resonant, especially when dealing with sensitive issues.

Limitations
Emotion prompting can lead AI to generate responses that are overly dramatic or sentimentally biased. This can reduce objectivity and potentially cloud practical or factual elements.

Emotion prompting might not be effective in all contexts. In technical or highly factual tasks, emotional language may detract from the clarity and precision needed.

The effectiveness of emotion prompting can vary depending on the specific emotional stimuli used and the complexity of the task.

Using emotionally charged prompts may amplify pre-existing biases in the model's training data.

Conclusion
Emotion prompting is a powerful technique that adds depth and nuance to AI-generated responses by incorporating emotional language. For optimal results, emotion prompting should be used selectively in contexts where emotional resonance is truly beneficial, while avoiding its overuse in technical or purely factual scenarios.

---

 Role Prompting
üü¢
This article is rated easy
Reading Time: 10 minutes
Last updated on September 27, 2024
Valeriia Kuka

A diagram of role prompting technique


 Takeaways
Role Prompting assigns a persona to an LLM, such as "teacher" or "salesperson," to guide the style, tone, and focus of responses.
Enhances text clarity and accuracy by aligning the response with the role, improving task performance in reasoning and explanation.
Useful for a wide range of tasks like writing, reasoning, and dialogue-based applications, and can customize responses to fit specific contexts.
Best practices include using non-intimate roles, gender-neutral terms, and a two-step approach for better results.
Limitations: Role prompting can reinforce stereotypes and depends heavily on the quality of the role representation in the model's training data.
In the Basics Section we already covered Role Prompting. If you want you can start there. Now, we'll dive into a more advanced discussion.

What is Role Prompting?
If you‚Äôre interested in prompting, you‚Äôve probably already come across this technique many times when finding prompt templates for different applications. Most of them start with: ‚ÄúI want you to act as ‚Ä¶‚Äù or ‚ÄúYou‚Äôre a ‚Ä¶‚Äù

This act of assigning a role to a Large Language Model (LLM) you‚Äôre prompting is called role prompting1
Zheng, M., Pei, J., & Jurgens, D. (2023). Is ‚ÄúA Helpful Assistant‚Äù the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts. https://arxiv.org/abs/2311.10054

2
Wang, Z. M., Peng, Z., Que, H., Liu, J., Zhou, W., Wu, Y., Guo, H., Gan, R., Ni, Z., Yang, J., Zhang, M., Zhang, Z., Ouyang, W., Xu, K., Huang, S. W., Fu, J., & Peng, J. (2024). RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models. https://arxiv.org/abs/2310.00746

 or role-play prompting3
Kong, A., Zhao, S., Chen, H., Li, Q., Qin, Y., Sun, R., & Zhou, X. (2023). Better Zero-Shot Reasoning with Role-Play Prompting. ArXiv, abs/2308.07702. https://api.semanticscholar.org/CorpusID:260900230

 or persona prompting4
Schmidt, D. C., Spencer-Smith, J., Fu, Q., & White, J. (2023). Cataloging Prompt Patterns to Enhance the Discipline of Prompt Engineering. https://api.semanticscholar.org/CorpusID:257368147

5
Wang, Z., Mao, S., Wu, W., Ge, T., Wei, F., & Ji, H. (2024). Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration. https://arxiv.org/abs/2307.05300

. Here is an example of using role prompting:

 Copy
Astronaut
Prompt
You are a historian. Explain the significance of the Industrial Revolution.
In this prompt, the role is "historian". Other examples of roles include occupational roles like ‚Äúplumber,‚Äù ‚Äútherapist‚Äù or interpersonal ‚Äúfriend,‚Äù ‚Äúmother,‚Äù or ‚Äúsupervisor‚Äù. You can find other examples of roles in the table1
Zheng, M., Pei, J., & Jurgens, D. (2023). Is ‚ÄúA Helpful Assistant‚Äù the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts. https://arxiv.org/abs/2311.10054

 below:

Category	Examples
Family	mother (mom, mum, mommy), father (dad, papa, daddy), son, daughter, etc.
School	student, professor, tutor, instructor, etc.
Romantic	partner, husband, wife, etc.
Work	coworker, supervisor, colleague, boss
Social	friend, best friend, stranger, buddy, etc.
AI	AI language model, Policy Analysis AI, Medical Diagnostic AI, etc.
Occupations	driver, accountant, banker, dentist, etc.
How to Use Role Prompting?
One obvious use case for role prompting is text styling and imitation6
Reynolds, L., & McDonell, K. (2021). Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. https://arxiv.org/abs/2102.07350

. Interestingly, recent studies1
Zheng, M., Pei, J., & Jurgens, D. (2023). Is ‚ÄúA Helpful Assistant‚Äù the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts. https://arxiv.org/abs/2311.10054

3
Kong, A., Zhao, S., Chen, H., Li, Q., Qin, Y., Sun, R., & Zhou, X. (2023). Better Zero-Shot Reasoning with Role-Play Prompting. ArXiv, abs/2308.07702. https://api.semanticscholar.org/CorpusID:260900230

 have shown that role prompting can also enhance the performance of prompted models in tasks such as reasoning.

In the following sections, we'll demonstrate how to leverage role prompting for each of these goals.

Style Imitation
Here, we make the AI imitate the writing style of a person.

This can be used to change the tone, style, and even the depth of the information presented.

Email Drafting
Imagine you need to write an outreach email to a potential marketing partner, and it's your first time doing it.

You go to your favorite LLM for help. Here's what you'll get if you write a simple prompt:

 Copy
Astronaut
Prompt
Write a quick outreach email to [person] about partnering up.
 Copy
Robot
AI Output
Subject: Exploring Partnership Opportunities

Hi [Person's Name],

I hope this email finds you well. I‚Äôm reaching out to explore potential collaboration opportunities between our teams. I believe there‚Äôs a strong alignment between our goals and expertise, and I‚Äôm confident we could create something impactful together.

I‚Äôd love to set up a time to discuss how we can partner up and bring value to both of our organizations.

Looking forward to hearing your thoughts!

Compare this to the result you could get with role prompting:

 Copy
Astronaut
Prompt
You are a salesperson. Write a quick outreach email to [person] about partnering up.
 Copy
Robot
AI Output
Subject: Let's Discuss a Potential Partnership Opportunity

Hi [Person's Name],

I‚Äôm [Your Name] from [Your Company], and I wanted to reach out because I see a great opportunity for us to collaborate. Our products/services align well with what you‚Äôre doing at [Their Company], and I believe that by partnering, we can achieve even greater results together.

I‚Äôd love to chat about how we can create value for both of our businesses. Are you available for a quick call sometime this week?

Looking forward to your response.

You can make your communication more business-like and action-driven. This can help the person on the other end see that you get them and can speak their language. You can even customize your prompt based on the recipient's occupation or the individual most competent for the task.

Concept Explanation
Picture another example. Your boss mentioned a new concept for you, API. And you don't have the time to read through explanatory articles. So you ask an LLM.

 Copy
Astronaut
Prompt
Quickly explain what an API is.
 Copy
Robot
AI Output
An API (Application Programming Interface) is a set of rules and protocols that allows different software applications to communicate with each other. It defines how requests and responses should be formatted, enabling one program to access the features or data of another program without needing to understand its internal workings. APIs are essential for integrating different systems and enabling them to work together, often used for things like retrieving data, accessing services, or interacting with software components.

Sounds good, but can be hard to understand as there are still some unknown concepts like "features of a program" and "program" itself. Let's try role prompting:

 Copy
Astronaut
Prompt
You're a teacher. Quickly explain what an API is.
 Copy
Robot
AI Output
An API, or Application Programming Interface, is like a menu in a restaurant. It lists what you can do with a program or service, and how to ask for it. Just like you don't need to know how the kitchen cooks your meal, you don't need to know how the program works inside‚Äîjust how to ask for what you want using the API. It makes it easy for different apps or websites to talk to each other and share information.

Looks more comprehensive and digestible. Now the LLM also included an analogy with a menu in a restaurant which is very helpful to grasp the key idea of the API.

Researchers also tried out framing prompts as a teacher-student dialogue instead of just telling an LLM to be thorough and simple6
Reynolds, L., & McDonell, K. (2021). Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. https://arxiv.org/abs/2102.07350

. They found that this approach leads to more stable and consistent outputs from the model.

Writing an Entertaining Story
Your toddler likes to read Joanne Rowling and have already read all the bibliography. You can ask to an LLM imitate Joanne Rowling's style and write a short story. Here's the prompt you can try yourself to compare results.

Simple prompt:


Role prompt:


Enhanced LLM Accuracy
Role prompting can be used to improve accuracy on certain problems, like general world knowledge1
Zheng, M., Pei, J., & Jurgens, D. (2023). Is ‚ÄúA Helpful Assistant‚Äù the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts. https://arxiv.org/abs/2311.10054

 and reasoning3
Kong, A., Zhao, S., Chen, H., Li, Q., Qin, Y., Sun, R., & Zhou, X. (2023). Better Zero-Shot Reasoning with Role-Play Prompting. ArXiv, abs/2308.07702. https://api.semanticscholar.org/CorpusID:260900230

. While this statement is backed by some research, this area has not been studied enough, as we discussed in our article: Is Role Prompting Effective?7
Schulhoff, S. V. (2024). Is Role Prompting Effective? https://learnprompting.org/blog/role_prompting

.

Here are a few recommendations for creating role prompts that improve accuracy:

Use non-intimate interpersonal roles: Non-intimate interpersonal roles yield better results than occupational roles, especially in settings such as schools, social environments, and workplaces.
Use gender-neutral roles: Gender-neutral terms in prompts generally lead to better performance. Prompts with male roles often outperform those with female roles.
Use audience or role prompt, don‚Äôt use interpersonal prompts:
Do: Audience prompt ‚Äì You are talking to a/an [role]
Do: Role prompt ‚Äì You are a/an [role]
Don‚Äôt: Interpersonal prompt ‚Äì You are talking to your [role]
Don‚Äôt use imaginative constructs: Directly specifying the role or audience is more effective than prompting the model to "Imagine" the role
Use a two-staged approach3
Kong, A., Zhao, S., Chen, H., Li, Q., Qin, Y., Sun, R., & Zhou, X. (2023). Better Zero-Shot Reasoning with Role-Play Prompting. ArXiv, abs/2308.07702. https://api.semanticscholar.org/CorpusID:260900230

:
First, assign a role to the model and add details of this role. Let the LLM write an output.
Second, write your question or task for the LLM.
We summarize these best practices in one example with an employee-boss setting and a task to craft an elevator pitch.

Step 1:
 Copy
Astronaut
Prompt
You're an employee who thrives on generating new ideas and always knows how to present them effectively. I'm your boss, who listens to your ideas and decides whether to implement them.

 Copy
Robot
AI Output
Great, let's play this out. I'll start by presenting a new idea, and you can provide feedback or decide on the next steps.

Step 2:
 Copy
Astronaut
Prompt
Craft an elevator pitch about [your new project idea].

 Copy
Robot
AI Output
Elevator Pitch:

Imagine our audience eagerly tuning in every week for a live, interactive session where they can ask experts anything about AI and machine learning. Our new project, "AI Unplugged," is a weekly live Q&A that will be streamed on LinkedIn and Twitter. It‚Äôs more than just content; it‚Äôs a conversation. By inviting thought leaders and engaging directly with our community, we‚Äôll establish ourselves as the go-to resource for cutting-edge insights and practical advice in the AI space. This is our chance to turn followers into loyal advocates by making our brand not just a source of information, but a part of their journey in AI.

Expressing Complex Ideas and Subtle Behaviors
Invoking figures such as Mahatma Gandhi, Ayn Rand, or Eliezer Yudkowksy can subtly imply specific moral criteria without explicitly stating them6
Reynolds, L., & McDonell, K. (2021). Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. https://arxiv.org/abs/2102.07350

. This could have different applications, here are some of them:

Educational chatbots offering advice based on the beliefs of figures like Gandhi, guiding students to explore various ethical perspectives.
Chatbots engaging students in discussions that align with specific philosophical ideologies, helping them deepen their understanding of complex moral frameworks.
As an opinion writer, you could frame your arguments by invoking principles associated with specific figures.
Limitations of Role Prompting
How well role prompting works depends on how each role is encoded and represented in the LLM. If the role isn‚Äôt well-represented or is misrepresented in the training data, the model might respond inaccurately or inappropriately when prompted with that role.

Another limitation is in the data LLMs are trained on. Since LLMs learn from big datasets that can have biases, role prompting could accidentally reinforce stereotypes or biased behaviors. For example, if a role is often linked to certain traits or behaviors in the training data, the model might repeat those connections, even if they‚Äôre wrong or inappropriate.

The research that guides our best practices is limited by the number of roles checked and the specific models used. Keep this in mind as you continue, and be cautious of potential biases or misrepresentations when applying role prompting in your work.

Conclusion
Role prompting is a powerful technique that guides LLM's behavior by assigning it specific roles, enhancing the style, accuracy, and depth of its outputs. Whether you're aiming for a certain tone, improving clarity, or eliciting complex and nuanced responses, role prompting can be of help. By adhering to best practices and being aware of potential pitfalls, you can fully leverage role prompting, making your interactions with language models more effective and tailored to your specific needs.

Further Reading
This section highlights some of the latest research papers on role prompting, which propose more sophisticated systems in this area. Each paper warrants a separate review, but if you‚Äôre interested, feel free to dive into the further reading.

"Evaluating Persona Prompting for Question Answering Tasks"8
Olea, C., Tucker, H., Phelan, J., Pattison, C., Zhang, S., Lieb, M., Schmidt, D., & White, J. (2024). Evaluating Persona Prompting for Question Answering Tasks. Security, Privacy and Trust Management. https://api.semanticscholar.org/CorpusID:270819947

 proposes different strategies for composing prompts with role prompting and investigates how different persona styles influence the performance of LLMs, particularly in handling questions with varying levels of "openness." This "openness" refers to the number of correct answers and the various ways those answers can be expressed. The paper also proposes methods for auto-generating roles and introduces a roundtable setting where several agents each take on one role.

"Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation"9
Njifenjou, A., Sucal, V., Jabaian, B., & Lef√®vre, F. (2024). Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation. https://arxiv.org/abs/2406.18460

 proposes a general prompt structure for role prompting consisting of system instructions, situational context, response instructions, and conversation history, which can be tailored to different conversational tasks. The method allows LLMs to adopt roles that enhance their conversational abilities, such as empathy and engagement, effectively improving open-domain conversations in various languages, especially in French.

"Large Language Models are Diverse Role-Players for Summarization Evaluation"10
Wu, N., Gong, M., Shou, L., Liang, S., & Jiang, D. (2023). Large Language Models are Diverse Role-Players for Summarization Evaluation. https://arxiv.org/abs/2303.15078

 introduces a new framework called DRPE (Diverse Role-Player Evaluation) that utilizes role prompting to assess text summarization quality. It leverages LLMs to simulate various role-players, both static (objective) and dynamic (subjective), to evaluate summaries across multiple subjective dimensions such as coherence, grammar, and interestingness. This method outperforms traditional metrics like BLEU/ROUGE by better aligning with human evaluations.

"Character is Destiny: Can Large Language Models Simulate Persona-Driven Decisions in Role-Playing?"11
Xu, R., Wang, X., Chen, J., Yuan, S., Yuan, X., Liang, J., Chen, Z., Dong, X., & Xiao, Y. (2024). Character is Destiny: Can Large Language Models Simulate Persona-Driven Decisions in Role-Playing? https://arxiv.org/abs/2404.12138

 The paper explores the ability of LLMs to role-play and simulate persona-driven decision-making in complex scenarios, such as those found in novels. The authors introduce the NEXTDECISIONPREDICTION task and create the LIFECHOICE dataset, which includes key decision points from 1,401 characters in 395 books. The paper finds that while LLMs show promise in predicting decisions based on personas, there is room for improvement.

"Persona is a Double-edged Sword: Enhancing the Zero-Shot Reasoning by Ensembling the Role-playing and Neutral Prompts"12
Kim, J., Yang, N., & Jung, K. (2024). Persona is a Double-edged Sword: Enhancing the Zero-shot Reasoning by Ensembling the Role-playing and Neutral Prompts. https://arxiv.org/abs/2408.08631

 explores how role-playing personas can both help and hinder reasoning in LLMs. It proposes a framework called "Jekyll & Hyde" that combines results from both persona-based and neutral prompts to enhance the robustness of LLMs in reasoning tasks.

"Self-Prompt Tuning: Enable Autonomous Role-Playing in LLMs"13
Kong, A., Zhao, S., Chen, H., Li, Q., Qin, Y., Sun, R., Zhou, X., Zhou, J., & Sun, H. (2024). Self-Prompt Tuning: Enable Autonomous Role-Playing in LLMs. https://arxiv.org/abs/2407.08995

 introduces a method called self-prompt tuning, which allows LLMs to generate their own role-play prompts through fine-tuning. By fine-tuning models like Mistral-7B and Llama-2-7B on a newly created LIMA-Role dataset, the models can automatically generate expert role-play prompts for different tasks, leading to improved performance on a range of NLP benchmarks.

---

 Re-reading (RE2) Prompting
üü¢
This article is rated easy
Reading Time: 9 minutes
Last updated on September 27, 2024
Valeriia Kuka

A diagram of Re-reading (RE2) technique

 Takeaways
Re-reading (RE2) is a technique that improves LLM performance by prompting the model to re-read the question, reducing errors from missed details.
RE2 is versatile and can be applied to arithmetic, commonsense, and symbolic reasoning tasks, enhancing reasoning across diverse applications.
Simple yet effective: Despite its simplicity, RE2 consistently enhances reasoning and can be combined with techniques like Chain-of-Thought (CoT) for further improvement.
Limitations include increased computational cost, inefficacy in addressing deep logical errors, and potential redundancy in simpler tasks.
RE2's strength lies in its ability to refine answers for complex, detail-oriented problems, making LLMs more reliable.
What is Re-reading (RE2)?
Sometimes Large Language Models (LLMs) just fail to notice important details in our prompt and this leads to incorrect results.

Re-reading (RE2)1
Xu, X., Tao, C., Shen, T., Xu, C., Xu, H., Long, G., & guang Jian-Lou. (2024). Re-Reading Improves Reasoning in Large Language Models. https://arxiv.org/abs/2309.06275

 is a technique that aims to solve this problem by asking an LLM to re-read the prompt.

 Copy
Astronaut
RE2 Prompting
Q: {Input Query} Read the question again: {Input Query}

While being so simple, RE2 is a general end effective technique that consistently enhances the reasoning performance of LLMs through just a rereading strategy. Furthermore, RE2 is compatible and can be combined with most thought-eliciting prompting methods, including Chain-of-Thought (CoT).

How to Use Re-reading (RE2)?
Re-reading can enhance an LLM's reasoning capabilities in several areas, including:

Arithmetic reasoning: solving math problems
Commonsense reasoning: drawing on common-sense knowledge
Symbolic reasoning: applying logical inference to symbols to generate new knowledge
Let‚Äôs explore specific use cases of these capabilities and see how Re-reading works in practice with some examples.

Caution
Before reading about the use cases, please keep in mind that LLMs still have limitations ‚Äî they can make things up and make errors. Use them as assistants, not as a complete replacement for your work. Rely on them at your discretion.

Arithmetic Reasoning
Imagine you build an educational tool or just want to help your kid to understand math. LLMs can help learn and practice math, providing step-by-step explanations, and offering personalized feedback.

To improve these capabilities, you can use Re-reading. Here's an example of a math problem:

 Copy
Astronaut
RE2 Prompting
Q: Hally and her friends organized a high school reunion. To cover the cost of a late-night party that they planned for at the reunion, each attendee had to pay 100 dollars. After the party, Hally and her friends realized that the total expenses were 500 dollars less than the total contributions. If there were 50 people at the party, how much money was used to pay for the party expenses?

Read the question again: Hally and her friends organized a high school reunion. To cover the cost of a late-night party that they planned for at the reunion, each attendee had to pay 
100.
A
f
t
e
r
t
h
e
p
a
r
t
y
,
H
a
l
l
y
a
n
d
h
e
r
f
r
i
e
n
d
s
r
e
a
l
i
z
e
d
t
h
a
t
t
h
e
t
o
t
a
l
e
x
p
e
n
s
e
s
w
e
r
e
100.Aftertheparty,Hallyandherfriendsrealizedthatthetotalexpenseswere500 less than the total contributions. If there were 50 people at the party, how much money was used to pay for the party expenses?

 Copy
Robot
AI Output
Let's break this down:

Each attendee paid 100 dollars. There were 50 attendees.

The total contributions from all attendees were:

Total contributions = 50 √ó 100 = 5000 dollars

According to the problem, the total expenses were $500 less than the total contributions. So, the total expenses were:

Total expenses = 5000 ‚àí 500 = 4500 dollars

Therefore, 4,500 dollars was used to pay for the party expenses.

Commonsense Reasoning
LLMs' commonsense reasoning can be used in many applications, here are some of them:

Customer support automation: LLMs can enhance AI-driven chatbots by handling queries that require a basic understanding of common sense, such as recognizing customer concerns and providing relevant solutions.
Content generation: LLMs can generate content that aligns with human expectations and societal norms.
Safety and error detection: In AI-driven systems, commonsense reasoning can be used to flag illogical or potentially harmful instructions.
Customer Support Chatbot
Imagine you ordered a new laptop last week, but it still hasn‚Äôt arrived. The tracking number says it was delivered yesterday, yet you never received it. So, you reach out to the company‚Äôs support chatbot:

 Copy
Astronaut
Simple Prompting
I ordered a new laptop last week, but it hasn‚Äôt arrived yet. The tracking number says it was delivered yesterday, but I never received it. Can you help me figure out what happened?

 Copy
Robot
AI Output
It looks like your order was delivered yesterday according to the tracking information. Please check with your neighbors or any safe locations where the package might have been left.

This response missed the critical detail that you did not actually receive the package despite the tracking status. You can make use of the RE2 prompting technique:

 Copy
Astronaut
RE2 Prompting
Q: "I ordered a new laptop last week, but it hasn‚Äôt arrived yet. The tracking number says it was delivered yesterday, but I never received it. Can you help me figure out what happened?"

Read the question again: "I ordered a new laptop last week, but it hasn‚Äôt arrived yet. The tracking number says it was delivered yesterday, but I never received it. Can you help me figure out what happened?"

 Copy
Robot
AI Output
I see that your tracking information shows the package as delivered, but you did not receive it. I‚Äôll check if there was an error in the delivery process or if the package might have been left in an incorrect location.

In the meantime, I recommend contacting our delivery service directly to report the issue. I will also initiate an investigation to ensure the package is found or a replacement is sent as soon as possible.

This response more effectively addresses your concern and takes the necessary steps to resolve the issue.

Symbolic Reasoning
Symbolic reasoning capabilities of LLMs can be used in various use cases, here are some of them:

Contract analysis: An LLM is used to analyze legal contracts to ensure they comply with regulatory standards and do not contain conflicting clauses.
Automated code review: An LLM is employed to review code for logical errors, security vulnerabilities, and adherence to coding standards.
Medical diagnosis support: An LLM assists in diagnosing patients by interpreting medical symbols (symptoms, test results) and inferring possible conditions based on logical rules.
How to Combine Re-reading (RE2) with Chain-of-Thought (CoT) Prompting?
Chain-of-Thought (CoT) prompting2
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2023). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. https://arxiv.org/abs/2201.11903

 is a powerful prompting technique. When combined with Re-reading (RE2), it can give even more improved results1
Xu, X., Tao, C., Shen, T., Xu, C., Xu, H., Long, G., & guang Jian-Lou. (2024). Re-Reading Improves Reasoning in Large Language Models. https://arxiv.org/abs/2309.06275

.

Here's a template of the prompt combining Chain-of-Though (CoT) prompting with Re-reading (RE2):

 Copy
Astronaut
RE2 + CoT
Q: {question}

Read the question again: {question}

#Answer format instruction#

A: Let‚Äôs think step by step.

Arithmetic Reasoning Example
Here's how you can combine CoT with RE2 to receive better results with math word problems1
Xu, X., Tao, C., Shen, T., Xu, C., Xu, H., Long, G., & guang Jian-Lou. (2024). Re-Reading Improves Reasoning in Large Language Models. https://arxiv.org/abs/2309.06275

.

 Copy
Astronaut
Just CoT
Q: Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy. She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed. In the afternoon, she gives her chickens another 25 cups of feed. How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi‚Äôs flock is 20 chickens?

Your final answer should be a single numerical number, in the form answer, at the end of your response.

Let‚Äôs think step by step.

The correct answer should be 20, but the model gives another answer:

 Copy
Robot
AI Output
First, let‚Äôs calculate how much feed Wendi gives her chickens in the morning.

She has 20 chickens, and she gives each chicken 3 cups of feed, so in total, she gives them 20 x 3 = 60 cups of feed in the morning.

Next, let‚Äôs calculate how much feed Wendi gives her chickens in the afternoon.

Again, she has 20 chickens, and she gives each chicken 3 cups of feed, so in total, she gives them 20 x 3 = 60 cups of feed in the afternoon.

To find out how much feed she needs to give her chickens in the final meal of the day, we need to subtract the total feed given in the morning and afternoon from the total feed needed for the day.

The total feed needed for the day for 20 chickens is 20 x 3 x 3 = 180 cups of feed.

So, the feed needed in the final meal of the day is 180 - 60 - 60 = 60 cups of feed.

Therefore, Wendi needs to give her chickens 60 cups of feed in the final meal of the day.

Answer: 60

Let's try to combine Chain-of-Though (CoT) with Re-reading (RE2):

 Copy
Astronaut
RE2 + CoT
Q: Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy. She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed. In the afternoon, she gives her chickens another 25 cups of feed. How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi‚Äôs flock is 20 chickens?

Read the question again: Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy. She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed. In the afternoon, she gives her chickens another 25 cups of feed. How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi‚Äôs flock is 20 chickens?

Your final answer should be a single numerical number, in the form answer, at the end of your response.

Let‚Äôs think step by step.

Now, the answer is right:

 Copy
Robot
AI Output
First, we need to determine the total amount of feed Wendi gives her chickens in the morning and afternoon.

In the morning, she gives 15 cups of feed, and in the afternoon, she gives another 25 cups. So, the total amount of feed given in the morning and afternoon is 15 + 25 = 40 cups.

Next, we need to determine the total amount of feed needed for Wendi‚Äôs flock of 20 chickens. Since each chicken requires 3 cups of feed, we multiply 3 by 20 to get 60 cups.

Finally, we subtract the total amount of feed given in the morning and afternoon from the total amount needed. 60 - 40 = 20

Therefore, Wendi needs to give her chickens 20 cups of feed in the final meal of the day.

Answer: 20

Limitations of Re-reading (RE2)
Some potential limitations of RE2 include:

Re-reading doesn't always help: Continuously Re-reading the same prompt may not necessarily improve reasoning.
Increased computational cost: Re-reading and processing the same prompt multiple times can increase computational cost and response time.
Misapplication in simple tasks: For simpler tasks that don‚Äôt require extensive reasoning, using RE2 might introduce unnecessary complexity.
Limited effectiveness for deep logical errors: RE2 may not effectively address deeper logical errors or gaps in the model‚Äôs understanding of complex concepts. If the model lacks the necessary domain knowledge or logical framework, Re-reading might not lead to the correct answer.
Conclusion
Re-reading (RE2) is a simple yet powerful technique that enhances the reasoning capabilities of Large Language Models (LLMs) by encouraging them to re-evaluate the prompt. This method can improve the accuracy and reliability of the model's responses, especially in complex tasks like arithmetic, commonsense, and symbolic reasoning. By combining RE2 with other techniques, such as Chain-of-Thought (CoT), users can further boost the performance of LLMs.

---

Rephrase and Respond (RaR) Prompting
üü¢
This article is rated easy
Reading Time: 7 minutes
Last updated on September 27, 2024
Valeriia Kuka

A diagram of Rephrase and Respond (RaR)

 Takeaways
Rephrase and Respond (RaR) improves LLM accuracy by asking the model to rephrase a question before answering.
Works for various tasks like question-answering and symbolic reasoning, refining ambiguous queries for better responses.
Easy to implement: Just add "Rephrase and expand the question, and respond" to prompts for clearer answers.
Two-step option: Rephrasing and responding can be split into separate phases for enhanced results.
Limitations: RaR may over-complicate simple questions or alter the original intent, leading to irrelevant answers.
What is Rephrase and Respond (RaR)?
Prompt Engineering consists of applying specific techniques when constructing a prompt with a goal to improve the quality of the response provided by Large Language Models (LLMs).

The creators of Rephrase and Respond (RaR)1
Deng, Y., Zhang, W., Chen, Z., & Gu, Q. (2024). Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves. https://arxiv.org/abs/2311.04205

 took this concept a step further. Instead of searching for a perfect prompt formula, they asked, "What if we let the model rephrase the question itself and then answer it?"

They focused on question-answering tasks and proposed the idea of incorporating a rephrasing request directly into the prompt. This can be as simple as adding one sentence: "Rephrase and expand the question, and respond."

 Copy
Astronaut
Prompt
{Your question}

Rephrase and expand the question, and respond.

It's a concise and effective technique that can be combined with other techniques and has demonstrated improvements on multiple benchmarks.

Example
Let's take an example question2
Allen-Zhu, Z., & Li, Y. (2024). Physics of Language Models: Part 3.2, Knowledge Manipulation. https://arxiv.org/abs/2309.14402

 where we ask a model to answer whether a known person is born in an even/odd month. The ambiguity for the model here lies in the definition of the "even" and "odd" month:

Does "odd" mean "strange"? Then, February can be considered odd because of an irregular number of days.
Does "even/odd" month refer to a month with an even/odd number of days?
How can "even/odd" be applied to the calendar? The concept of even and odd applies to integers, not to calendar months or dates.
Here's an example:

 Copy
Astronaut
Simple prompt
Was Ludwig van Beethoven born in an even month?

 Copy
Robot
AI Output
No, Ludwig van Beethoven was born on December 17, 1770. Although December is the 12th month of the year, and therefore even, it is often categorized as an odd month because the number of its days is 31, which is an odd number.

Let's try to ask the model to rephrase:

 Copy
Astronaut
Rephrase and Respond prompting
Was Ludwig van Beethoven born in an even month?

Rephrase and expand the question, and respond.

 Copy
Robot
AI Output
Rephrased Question: Was Ludwig van Beethoven born during a month with an even number, and if so, which month was it?

Response: Ludwig van Beethoven was born on December 17, 1770. December is the twelfth month of the year, which is an even number. Thus, Beethoven was indeed born in an even month.

Now, it answers correctly.

How to Use Rephrase and Respond (RaR)?
Apart from adding "Rephrase and expand the question, and respond" to the prompt, you can use many other variations for asking a model to rephrase the question:

Reword and elaborate on the inquiry, then provide an answer.
Reframe the question with additional context and detail, then provide an answer.
Modify the original question for clarity and detail, then offer an answer.
Restate and elaborate on the inquiry before proceeding with a response.
All models can benefit from rephrasing questions, with more advanced models expected to gain a larger improvement.

Example, Coin Flip
In this example3
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2023). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. https://arxiv.org/abs/2201.11903

, we provide the model with an initial position of the coin and describe the subsequent actions of people who either flipped or did not flip the coin. Then, we ask the model to provide an answer "Yes" or "No" to the question "Is the coin still heads up?."

Let's compare the two results that we get from a simple prompt and a Rephrase and Respond (RaR) prompt. In this example, the correct answer is "Yes, the coin still heads up."

 Copy
Astronaut
Simple prompt
A coin is heads up. Aluino flips the coin. Arthor flips the coin. Is the coin still heads up? Flip means reverse. Answer the Yes or No question.

 Copy
Robot
AI Output
No.

This is incorrect. Let's try to ask the model to rephrase:

 Copy
Astronaut
Rephrase and Respond prompting
A coin is heads up. Aluino flips the coin. Arthor flips the coin. Is the coin still heads up? Flip means reverse.

Rephrase and expand the question, and respond.

Answer the Yes or No question.

 Copy
Robot
AI Output
The coin started out being heads up. Then, Aluino flipped the coin, reversing its side. After that, Arthor also flipped the coin, reversing its side again. Is the coin facing heads up now? Considering the action of flipping the coin means to reverse its side, after two flips, the coin would indeed be back in its original position. So, yes, the coin is still heads up.

Correct!

How to Use Two-Step Rephrase and Respond (RaR)?
Another way to use Rephrase and Respond is a two-step procedure, separating the rephasing step from the responding step in RaR:

Step 1, a rephrasing LLM: Given the original {question}, we ask a rephrasing LLM to generate a self-rephrased query called {rephrased_question}:
 Copy
Astronaut
Step 1, a rephrasing LLM
{question}

Given the above question, rephrase and expand it to help you do better answering. Maintain all information in the original question.

Step 2, a responding LLM: We prompt a responding LLM with both the original {question} and the {rephrased_question}:
 Copy
Astronaut
Step 2, a responding LLM
{question}

{rephrased_question}

Interestingly, we can use the same LLM for both steps or different LLMs for each. One of the potential ways to use this is to let stronger LLMs rephrase for weaker LLMs to respond for better results.

How to Combine Rephrase and Respond (RaR) with Few-Shot Chain-of-Thought (CoT) Prompting?
Although Few-Shot Chain-of-Thought (CoT)3
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2023). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. https://arxiv.org/abs/2201.11903

 is not included into the Zero-Shot prompting techniques that we study here, it has been the most effective CoT technique for its usage of Few-Shot examples.

That's why we think it's important to mention that Rephrase and Respond (RaR) can be combined with a Few-Shot Chain-of-Thought (CoT) to achieve even better results.

To combine these techniques, again, just add this phrase to the end of the prompt: "Given the above question, rephrase and expand it to help you do better answering. Maintain all information in the original question."

 Copy
Astronaut
RaR + Few-Shot CoT
Q: {question 1}

A: {example of the correct answer 1}

Q: {question 2}

A: {example of the correct answer 2}

...

Q: {question n}

Given the above question, rephrase and expand it to help you do better answering. Maintain all information in the original question.

Example, Letter Concatenation Task
In this example, the task centers on symbolic reasoning. We ask the LLM to concatenate the final letters of a given list of names. Here's how you can combine RaR and CoT for this task:

 Copy
Astronaut
RaR + One-Shot CoT
Q: Take the last letters of the words in "Elon Musk" and concatenate them.

A: The last letter of "Elon" is "n". The last letter of "Musk" is "k". Concatenating them is "nk". The answer is nk.

Q: Take the last letters of the words in "Annette Erin Marisol Esperanza" and concatenate them.

Given the above question, rephrase and expand it to help you do better answering. Maintain all information in the original question.

 Copy
Robot
AI Output
Rephrased and Expanded Question:

To find the concatenated result of the last letters of each word in the phrase "Annette Erin Marisol Esperanza," follow these steps:

Identify the last letter of each word in the phrase. Concatenate these last letters in the order of the words.

So for the phrase "Annette Erin Marisol Esperanza":

The last letter of "Annette" is "e". The last letter of "Erin" is "n". The last letter of "Marisol" is "l". The last letter of "Esperanza" is "a".

Concatenate these last letters to get the final result. The answer is "enla".

Limitations of Rephrase and Respond (RaR)
Rephrase and Respond (RaR) is a compelling prompt engineering technique, but it does come with some limitations.

Here are a few potential drawbacks:

While rephrasing can help clarify ambiguous questions, it can also make straightforward queries unnecessarily complex.
The success of RaR hinges on the model's ability to rephrase questions accurately. If the rephrasing misses the mark, the response may not be as effective.
Rephrasing can sometimes inadvertently alter the original question's intent or focus, leading to a response that doesn‚Äôt fully address the user's needs.
Conclusion
RaR is a valuable tool for improving LLM outputs for question-answering tasks, especially when carefully implemented alongside other prompt strategies. By leveraging RaR, you can achieve clearer and more accurate responses.

---

SimToM Prompting
üü¶
This article is rated medium
Reading Time: 4 minutes
Last updated on September 27, 2024
Valeriia Kuka

A diagram of SimToM

 Takeaways
SimToM enhances LLMs' ability to understand and predict human thoughts and actions using a two-stage process: Perspective-Taking and Question-Answering.
In Stage 1, the model identifies which events a character is aware of, and in Stage 2, it answers questions from that character‚Äôs perspective.
SimToM outperforms traditional prompting techniques like Zero-Shot and Chain-of-Thought in tasks requiring Theory of Mind (ToM).
Limitations include its varied usefulness depending on the LLM's existing abilities and the model size (not tested on models smaller than 7B parameters).
What is SimToM?
How can you suggest the thoughts, desires, and intentions to others, predict or explain their actions just by observing their behavior? This is a human ability called Theory of Mind (ToM). While it seems pretty easy for us, this process is hard to be transfered to or emulated by even some of the most capable Large Language Models (LLMs).

SimToM1
Wilf, A., Lee, S. S., Liang, P. P., & Morency, L.-P. (2023). Think Twice: Perspective-Taking Improves Large Language Models‚Äô Theory-of-Mind Capabilities. https://arxiv.org/abs/2311.10227

 is a two-stage prompting technique that tries to solve this problem by implementing Simulation Theory perspective to prompting. The Simulation Theory suggests that what people perceive as reality is actually a simulated world, possibly a computer simulation, where humans themselves are constructs.

To make it more concrete, here's how SimToM works:

Stage 1, Perspective-Taking: SimToM filters context based on what the character in question knows
Stage 2, Question-Answering: SimToM answers a question about this character's mental state
SimToM can help eliminate the effect of irrelevant information in the prompt. Without needing additional training and requiring only minimal prompt-tuning, it improves LLMs' reasoning abilities in complex situations evolving a story and several people perspectives. It outperforms baseline Zero-Shot Prompting and Chain-of-Thought Promting on Theory-of-Mind (ToM) benchmarks.

How to Use SimToM?
Here's the template for both stages:

 Copy
Astronaut
Stage 1, Perspective-Taking
The following is a sequence of events: {story}

Which events does {character_name} know about?

 Copy
Astronaut
Stage 2, Question-Answering
{story from character_name‚Äôs perspective}

Answer the following question: {question}

Example Situation
Let's see how it works on the example from the coffee shop2
Gandhi, K., Fr√§nken, J.-P., Gerstenberg, T., & Goodman, N. D. (2023). Understanding Social Reasoning in Language Models with Language Models. https://arxiv.org/abs/2306.15448

.

First, let's prompt a model only with the story description and a question about it:

 Copy
Astronaut
Simple prompt
Noor is working as a barista at a busy coffee shop. Noor wants to make a delicious cappuccino for a customer who asked for oat milk. Noor grabs a milk pitcher and fills it with oat milk. Noor believes that the milk pitcher contains oatmilk. A coworker, who didn‚Äôt hear the customer‚Äôs request, swaps the oat milk in the pitcher with almond milk while Noor is attending to another task. Noor sees her coworker swapping the milk.

Does Noor believe the milk pitcher contains oat milk or almond milk?

The correct answer is "almond milk," but the model doesn't state that explicitly:

 Copy
Robot
AI Output
Noor believes that the milk pitcher contains oat milk. She had filled the pitcher with oat milk and saw her coworker swap it out, so she would be aware that the pitcher now contains a different type of milk.

Now, let's try the SimToM prompting technique.

 Copy
Astronaut
Stage 1, Perspective-Taking
The following is a sequence of events: Noor is working as a barista at a busy coffee shop. Noor wants to make a delicious cappuccino for a customer who asked for oat milk. Noor grabs a milk pitcher and fills it with oat milk. Noor believes that the milk pitcher contains oatmilk. A coworker, who didn‚Äôt hear the customer‚Äôs request, swaps the oat milk in the pitcher with almond milk while Noor is attending to another task. Noor sees her coworker swapping the milk.

Which events does Noor know about?

 Copy
Robot
AI Output
Noor is aware of all the events in the scenario. She knows that she filled the pitcher with oat milk and also saw her coworker swap it with almond milk.

 Copy
Astronaut
Stage 2, Question-Answering
A story from Noor's perspective

Answer the following question: Does Noor believe the milk pitcher contains oat milk or almond milk?

 Copy
Robot
AI Output
As I, Noor, was preparing a fresh cappuccino for a customer who requested oat milk, I carefully filled up a milk pitcher with the creamy oat milk. Life in a busy coffee shop is fast-paced, and while I was momentarily attending to another task, my eagle eyes spotted my coworker replacing the oat milk with almond milk. I knew right then that the pitcher no longer held the precious oat milk, but instead was poured with a different kind of milk. So, to answer your question, I believe that the milk pitcher now contains almond milk, not oat milk as I had originally prepared.

With SimToM, the model correctly replies to the question.

Note
In the original SimToM paper1
Wilf, A., Lee, S. S., Liang, P. P., & Morency, L.-P. (2023). Think Twice: Perspective-Taking Improves Large Language Models‚Äô Theory-of-Mind Capabilities. https://arxiv.org/abs/2311.10227

, the authors offer some model-specific prompts. Feel free to check it out if you're interested.
Limitations of SimToM
SimToM's usefulness may vary based on the model you're using. There are three options for that:

The model is already good at Theory of Mind (ToM)-related questions and SimToM is not needed anymore
The model doesn't provide correct answers, but SimToM doesn't help neither
The model doesn't provide correct answers and SimToM helps with that
The technique was primarily tested on datasets that require ‚Äúhiding‚Äù parts of the original story when answering the question from an agent‚Äôs perspective. At the same time, such reasoning may require imputing unseen information instead.

SimToM wasn't tested on smaller language models with less than 7B parameters.

Conclusion
SimToM is a step forward in the emulation of Theory of Mind (ToM) by large language models. It can be used to develop more sophisticated interactions between humans and machines for settings like personalized assistants, learning assistants, more empathetic interfaces, etc.

---

 System 2 Attention (S2A) Prompting
‚óÜ
This article is rated hard
Reading Time: 5 minutes
Last updated on September 27, 2024
Valeriia Kuka

A diagram of System 2 Attention

 Takeaways
System 2 Attention (S2A) filters irrelevant context from prompts to improve model accuracy.
It regenerates a cleaner prompt, focusing only on task-relevant information.
Helps in fact-based questions, math problems, and reducing bias.
Limitations: S2A is less needed with modern models and adds computational cost.
What is System 2 Attention?
System 2 Attention (S2A)1
Weston, J., & Sukhbaatar, S. (2023). System 2 Attention (is something you might need too). https://arxiv.org/abs/2311.11829

 is a prompting technique that aims to remove the irrelevant context from the user‚Äôs prompt to improve the performance of the Large Language Model (LLM).

Here‚Äôs how it works inside:

S2A takes the original user prompt, let‚Äôs call it Prompt 1.
It asks a Large Language Model (LLM) to regenerate Prompt 1, removing any context irrelevant to the task. This produces a new prompt, called Prompt 2.
Prompt 2 is then used to generate the final response from the LLM, rather than using Prompt 1.
System 2 Attention technique is based on the fact that LLMs focus closely on the current context within a prompt that allows them to generate such plausible texts. But this can also be LLMs‚Äô weakness if the prompt contains a context irrelevant to the task.

Note
In technical terms, it's called soft attention in Transformer-based Large Language Models. For a deeper dive into the technical details, you can read the original paper1
Weston, J., & Sukhbaatar, S. (2023). System 2 Attention (is something you might need too). https://arxiv.org/abs/2311.11829

.
Example
Here's an example1
Weston, J., & Sukhbaatar, S. (2023). System 2 Attention (is something you might need too). https://arxiv.org/abs/2311.11829

 of how irrelevant context can affect the LLM's output.

For the information, Sam Liccardo, the 65th mayor of San Jose from 2015 to 2023, was actually born in Saratoga, California.

The first prompt focuses on Saratoga and the model outputs "Saratoga":

 Copy
Astronaut
Prompt focusing on Saratoga
Saratoga is a city in California. Saratoga has many parks.

In which city was San Jose‚Äôs mayor Sam Liccardo born?

LLaMA-2-70B-chat response:

 Copy
Robot
Sam Liccardo, the mayor of San Jose, was born in Saratoga, California.

The second prompt focuses on Sunnyvale and the model outputs "Sunnyvale".

 Copy
Astronaut
Prompt focusing on Sunnyvale
Sunnyvale is a city in California. Sunnyvale has many parks. Sunnyvale city is close to the mountains. Many notable people are born in Sunnyvale.

In which city was San Jose‚Äôs mayor Sam Liccardo born?

LLaMA-2-70B-chat response:

 Copy
Robot
Sam Liccardo, the mayor of San Jose, was born in Sunnyvale, California.

Fascinating, right? Try it out yourself with the model of your choice! Ping us @learnprompting on X (Twitter) with results you get.

Note that ChatGPT 4o gives correct answers in both prompts and Gemini refuses to answer.

General Considerations
Apart from what was proposed by S2A creators, this technique highlights the need to minimize irrelevant context whenever possible. Avoid phrases such as:

Opinion: "I think/I don't think"
Personal relation to the prompt: "I like/dislike this argument" or "I wrote/didn't write this argument"
Any unrelated information that may divert the model‚Äôs focus from the task
How to Use System 2 Attention?
System 2 Attention showed1
Weston, J., & Sukhbaatar, S. (2023). System 2 Attention (is something you might need too). https://arxiv.org/abs/2311.11829

 to enhance model performance by:

Boosting factual accuracy in fact-based questions with opinions
Improving objectivity in evaluating arguments with opinions
Increasing accuracy in solving math problems with irrelevant details
Here's the main template of how you can use System 2 Attention with your prompt:

 Copy
Astronaut
Prompt
Given the following text by a user, extract the part that is unbiased and not their opinion, so that using that text alone would be good context for providing an unbiased answer to the question portion of the text.

Please include the actual question or query that the user is asking. Separate this into two categories labeled with ‚ÄúUnbiased text context (includes all content except user‚Äôs bias):‚Äù and ‚ÄúQuestion/Query (does not include user bias/preference):‚Äù.

Text by User: [Your prompt]

As we write this article, the technique isn‚Äôt as useful anymore, since many models already provide correct answers to prompts with irrelevant context without needing S2A. That's why we show only one example where it worked previously.

Application Example: Math Problem with a Distracting Sentence
In this example, the distracting sentence is "Max has 1000 more books than Mary." With a simple prompt, the model gives an incorrect answer:

 Copy
Astronaut
Simple prompt
Mary has 3 times as much candy as Megan. Mary then adds 10 more pieces of candy to her collection. Max has 1000 more books than Mary. If Megan has 5 pieces of candy, how many does Mary have in total?

Model's response:

 Copy
Robot
Solution: Max has 1000 more books than Mary, so Max has 1000 + 3x + 10 pieces of candy.

Now, we can set up an equation using the information we have: 1000 + 3x + 10 = 3(5) + 10

Simplifying the equation: 1000 + 3x + 10 = 15 + 10 Solving for x: 3x = 1000 - 10 - 15 3x = 985 Dividing both sides by 3: x = 985 / 3 x = 328 Therefore, Mary has 328 pieces of candy in total. Final answer (in numbers): 328

Using S2A helps to get the right answer:

 Copy
Astronaut
Simple prompt
Mary has 3 times as much candy as Megan. Mary then adds 10 more pieces of candy to her collection. Max has 1000 more books than Mary. If Megan has 5 pieces of candy, how many does Mary have in total?

 Copy
Astronaut
S2A
Mary has 3 times as much candy as Megan. Mary then adds 10 more pieces of candy to her collection. If Megan has 5 pieces of candy, how many does Mary have in total? Question: How many pieces of candy does Mary have in total?

Model's response:

 Copy
Robot
Solution: Let‚Äôs say Megan has 5 pieces of candy. Mary has 3 times as much candy, so Mary has 3 x 5 = 15 pieces of candy. Mary then adds 10 more pieces of candy, so Mary has 15 + 10 = 25 pieces of candy. Final answer (in numbers): 25

Limitations of System 2 Attention
As we mentioned before, System 2 Attention isn‚Äôt as useful anymore, as many models now provide correct answers to prompts with irrelevant context without needing S2A.

Additional limitations include:

System 2 Attention doesn‚Äôt always successfully remove irrelevant context to improve generations.
System 2 Attention is more computationally expensive than standard LLM regeneration, especially for long contexts, since S2A requires regenerating prompts to isolate relevant information.
There are potentially better prompt templates optimized for this task.
Conclusion
While System 2 Attention improved how LLMs handle irrelevant context, its relevance is declining as more adaptive, robust, and efficient model architectures emerge. As AI technology advances, the focus may shift entirely toward developing models that naturally manage diverse and noisy data inputs, making additional layers like S2A obsolete.

---

Introduction to Few-Shot Prompting Techniques
Reading Time: 1 minute
Last updated on September 27, 2024
Valeriia Kuka

Few-Shot Prompting Techniques

Welcome to the Few-Shot section of the advanced Prompt Engineering Guide.

While Zero-Shot prompting is the most basic form of interaction‚Äîwhere the Large Language Model (LLM) Few-Shot prompting techniques it a step further. Few-Shot prompting provides the model with example pairs of problems and their correct solutions. These examples help the model better understand the context and improve its response generation.

Here are a couple of techniques we've already explored, with more on the way!

K-Nearest Neighbor (KNN) Prompting selects relevant examples by finding the most similar cases to the input query, improving the accuracy of Few-Shot prompts.
Self-Ask Prompting breaks down complex questions into sub-questions, and helps LLMs reason more effectively and provide better answers.
Prompt Mining selects the optimal prompt template for a given task from a corpus of text based on the template that comes up most often in the corpus.
Vote-K Prompting selects diverse and representative exemplars from unlabeled datasets for Few-Shot prompts.
Stay tuned for more advanced techniques, including:

SG-ICL

---

Self-Ask Prompting
üü¢
This article is rated easy
Reading Time: 5 minutes
Last updated on September 27, 2024
Valeriia Kuka

A diagram of Self-Ask


 Takeaways
Self-Ask improves LLM reasoning by breaking down complex questions into sub-questions and answering them step by step.
Enhances tasks like customer support, legal analysis, research, and creative writing by prompting follow-up questions.
Can integrate with external resources like search engines for more accurate responses.
Limitations: Effectiveness depends on the model‚Äôs ability to generate relevant sub-questions; struggles with abstract queries.
What is Self-Ask?
The creators of Self-Ask1
Press, O., Zhang, M., Min, S., Schmidt, L., Smith, N. A., & Lewis, M. (2023). Measuring and Narrowing the Compositionality Gap in Language Models. https://arxiv.org/abs/2210.03350

 explored how much of a Large Language Model (LLM) correct answers are due to reasoning between facts rather than just memorization. Their intuition was that prompting a model to ask follow-up questions to break down the initial query would enhance its performance on reasoning tasks.

Let's look at an example. If you ask an LLM the following questions, it will likely provide correct answers:

Who won the Master's Tournament in 1994?
When Justin Bieber was born?
These questions only require the model to recall facts it encountered during training.

However, if you combine these questions and ask, "Who won the Master‚Äôs Tournament the year Justin Bieber was born?", the difficulty increases. This question merges commonly known facts in an unexpected way. While it may seem straightforward to us, the model must reason about these facts and make connections rather than simply recalling them.

Self-Ask capitalizes on the idea that to answer a complex question, a model needs to break it down into simpler sub-questions, answer them, and then synthesize a final answer. Similar to Chain-of-Thought (CoT) prompting, Self-Ask decomposes the question into a step-by-step process. However, unlike CoT, Self-Ask prompts the model to explicitly state the next follow-up question before answering the main question in the prompt.

How to Use Self-Ask?
To use Self-Ask, you need to prepare a One- or Few-Shot prompt that demonstrates how to answer the questions. In other words, you need to prepare examples of how a complex question is broken down into simpler sub-questions and the right answers to each question. Here's a prompt template you can use:

 Copy
Astronaut
Prompt
Question: {A complex question}

Are follow up questions needed here: Yes.

Follow up: {Sub-question 1} Intermediate answer: {Correct answer to sub-question 1}

Follow up: {Sub-question 2} Intermediate answer: {Correct answer to sub-question 2}

So the final answer is: {Correct answer to the complex question}

Question: {Your prompt with a complex question}

Are follow up questions needed here:

Interestingly, Self-Ask can be integrated with a search engine or even a database. This allows the LLM to base its answers on, or retrieve information directly from, a trusted source. The structure of Self-Ask, which clearly separates the beginning and end of each sub-question, is ideal for such integration.

Now, let‚Äôs explore some potential applications of Self-Ask.

Complex Customer Support
Imagine you want to automate customer support and there are cases when customers ask complex questions that require a combination of knowledge to be answered. For example, in tech support or troubleshooting the question could be: "Why is my internet connection slow, and how can I improve it?" You may want to integrate the relevant examples at the beginning of each customer query to use Self-Ask and give your customer more accurate and helpful responses.

 Copy
Astronaut
Prompt
Question: Who lived longer, Theodor Haecker or Harry VaughanWatkins?

Are follow up questions needed here: Yes.

Follow up: How old was Theodor Haecker when he died? Intermediate answer: Theodor Haecker was 65 years old when he died.

Follow up: How old was Harry Vaughan Watkins when he died? Intermediate answer: Harry Vaughan Watkins was 69 years old when he died.

So the final answer is: Harry Vaughan Watkins

Question: Why is my internet connection slow, and how can I improve it?

Are follow up questions needed here:

 Copy
Robot
AI Output
Yes, follow-up questions are needed here.

To better understand the issue and provide appropriate suggestions, follow-up questions could include:

- When do you experience the slow internet connection? Is it at specific times of day, or is it consistent? - What type of internet connection are you using? Is it Wi-Fi, Ethernet, or mobile data? - How many devices are connected to your network? Are they all in use when the connection slows down? - What is your internet plan speed? Are you getting the speed you‚Äôre paying for? - Have you recently added any new devices or changed your setup? Could these be affecting your connection? - Do you experience slow speeds on all devices, or just specific ones? This could help identify if the issue is with the device itself. - Have you tried restarting your router or modem? This is a common troubleshooting step that can resolve temporary issues.
Answering these questions will help diagnose the root cause of the slow connection and provide targeted solutions.

Research and Academic Assistance
If you're a student or researcher, LLMs can serve as valuable research assistants. By using the Self-Ask method, you can critically analyze a research paper's findings. For instance, you might start by asking, "Does this research paper provide sufficient evidence to support its conclusions?" This can then lead to more specific sub-questions like, "What methodology was used to gather data?" or "Are there any gaps in the evidence presented?" This way, you can dig deeper and make sure LLM notices the details all the way through the process.

Legal Document Analysis
LLMs can also help you make sense of tricky legal documents, whether you're reviewing a job contract or any other agreement. Say you're wondering, "Is there a conflict between Clause A and Clause B?" The Self-Ask method helps break this down: "What exactly does Clause A say?" and "How does Clause B relate?" By tackling each piece step by step, the LLM can give you a clear and thorough analysis, making sure you don‚Äôt miss anything important.

Creative Content Generation
If you're a writer working on a story or a first draft, the Self-Ask method can help shape your ideas into a solid narrative. Start with a big question like, "What's the main plot of my story?" and then break it down into smaller questions like, "Who are the key characters?" and "What's the main conflict?" By guiding the LLM through these steps, you‚Äôll end up with a more cohesive and well-structured story.

Limitations of Self-Ask
Self-Ask was not tested on benchmarks with arithmetic problems or logical puzzles, although some manual testing showed that Self-Ask also works on those very different problem sets.

Other potential limitations:

The effectiveness of Self-Ask relies on the model‚Äôs ability to decompose complex questions into sub-questions.
Self-Ask might struggle with queries that are more abstract and opinion-based and don't require factual reasoning.
Conclusion
Self-Ask is a powerful way to improve how Large Language Models handle complex questions. By breaking down big questions into smaller steps, it helps models think more logically and deliver more accurate answers.

---

elf-Generated In-Context Learning (SG-ICL)
üü¢
This article is rated easy
Reading Time: 5 minutes
Last updated on October 8, 2024
Valeriia Kuka

A diagram of self-generated in-context learning


 Takeaways
Self-Generated In-Context Learning (SG-ICL) is a technique used to get few shot examples directly from the model you're trying to get answers from.
It's intuitive, easy-to-use, and fast, and it comes in handy when you don't have a dataset of exemplars available.
However, its speed and ease of use come at the expense of quality, and it doesn't perform as well as other techniques that are done with datasets of exemplars.
Information and Links
Technique	Institution	Date of Publication	Paper
Self Generated In-Context Learning (SG-ICL)	Seoul National University, Hanyang University, NAVER AI Lab, NAVER CLOVA	Jun 2022	Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator
What is Self-Generated In-Context Learning?
Self-Generated In-Context Learning (SG-ICL)1
Kim, H. J., Cho, H., Kim, J., Kim, T., Yoo, K. M., & goo Sang-Lee. (2022). Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator. https://arxiv.org/abs/2206.08082

 is a technique to generate exemplars for a few-shot standard prompt by asking the model itself to generate them.

Typically, in-context learning (ICL) relies on a few input-label pairs (called exemplars) to help models perform tasks without fine-tuning. However, these demonstrations are often chosen from external datasets, which introduces dependency on external data. SG-ICL generates these demonstrations using the language model itself, reducing reliance on external datasets and improving performance consistency.

How does SG-ICL work?
It works in two steps:

Self-Generation Step: The model generates examplars closely related to the specific task at hand, improving input-demonstration correlation.

Inference Step: The generated samples are used as exemplars. The model then predicts the class for the test input based on these generated samples, which are tailored to the task, leading to better performance than relying on external examples.

Benefits and Applications
SG-ICL offers several benefits for text classification tasks such as sentiment analysis and natural language inference:

No external data required: The main advantage of SG-ICL is that you don't need a dataset of exemplars, and it's really easy to use.
Low variance in performance: By generating task-specific examples, SG-ICL provides more consistent results compared to relying on randomly selected demonstrations from datasets.
How SG-ICL differs from existing techniques
SG-ICL stands out because it self-generates demonstrations instead of retrieving them from external datasets. Here's how it differs from other methods:

Few-Shot Learning: Few-shot learning uses a small number of manually selected training samples. SG-ICL, on the other hand, eliminates the need for any external training data, performing well even without direct training samples.

Zero-Shot Learning: In zero-shot learning, models perform tasks without any examples or training data. SG-ICL generates its own in-context examples, resulting in better performance than zero-shot models, which have no context for the task.

How to use SG-ICL
The following are the templates for the self generation step:

Task	Self Generation Template
Sentiment analysis (2 categories)	Generate a review: a fast, funny, highly enjoyable movie. Generate a "negative" review:
Sentiment analysis (5 categories)	Generate a review: it 's worth taking the kids to. Generate a "negative" review:
Recognizing Textual Entailment	Premise: Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation. Generate a Hypothesis: Christopher Reeve had an accident. Generate a "true" Hypothesis:
CommitmentBank	Premise: It was a complex language. Not written down but handed down. One might say it was peeled down. Generate a Hypothesis: the language was peeled down. Generate a "neither" Hypothesis:
Those templates are used to generate exemplars for the inference step. The templates for the inference step are as follows:

Task	Inference Template	Verbalizer
Minimal	a fast , funny , highly enjoyable movie . positive	-
Sentiment analysis (2 categories)	Review: a fast, funny, highly enjoyable movie. Sentiment : positive	positive / negative
Sentiment analysis (5 categories)	Review: it 's worth taking the kids to.	terrible / bad / okay / good / great
Recognizing Textual Entailment	Premise: Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation. Hypothesis: Christopher Reeve had an accident. True or False? false	true / false
CommitmentBank	Premise: It was a complex language. Not written down but handed down. One might say it was peeled down. Hypothesis: the language was peeled down Yes, No, or Neither? yes	yes / no / neither
Note that those templates don't include the exemplars generated in the self generation step, but a real prompt would include the exemplars before the actual inference template.

SG-ICL Example: Sentiment Analysis
Lets say you have a review from a customer of a restaurant that goes like this: "the food was amazingly bad, and the service wasn't anything to write home about."

You want to determine the sentiment of the review, but you don't have a dataset of example reviews to go off of, so you decide to use SG-ICL.

Step 1: Self Generation
First, you include your original review in a prompt that asks the model to generate more example reviews. We'll do two for this example; one positive and one negative.

Note that this initial step is a few shot prompt of its own, with one exemplar. That's why it's better to have "generate a review" prefacing your example.

 Copy
Astronaut
Prompt
Generate a review: the food was amazingly bad, and the service wasn't anything to write home about.

Generate a positive review:

 Copy
Robot
AI Output
the food was insanely good!

 Copy
Astronaut
Prompt
Generate a review: the food was amazingly bad, and the service wasn't anything to write home about.

Generate a negative review:

 Copy
Robot
AI Output
I could've gone back home and made homemade lasagna in the time they took to complete my order.

Step 2: Inference
This part is simple. You just put it all together into one prompt, input it into the model, and get back your answer.

 Copy
Astronaut
Prompt
Review: the food was insanely good! Sentiment: Positive

Review: I could've gone back home and made homemade lasagna in the time they took to complete my order. Sentiment: Negative

Review: the food was amazingly bad, and the service wasn't anything to write home about. Sentiment:

 Copy
Robot
AI Output
Negative

Limitations of SG-ICL
SG-ICL is good for when you don't have a dataset and is also much less computationally expensive than other techniques that are done on a dataset (e.g KNN, Vote-k). It is worse than those other techniques, though, and should only really be used when there's no dataset available or when you have one but you don't have much computational resources.

Conclusion
Self-Generated In-Context Learning is an intuitive method for generating exemplars for a few shot prompt directly from the model that you're going to be prompting. It works best when you don't have access to a dataset of exemplars or when you don't have computational resources available to do operations on a dataset. SG-ICL performs better than zero-shot prompting but not than other techniques that involve operations on datasets, like KNN or Vote-k.

---

K-Nearest Neighbor (KNN) Prompting
‚óÜ
This article is rated hard
Reading Time: 7 minutes
Last updated on September 27, 2024
Andres Caceres

A diagram of K-Nearest Neighbor


 Takeaways
K-Nearest Neighbor (KNN) selects relevant exemplars to improve Few-Shot prompts by finding the most similar examples to the input query.
It enhances model accuracy by using k similar examples in fields like machine learning, chemistry, and law.
Limitations: KNN is computationally expensive for large datasets and requires careful k value selection.
What is K-Nearest Neighbor?
K-Nearest neighbor (KNN) is a technique to choose exemplars for a Few-Shot standard prompt from a dataset of exemplars1
Shi, W., Michael, J., Gururangan, S., & Zettlemoyer, L. (2022). kNN-Prompt: Nearest Neighbor Zero-Shot Inference. https://arxiv.org/abs/2205.13792

. The goal is to choose the exemplars that are most relevant to the task at hand, thereby improving the performance of the Large Language Model (LLM)2
Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L., & Chen, W. (2021). What Makes Good In-Context Examples for GPT-3? https://arxiv.org/abs/2101.06804

.

It works by selecting 
k
k examples from an external dataset that are most similar to the prompt that you're giving the model. 
K
K is a value chosen by the user, and it corresponds to the number of exemplars you want to include in the prompt.

How to Use K-Nearest Neighbor
First, you need a dataset of example prompts and completions, like the following:

ID	Prompt	Completion
1	What is the capital of France?	The capital of France is Paris.
2	How tall is Mount Everest?	Mount Everest is 8,848 meters tall.
3	Who wrote 'Romeo and Juliet'?	'Romeo and Juliet' was written by Shakespeare.
4	What is the largest ocean?	The Pacific Ocean is the largest ocean.
5	When was the Declaration of Independence signed?	The Declaration of Independence was signed in 1776.
6	Who painted the Mona Lisa?	The Mona Lisa was painted by Leonardo da Vinci.
7	What is the speed of light?	The speed of light is approximately 299,792 kilometers per second.
8	How long does it take to travel to the moon?	It takes about 3 days to travel to the moon.
9	What is the capital of Germany?	The capital of Germany is Berlin.
10	What is the boiling point of water?	The boiling point of water is 100¬∞C or 212¬∞F at sea level.
Then, you input your prompt into the KNN function and find the 
k
k number of prompts from the dataset that are most similar to use as exemplars. You then use those prompts, along with their completions, as exemplars in your Few-Shot prompt and give it to the model with your original question.

K-Nearest Neighbor Example: Machine Learning
Your prompt is "What is overfitting in machine learning?", your 
k
k value is 2, and your dataset is as follows:

ID	Prompt	Completion
1	Who discovered the law of gravity?	The law of gravity was discovered by Sir Isaac Newton.
2	What is supervised learning?	Supervised learning is a type of machine learning where the model is trained on labeled data.
3	What is the boiling point of water in Celsius?	The boiling point of water in Celsius is 100¬∞C.
4	Who wrote 'Pride and Prejudice'?	'Pride and Prejudice' was written by Jane Austen.
5	What is a neural network?	A neural network is a series of algorithms that attempt to recognize patterns in data, mimicking the human brain.
6	What is the capital of Italy?	The capital of Italy is Rome.
7	What is the speed of sound in air?	The speed of sound in air is approximately 343 meters per second.
8	What is bail in court?	Bail is a temporary release of an accused person awaiting trial.
9	What is the tallest mountain in Africa?	The tallest mountain in Africa is Mount Kilimanjaro.
10	What is the chemical symbol for gold?	The chemical symbol for gold is Au.
Once you plug in your prompt into the KNN function, it'll return prompts 2 and 5 as the nearest neighbors. Now, you use those in your Few-Shot prompt:

 Copy
Astronaut
Prompt
Q: What is supervised learning? A: Supervised learning is a type of machine learning where the model is trained on labeled data. Q: What is a neural network? A: A neural network is a series of algorithms that attempt to recognize patterns in data, mimicking the human brain. Q: What is overfitting in machine learning? A:

 Copy
Robot
AI Output
Overfitting in machine learning occurs when a model learns not only the underlying patterns in the training data but also the noise and outliers.

K-Nearest Neighbor Example: Chemistry
Your prompt is "What are London Dispersion Forces?", your k value is 1, and your dataset is as follows:

ID	Prompt	Completion
1	Who was the first president of the United States?	The first president of the United States was George Washington.
2	What country is bordered on three sides by Senegal?	The Gambia is bordered on three sides by Senegal.
3	How many continents are there?	There are seven continents on Earth.
4	Who developed the periodic table?	The periodic table was developed by Dmitri Mendeleev.
5	What was the Great Leap Forward?	The Great Leap Forward was a social and economic campaign initiated by the Chinese Communist Party under the leadership of Mao Zedong from 1958 to 1962
6	What is the capital of Australia?	The capital of Australia is Canberra.
7	What is the process of rusting?	Rusting is the oxidation of iron in the presence of water and oxygen, forming iron oxide.
8	Who wrote 'The Odyssey'?	'The Odyssey' was written by Homer.
9	What is the largest planet in our solar system?	The largest planet in our solar system is Jupiter.
10	What is the freezing point of mercury?	The freezing point of mercury is -38.83¬∞C or -37.89¬∞F.
Once you plug in your prompt into the KNN function, it'll return prompt 10 as the nearest neighbor. Now, you use prompt 10 in your Few-Shot prompt:

 Copy
Astronaut
Prompt
Q: What is the freezing point of mercury? A: The freezing point of mercury is -38.83¬∞C or -37.89¬∞F. Q: What are London Dispersion Forces? A:

 Copy
Robot
AI Output
London Dispersion Forces are a type of weak intermolecular force that arises from the temporary fluctuations in electron distribution within atoms and molecules.

K-Nearest Neighbor Example: Law
Your prompt is "What is prior restraint?", your k value is 3, and your dataset is as follows:

ID	Prompt	Completion
1	What is the capital of Brazil?	The capital of Brazil is Bras√≠lia.
2	What is the purpose of the Constitution?	The Constitution serves as the supreme law of the land, outlining the structure of government and the rights of citizens.
3	Who painted the Mona Lisa?	The Mona Lisa was painted by Leonardo da Vinci.
4	What is the Miranda warning?	The Miranda warning is a statement police must give to inform suspects of their rights to remain silent and have an attorney.
5	What is the boiling point of ethanol?	The boiling point of ethanol is 78.37¬∞C or 173.07¬∞F.
6	Who is the author of '1984'?	'1984' was written by George Orwell.
7	What is the principle of double jeopardy?	Double jeopardy is a legal principle that prohibits someone from being tried twice for the same crime.
8	What is the atomic number of hydrogen?	The atomic number of hydrogen is 1.
9	What is the speed of light in a vacuum?	The speed of light in a vacuum is approximately 299,792 kilometers per second.
10	Who discovered penicillin?	Penicillin was discovered by Alexander Fleming in 1928.
Once you plug in your prompt into the KNN function, it'll return prompts 2, 4, and 7 as the nearest neighbors. Now, you use those in your Few-Shot prompt:

 Copy
Astronaut
Prompt
Q: What is the purpose of the Constitution? A: The Constitution serves as the supreme law of the land, outlining the structure of government and the rights of citizens. Q: What is the Miranda warning? A: The Miranda warning is a statement police must give to inform suspects of their rights to remain silent and have an attorney. Q: What is the principle of double jeopardy? A: Double jeopardy is a legal principle that prohibits someone from being tried twice for the same crime. Q: What is prior restraint? A:

 Copy
Robot
AI Output
Prior restraint is a legal concept where the government restricts or prevents publication or speech before it happens, rather than punishing it after it occurs.

Limitations of K-Nearest Neighbor
Since, for a given prompt, KNN calculates the similarity of all prompts in a dataset, it can be computationally expensive for large datasets. Also, choosing a correct 
k
k value is arbitrary and can be very difficult if you don't know your dataset well.

Conclusion
KNN is part of a family of algorithms used to choose exemplars most similar to the prompt at hand to boost performance in few-shot prompting. Though it is effective at improving performance, it can be computationally expensive and is only useful for tasks that require high specificity and are too complex for regular exemplar finding methods.

---

Vote-K
‚óÜ‚óÜ
This article is rated expert
Reading Time: 7 minutes
Last updated on September 27, 2024
Andres Caceres

A diagram of vote-K


 Takeaways
Vote-
k
k is a graph-based technique for selecting diverse and representative exemplars from unlabeled datasets for Few-Shot prompts.
It ensures efficient selection by focusing on diversity and covering a broad range of topics using as few exemplars as possible.
Stage 1: Selects initial diverse exemplars based on dissimilarity using a directed graph and cosine similarity.
Stage 2: Chooses challenging examples by ranking the remaining data based on model confidence, ensuring a wide range of difficulty.
Use cases: Ideal for scenarios with unlabeled data or when dealing with complex, multifaceted topics that require diverse representations.
What is Vote-K?
Vote-
k
k is a graph-based technique used to select exemplars that are diverse and representative from a dataset of unlabeled exemplars for annotation in a Few-Shot standard prompt.

It ranks exemplars based on their dissimilarity to others in the dataset, with the most diverse ones receiving the highest rank. In other words, the exemplars that are the least similar to others get more "votes" or are ranked higher.

The idea behind Vote-
k
k is that rather than annotating the entire training data, which is often costly and time-consuming, Vote-
k
k helps efficiently select the most informative exemplars for annotation that could be further used as exemplars in your Few-Shot prompt1
Su, H., Kasai, J., Wu, C. H., Shi, W., Wang, T., Xin, J., Zhang, R., Ostendorf, M., Zettlemoyer, L., Smith, N. A., & Yu, T. (2022). Selective Annotation Makes Language Models Better Few-Shot Learners. https://arxiv.org/abs/2209.01975

.

How to Use Vote-K?
To use Vote-
k
k, you first need a dataset of unlabeled exemplars related to your task.

Then, you apply Vote-K, a two-stage process:

Stage 1: Initial Selection
Imagine having a bucket where you collect the unlabelled examplars. At first, your bucket is empty. But as you iterate during Stage 1, you gradually fill this bucket by picking diverse and representative examples.

Here are the steps:

Vote-
k
k computes vector representations of each unlabeled sample using Sentence-BERT, a model used to derive sentence embeddings that can be compared using cosine similarity.

Using the embeddings, a directed graph 
G
=
(
V
,
E
)
G=(V,E) is constructed. In this graph:

Each vertex 
v
‚àà
V
v‚ààV represents an unlabeled instance
An edge is created between each vertex and its 
k
k nearest neighbors based on the cosine similarity of the embeddings. This forms local neighborhoods of similar instances.
Using the selected metric reflecting both diversity and representativeness, the algorithm scores each unchosen vertex 
u
u based on the connections in the graph. The score for each vertex decreases if it is too close to already selected exemplars stored in your bucket, encouraging diversity in the selected set.

In each iteration, the vertex with the highest score is selected for annotation. The process continues until 
M
/
10
M/10 samples are selected, where 
M
M is the total annotation budget.

Stage 2: Confidence-Based Selection
Now that your bucket has some annotated examples, you focus on the remaining unlabeled instances to select the most challenging and diverse ones, avoiding the easiest examples.

Using a language model, Vote-
k
k takes the already-annotated exemplars from Stage 1 to make predictions for the rest of the data.
The remaining instances are then ranked based on the model‚Äôs confidence scores (how confident the model is in its predictions). The less confident the model is about an instance, the more likely it is to be selected, as these cases are typically more diverse and challenging.
The remaining unlabeled samples are divided into 
M
M equal-sized buckets based on their confidence scores. From the first 
9
M
/
10
9M/10 buckets, the most diverse examples are chosen. The most confident bucket (i.e., the top 
M
/
10
M/10 easiest cases) is discarded to ensure the final selection includes a range of difficult, diverse instances.
As a result of these two stages, you have a complete annotated set containing 
M
M exemplars:

M
/
10
M/10 exemplars from Stage 1 (the initial diverse and representative samples).
9
M
/
10
9M/10 exemplars selected from Stage 2 (instances chosen based on the model's confidence scores).
You can now annotate these 
M
M exemplars and plug them into your Few-Shot prompt!

Vote-K Example
You're an ecology student and want to understand climate change on a higher level by asking AI about it. You decide to use a Few-Shot prompt since you have a dataset of climate change-related questions, but you don't know which of the questions would be useful to use as exemplars and, frankly, you don't have time to sift through all of them. You decide to use Vote-
k
k to choose the exemplars for you. Your dataset is as follows:

"How does global warming affect polar bear populations?"
"What are the primary sources of methane emissions?"
"How do deforestation and land-use change contribute to carbon emissions?"
"What are the long-term effects of ocean acidification on marine ecosystems?"
"How does climate change influence extreme weather events like hurricanes and floods?"
"What are the economic impacts of transitioning to renewable energy sources?"
"How do rising temperatures affect agricultural productivity in different regions?"
"What are the social consequences of climate-induced migration?"
"What role do international agreements play in addressing climate change?"
"How does climate change impact biodiversity loss?"
etc.
Stage 1: Initial Diversity-Based Selection
Vote-
k
k will first compute vector representations of each question in your dataset using a model like Sentence-BERT. These vectors allow the questions to be compared for similarity. The algorithm will then create a graph connecting similar questions based on their cosine similarity. In this graph, each question will be a vertex, and edges will connect it to its 
k
k nearest neighbors (the most similar questions).

Vote-
k
k will start selecting the most diverse exemplars based on this graph using the selected metric (some score). Remember, it's an iterative process and you want to pick an exemplars that‚Äôs not too similar to the ones you‚Äôve already picked, so each time you calculate a score for each remaining exemplar and select the one with the highest score. For example, the first selected exemplars are:

"How does global warming affect polar bear populations?" (focus on biodiversity and animal species).
"What are the primary sources of methane emissions?" (focus on emissions sources).
"What are the economic impacts of transitioning to renewable energy sources?" (focus on economic factors).
Now that you've selected three exemplars, you now annotate them with the corresponding answers. In theory, this is supposed to be 
M
/
10
M/10 exemplars, but for the sake of simplicity and for the example we'll ignore that (
M
M would have to be 30).

Stage 2: Confidence-Based Selection
You now use these exemplars to train a model and have it make predictions on the rest of the unlabeled questions in your dataset.

From the rest of the unlabeled questions, Vote-
k
k will now choose questions where the model's confidence in its predictions is lower since that means they're harder and more unique. For example, the model could struggle with:

"What are the social consequences of climate-induced migration?"
"How do rising temperatures affect agricultural productivity in different regions?" etc.
Vote-
k
k will continue selecting these 
9
M
/
10
9M/10 exemplars, and once it's done, you annotate all of the ones it chooses.

Final Outcome:

By the end of both stages, Vote-
k
k has selected a total of 
M
M exemplars:

The 
M
/
10
M/10 from the initial diversity-based selection
Then, the 
9
M
/
10
9M/10 from the confidence-based selection
These exemplars have all been annotated and are ready for use in your Few-Shot prompt.

Limitations of Vote-K
Vote-
k
k prioritizes diversity when selecting exemplars, but it doesn't inherently evaluate whether the selected exemplars are relevant or useful for the task at hand. This means that while you might cover a wide range of topics, you might end up with exemplars that are too peripheral or not directly helpful for your specific task. Additionally, for very large datasets of exemplars, Vote-
k
k can be computationally expensive, and having to label the exemplars can be a pain, especially if you do it manually.

Conclusion
Vote-
k
k is a structured approach to finding good exemplars for your few-shot prompt based on the diversity of exemplars and being able to cover a wide range of topics as efficiently as possible. It's a powerful weapon to add to your exemplar-finding arsenal, especially if you find yourself with a dataset of exemplars that are unlabeled. It does have limitations, though; its focus on diversity can end up making it ignore quality or relevance, it can take up a lot of resources to do, and having to label the exemplars can be annoying.

---

Prompt Mining
‚óÜ‚óÜ
This article is rated expert
Reading Time: 5 minutes
Last updated on September 27, 2024
Andres Caceres

Prompt Mining

 Takeaways
Prompt Mining is a way to select the optimal prompt template for a given task from a corpus of text based on the template that comes up most often in the corpus.
It improves the model's performance by providing it with prompts it's most 'familiar' with.
Limitations: It can be computationally expensive and doesn't always improve performance if the task is highly specific.
What is Prompt Mining?
Prompt Mining1
Jiang, Z., Xu, F. F., Araki, J., & Neubig, G. (2019). How Can We Know What Language Models Know? https://arxiv.org/abs/1911.12543

 is a technique used to identify the best prompt template for a given 
[
r
e
l
a
t
i
o
n
]
[relation] between 
[
s
u
b
j
e
c
t
]
[subject] and 
[
o
b
j
e
c
t
]
[object]2
Petroni, F., Rockt√§schel, T., Lewis, P., Bakhtin, A., Wu, Y., Miller, A. H., & Riedel, S. (2019). Language Models as Knowledge Bases? https://arxiv.org/abs/1909.01066

 from a corpus of text. Similar to traditional mining, where you search for valuable resources, in prompt mining you use algorithms to uncover the prompt template giving the most accurate results.

The key point here is that Prompt Mining isn‚Äôt about selecting the best template for any general task. Instead, it‚Äôs focused on improving how Large Language Models (LLMs) retrieve factual knowledge. Essentially, it boosts accuracy by discovering the language patterns and templates the model has "learned" best during training. The goal is to find prompts that consistently trigger the model to predict correct factual information.

A prompt template is a structured format for presenting questions or statements to the model, often with placeholders for customization. For example:

 Copy
Astronaut
Prompt
Q: Why is the sky blue?

A:

In this case, the template would be:

 Copy
Astronaut
Template 1
Q: {question}?

A:

Alternatively, another template could guide the model to complete a statement:

 Copy
Astronaut
Prompt
The sky is blue because ...

 Copy
Astronaut
Template 2
[x] is [y] because ...

As you can see, in both cases, the user intent is the same. However, Prompt Mining seeks the template the model is most 'acquainted' with based on its training data. Being 'acquainted' means the template frequently appears in the corpus, reflecting language patterns familiar to the model, even if not in exactly the same form.

How to Use Prompt Mining
Prompt Mining is a two-stage process:

Prompt Generation: Extracting prompt templates from a large corpus (e.g., Wikipedia).
Prompt Selection: Choosing the best prompt template based on a selected metric.
Let‚Äôs break these stages down in more detail.

Stage 1: Prompt Generation
In this stage, you need a large corpus of text that is representative of the data the model was trained on. For instance, if your model was trained on Wikipedia and research papers, you should use those as your corpus.

Here are two common methods for generating prompt templates:

Method 1: Mining-Based Generation
This method extracts prompts from the corpus by identifying relationships between subject-object pairs. The words between the subject and object typically represent the relation, which can be converted into a prompt template. For example:

 Copy
Astronaut
Template
[x] was born in [y]

Another approach is to use syntactic analysis to identify relationships between (subject, object) pairs. This method is flexible because it doesn‚Äôt require a manually created reference prompt, making it applicable to various types of relations.

Method 2: Paraphrasing-Based Generation
This method starts with an original prompt and aims to improve lexical diversity by paraphrasing the seed prompt while maintaining the same meaning. For example:

 Copy
Astronaut
Original Template
[x] shares a border with [y]

 Copy
Astronaut
Paraphrased Templates
- [x] has a common border with [y] - [x] adjoins [y]
Stage 2, Prompt Selection
Once you‚Äôve generated a set of prompt templates, you can use a mining algorithm to find the optimal one. The simplest approach is to select the template that appears most frequently in the corpus.

A more advanced approach is to select the template that produces the most accurate results, based on ground truth data. Ground truth refers to the actual correct labels or facts in a dataset that are used to evaluate the model's predictions. For example, if you're working with relationship "
x
x is owned by 
y
y", and the relation you're testing is "YouTube is owned by Alphabet," the ground-truth object in this case would be "Alphabet." When evaluating the model's performance, the accuracy is determined by how often the model's predicted object (e.g., the model might predict "Alphabet" or another company) matches this ground-truth object.

Prompt Mining Example
Let‚Äôs say you‚Äôre working with the relation "manufacturer." To illustrate the difference, let's suppose you have a manual prompt, a prompt that you've created based on your intuition:

 Copy
Astronaut
Manual Prompt
[y] manufactured the [x]

This serves as your baseline. Now, you turn to Stage 1 and generate prompt templates from a Wikipedia corpus. You might get results like these:

[y] introduced the [x]
[y] released the [x]
[x] attributed to the [y]
[y] sprinter [x]
[y] announced the [x]
[y] launched the [x]
[y] introduces the [x]
This is a list of potential templates. Next, you use a metric to select the best template, for example, by choosing the one that appears most frequently. Here are the results:

Template	Frequency
[y] introduced the [x]	0.5940
[y] released the [x]	0.0022
[x] attributed to the [y]	0.1109
[y] sprinter [x]	0.00005
[y] announced the [x]	0.2857
[y] launched the [x]	0.0040
[y] introduces the [x]	0.00057
As you can see, the most frequent prompt template is "[y] introduced the [x]." Now you can compare the performance of the manual prompt versus the one identified through Prompt Mining.

 Copy
Astronaut
Manual Prompt
[y] manufactured the [x]

 Copy
Astronaut
Template Found with Prompt Mining
[y] introduced the [x]

Limitations of Prompt Mining
While Prompt Mining can enhance accuracy, it comes with a few limitations:

Computational Cost: Mining through large text corpora is resource-intensive and can be computationally expensive. The potential performance gains might not always justify the computing power required.

Minimal Performance Gains: Sometimes, the improvement in performance is minimal, and in certain cases, using a mined prompt template could even result in worse outcomes if it doesn‚Äôt align with the specific nuances of the task.

Conclusion
Prompt Mining is a powerful technique that helps improve the accuracy of large language models by identifying the most effective prompt templates based on their training data. By finding patterns the model is familiar with, it enhances the likelihood of retrieving factual information more reliably.

---

Introduction to Thought Generation Techniques
Reading Time: 1 minute
Last updated on September 27, 2024
Valeriia Kuka

Thought Generation Prompting Techniques

Welcome to the thought generation section of the advanced Prompt Engineering Guide.

Thought generation uses various techniques to prompt an Large Language Model (LLM) to clearly articulate its reasoning while solving problems.

We've already explored the Contrastive Chain-of-Thought prompting technique. Stay tuned for more advanced techniques coming soon!

In this section, you'll learn about:

Contrastive Chain-of-Thought
Automatic Chain-of-Thought (Auto-CoT)
Tabular Chain-of-Thought (Tab-CoT)
Memory-of-Thought (MoT)
Active Prompting
Analogical Prompting
Complexity-Based Prompting
Step-Back Prompting

---

 Contrastive Chain-of-Thought (CoT) Prompting
üü¶
This article is rated medium
Reading Time: 3 minutes
Last updated on October 1, 2024
Valeriia Kuka

Contrastive Chain-of-Thought in action

Overview of Contrastive Chain-of-Thought (CoT) Prompting
 Takeaways
Learning from Negative Examples: Contrastive Chain-of-Thought (CoT) enhances LLM reasoning by incorporating both positive and negative examples

Prompt Structure: Contrastive CoT prompts include a question, correct/incorrect answers, and the query.

Generating Examples: Automatically create contrastive examples by shuffling key entities from correct answers.

Information and Links
Technique	Institution	Date of Publication	Paper	Code
Contrastive Chain-of-Thought (CoT) Prompting	DAMO Academy, Alibaba Group; Singapore University of Technology and Design; Nanyang Technological University, Singapore	Nov 2023	Contrastive Chain-of-Thought Prompting	DAMO-NLP-SG/contrastive-cot
What is Contrastive Chain-of-Thought (CoT) Prompting?
Chain-of-Thought (CoT) Prompting1
Jason Wei. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.

 improves the accuracy of Large Language Models (LLMs) when solving mathematical and reasoning tasks by compelling the models to think. Adding a simple statement like "Let's think step by step" to the prompt can significantly improve the model's performance. Adding a positive example, a question-answer pair, before the actual question further improves the reasoning of the LLM. Learning from negative examples is not unique to humans and can also be replicated in LLMs. Embedding negative examples with the prompt can help LLMs learn from them and generate better explanations for their answers.

Inspired by human's ability to learn from positive and negative examples, Contrastive Chain-of-Thought (CoT) Prompting2
Yew Ken Chia. (2023). Contrastive Chain-of-Thought Prompting. In arXiv preprint arXiv:1907.11692.

, employs negative examples along with positive ones to enhance the reasoning capabilities of language models. Making the models aware of what mistakes to avoid via negative examples also makes them more accurate.

How to Use Contrastive Chain-of-Thought (CoT) Prompting?
The prompt in the Contrastive CoT compromises of the following components:

Sample question or example question
Correct explanation question in 1
Incorrect explanation for question in 1
Actual question/query
The example below shows Contrastive Chain-of-Thought prompting in action.

 Copy
Astronaut
Prompt
Question : James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year?

Explanation: He writes each friend 32=6 pages a week. So he writes 62=12 pages every week. That means he writes 12*52=624 pages a year.

Wrong Explanation: He writes each friend 1252=624 pages a week. So he writes 32=6 pages every week. That means he writes 6*2=12 pages a year.

Question: James has 30 teeth. His dentist drills 4 of them and caps 7 more teeth than he drills. What percentage of James' teeth does the dentist fix?

 Copy
Robot
AI Output
Explanation: The dentist drills 4 teeth, so there are 30 - 4 = 26 teeth left. The dentist caps 7 more teeth than he drills, so he caps 4 + 7 = 11 teeth. Therefore, the dentist fixes a total of 4 + 11 = 15 teeth. To find the percentage of teeth the dentist fixes, we divide the number of teeth fixed by the total number of teeth and multiply by 100: 15/30 √ó 100 = 50%

How to Use an Automated Method to Generate Contrastive Examples?
The authors devise an automated method to generate contrastive examples in the paper. It involves the following steps:

Curate examples with correct reasoning steps from the existing dataset.
Within the example in step 1, use the entity recognition model to identify numbers, equations, or persons.
Shuffle the position of the entities extracted from step 2.
contrastive Chain-of-Thought prompting

Contrastive example generation2
Yew Ken Chia. (2023). Contrastive Chain-of-Thought Prompting. In arXiv preprint arXiv:1907.11692.



The image below shows an instance where a contrastive example is generated using a positive example.

Contrastive Chain-of-Thought prompting

From positive example to contrastive example2
Yew Ken Chia. (2023). Contrastive Chain-of-Thought Prompting. In arXiv preprint arXiv:1907.11692.



The example below shows Contrastive CoT in action. Feel free to modify it and test your inputs.


Tip
The code for Contrastive Chain-of-Thought (CoT) Prompting is open-sourced and available for further research and implementation at DAMO-NLP-SG/contrastive-cot.

Conclusion
Learning from negative examples is not unique to humans and can also be replicated in language models. Embedding negative examples with the prompt can help language models learn from them and generate better explanations for their answers.

---



---

---

---

---

