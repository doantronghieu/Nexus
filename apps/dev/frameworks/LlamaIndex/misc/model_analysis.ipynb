{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import packages\n",
				"import pandas as pd\n",
				"import os"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_csv(f\"{packages.APP_PATH}/data/logs/performance_logs.csv\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df.dtypes"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"print(f\"metadata_algorithm: {df['metadata_algorithm'].unique()}\")\n",
				"print(f\"metadata_dataset: {df['metadata_dataset'].unique()}\")\n",
				"print(f\"metadata_inference_server: {df['metadata_inference_server'].unique()}\")\n",
				"print(f\"metadata_model: {df['metadata_model'].unique()}\")\n",
				"print(f\"performance_data_cpu_usage: {df['performance_data_cpu_usage'][0][:50]}\")\n",
				"print(f\"performance_data_ram_usage: {df['performance_data_ram_usage'][0][:50]}\")\n",
				"print(f\"performance_data_peak_memory (float): {df['performance_data_peak_memory'][0]}\")\n",
				"print(f\"performance_data_system_performance_cpu_percent_avg: {df['performance_data_system_performance_cpu_percent_avg'][0]}\")\n",
				"print(f\"performance_data_system_performance_cpu_percent_peak: {df['performance_data_system_performance_cpu_percent_peak'][0]}\")\n",
				"print(f\"performance_data_system_performance_cpu_system: {df['performance_data_system_performance_cpu_system'][0]}\")\n",
				"print(f\"performance_data_system_performance_execution_time: {df['performance_data_system_performance_execution_time'][0]}\")\n",
				"print(f\"performance_data_system_performance_ram_peak: {df['performance_data_system_performance_ram_peak'][0]}\")\n",
				"print(f\"system_info_cpu: {df['system_info_cpu'][0]}\")\n",
				"print(f\"system_info_cpu_count: {df['system_info_cpu_count'][0]}\")\n",
				"print(f\"system_info_device_name: {df['system_info_device_name'][0]}\")\n",
				"print(f\"system_info_os: {df['system_info_os'][0]}\")\n",
				"print(f\"system_info_python_version: {df['system_info_python_version'][0]}\")\n",
				"print(f\"system_info_total_ram: {df['system_info_total_ram'][0]}\")\n",
				"print(f\"performance_data_llm_performance_execution_time: {df['performance_data_llm_performance_execution_time'][0]}\")\n",
				"print(f\"performance_data_llm_performance_first_token_time: {df['performance_data_llm_performance_first_token_time'][0]}\")\n",
				"print(f\"performance_data_llm_performance_tokens_per_second: {df['performance_data_llm_performance_tokens_per_second'][0]}\")\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import pandas as pd\n",
				"import plotly.graph_objects as go\n",
				"from plotly.subplots import make_subplots\n",
				"import ast\n",
				"\n",
				"# Load the data\n",
				"df = pd.read_csv(f\"{packages.APP_PATH}/data/logs/performance_logs.csv\")\n",
				"\n",
				"# Function to safely evaluate and calculate mean of list-like strings\n",
				"def safe_mean(x):\n",
				"    try:\n",
				"        values = ast.literal_eval(x)\n",
				"        if isinstance(values, list) and all(isinstance(i, (int, float)) for i in values):\n",
				"            return sum(values) / len(values)\n",
				"        else:\n",
				"            return None\n",
				"    except:\n",
				"        return None\n",
				"\n",
				"# Convert relevant columns to numeric\n",
				"df['performance_data_cpu_usage'] = df['performance_data_cpu_usage'].apply(safe_mean)\n",
				"df['performance_data_ram_usage'] = df['performance_data_ram_usage'].apply(safe_mean)\n",
				"df['performance_data_system_performance_cpu_percent_avg'] = df['performance_data_system_performance_cpu_percent_avg'].str.rstrip('%').astype('float')\n",
				"df['performance_data_system_performance_cpu_percent_peak'] = df['performance_data_system_performance_cpu_percent_peak'].str.rstrip('%').astype('float')\n",
				"df['performance_data_system_performance_cpu_system'] = df['performance_data_system_performance_cpu_system'].str.split().str[0].astype('float')\n",
				"df['performance_data_system_performance_execution_time'] = df['performance_data_system_performance_execution_time'].str.split().str[0].astype('float')\n",
				"df['performance_data_system_performance_ram_peak'] = df['performance_data_system_performance_ram_peak'].str.split().str[0].astype('float')\n",
				"\n",
				"# Create a reorganized figure\n",
				"fig = make_subplots(\n",
				"    rows=3, cols=3,\n",
				"    subplot_titles=(\n",
				"        \"<b>Total Execution Time</b>\", \"<b>LLM Tokens per Second</b>\", \"<b>Time to First Token</b>\",\n",
				"        \"<b>CPU Usage</b>\", \"<b>RAM Usage</b>\", \"<b>Model and Dataset Info</b>\",\n",
				"        \"<b>System Info</b>\", \"<b>Inference Info</b>\"\n",
				"    ),\n",
				"    specs=[\n",
				"        [{\"type\": \"box\"}, {\"type\": \"box\"}, {\"type\": \"box\"}],\n",
				"        [{\"type\": \"box\"}, {\"type\": \"box\"}, None],\n",
				"        [{\"type\": \"table\"}, {\"type\": \"table\"}, {\"type\": \"table\"}],\n",
				"    ],\n",
				"    vertical_spacing=0.07,\n",
				"    row_heights=[0.38, 0.38, 0.24]\n",
				")\n",
				"\n",
				"# Function to add box plot\n",
				"def add_box_plot(fig, df, y_column, row, col):\n",
				"    fig.add_trace(\n",
				"        go.Box(x=df['metadata_model'], y=df[y_column], name=y_column),\n",
				"        row=row, col=col\n",
				"    )\n",
				"\n",
				"# Add box plots\n",
				"add_box_plot(fig, df, 'performance_data_llm_performance_execution_time', 1, 1)\n",
				"add_box_plot(fig, df, 'performance_data_llm_performance_tokens_per_second', 1, 2)\n",
				"add_box_plot(fig, df, 'performance_data_llm_performance_first_token_time', 1, 3)\n",
				"add_box_plot(fig, df, 'performance_data_system_performance_cpu_percent_avg', 2, 1)\n",
				"add_box_plot(fig, df, 'performance_data_system_performance_ram_peak', 2, 2)\n",
				"\n",
				"# Model and Dataset Info\n",
				"model_dataset_info = df.groupby(['metadata_model', 'metadata_dataset']).size().reset_index(name='count')\n",
				"fig.add_trace(go.Table(\n",
				"    header=dict(values=[\"<b>Model</b>\", \"<b>Dataset</b>\", \"<b>Count</b>\"],\n",
				"                align=\"left\", font=dict(size=11)),\n",
				"    cells=dict(values=[model_dataset_info[col] for col in model_dataset_info.columns],\n",
				"               align=\"left\", font=dict(size=10))\n",
				"), row=3, col=1)\n",
				"\n",
				"# System Info\n",
				"system_info = df[['system_info_cpu', 'system_info_cpu_count', 'system_info_os', 'system_info_python_version', 'system_info_total_ram']].drop_duplicates()\n",
				"fig.add_trace(go.Table(\n",
				"    header=dict(values=[\"<b>CPU</b>\", \"<b>CPU Count</b>\", \"<b>OS</b>\", \"<b>Python Version</b>\", \"<b>Total RAM</b>\"],\n",
				"                align=\"left\", font=dict(size=11)),\n",
				"    cells=dict(values=[system_info[col] for col in system_info.columns],\n",
				"               align=\"left\", font=dict(size=10))\n",
				"), row=3, col=2)\n",
				"\n",
				"# Inference Info\n",
				"inference_info = df.groupby(['metadata_inference_server', 'metadata_algorithm']).size().reset_index(name='algo_count')\n",
				"fig.add_trace(go.Table(\n",
				"    header=dict(values=[\"<b>Inference Server</b>\", \"<b>Algorithm</b>\", \"<b>Count</b>\"],\n",
				"                align=\"left\", font=dict(size=11)),\n",
				"    cells=dict(values=[inference_info[col] for col in inference_info.columns],\n",
				"               align=\"left\", font=dict(size=10))\n",
				"), row=3, col=3)\n",
				"\n",
				"# Update layout\n",
				"fig.update_layout(\n",
				"    height=1700,\n",
				"    width=1500,\n",
				"    title_text=\"LLM Performance Analysis\",\n",
				"    showlegend=False,\n",
				"    margin=dict(l=50, r=50, t=100, b=50)\n",
				")\n",
				"\n",
				"# Update x-axis labels for box plots\n",
				"for i in range(1, 6):\n",
				"    row = 1 if i <= 3 else 2\n",
				"    col = i if i <= 3 else i - 3\n",
				"    fig.update_xaxes(title_text=\"Model\", row=row, col=col)\n",
				"\n",
				"# Adjust subplot titles\n",
				"for i in fig['layout']['annotations']:\n",
				"    i['font'] = dict(size=14, color=\"black\")\n",
				"\n",
				"# Show the plot\n",
				"fig.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "llm",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.19"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
