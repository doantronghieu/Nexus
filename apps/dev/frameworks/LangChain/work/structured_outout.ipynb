{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import packages\n",
    "\n",
    "from context.utils import typer as t\n",
    "from context.infra.clients import logger\n",
    "\n",
    "from toolkit.utils import utils\n",
    "from toolkit.utils.utils import rp_print\n",
    "from toolkit.utils.llm import main as utils_llm\n",
    "\n",
    "import context.instances as inst\n",
    "import context.consts as const\n",
    "import context.settings.main as settings_main\n",
    "\n",
    "from toolkit.llm.langchain.core import integration, utils as utils_lc\n",
    "from toolkit.llm.langchain.data.indexing import (\n",
    "    documents, document_loaders, text_splitters,\n",
    ")\n",
    "from toolkit.llm.langchain.data.persistence import retrievers\n",
    "from toolkit.llm.langchain.execution import (\n",
    "    runnables, graphs, tools, agents, tools as tools_lc\n",
    ")\n",
    "from toolkit.llm.langchain.models import (\n",
    "    prompts as prompts_lc, llms, messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person(t.BaseModel):\n",
    "\t\"\"\"Information about a person.\"\"\"\n",
    "\n",
    "\t# ^ Doc-string for the entity Person.\n",
    "\t# This doc-string is sent to the LLM as the description of the schema Person,\n",
    "\t# and it can help to improve extraction results.\n",
    "\n",
    "\t# Note that:\n",
    "\t# 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "\t# 2. Each field has a `description` -- this description is used by the LLM.\n",
    "\t# Having a good description can help improve extraction results.\n",
    "\tname: t.Optional[str] = t.Field(\n",
    "\tdefault=None, description=\"The name of the person\"\n",
    "\t)\n",
    "\thair_color: t.Optional[str] = t.Field(\n",
    "\t\tdefault=None, description=\"The color of the person's hair if known\"\n",
    "\t)\n",
    "\theight_in_meters: t.Optional[str] = t.Field(\n",
    "\t\tdefault=None, description=\"Height measured in meters\"\n",
    "\t)\n",
    "\n",
    "class Group(t.BaseModel):\n",
    "  # Creates a model so that we can extract multiple entities.\n",
    "\tpeople: t.List[Person]\n",
    "\n",
    "prompt_tpl = prompts_lc.ChatPromptTemplate.from_messages([\n",
    "\t(\n",
    "\t\t\"system\",\n",
    "\t\t\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value.\",\n",
    "\t),\n",
    "\t(\n",
    "   \t\"human\", \"{user_input}\"\n",
    "  ),\n",
    "])\n",
    "\n",
    "llm_structured = inst.llm_main.with_structured_output(schema=Group)\n",
    "\n",
    "user_input = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\n",
    "prompt = prompt_tpl.invoke({\"user_input\": user_input})\n",
    "response = llm_structured.invoke(prompt)\n",
    "\n",
    "rp_print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
