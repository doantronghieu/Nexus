{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import packages\n",
    "\n",
    "from context.utils import typer as t\n",
    "\n",
    "from toolkit.utils import utils\n",
    "from toolkit.utils.utils import rp_print\n",
    "\n",
    "from context.infra import clients\n",
    "import context.instances as inst\n",
    "import context.consts as const\n",
    "import context.settings.main as settings_main\n",
    "\n",
    "from toolkit.llm.langchain.core import integration, utils as utils_lc\n",
    "from toolkit.llm.langchain.data.persistence import retrievers\n",
    "from toolkit.llm.langchain.data.indexing import (\n",
    "  documents, document_loaders, text_splitters,\n",
    ")\n",
    "from toolkit.llm.langchain.execution import (\n",
    "  runnables, graphs, tools as tools_lc, agents\n",
    ")\n",
    "from toolkit.llm.langchain.models import (\n",
    "\tprompts as prompts_lc, llms, messages as msgs_lc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_tool(description: str, name: str = None):\n",
    "    # Get the calling frame\n",
    "    frame = utils.inspect.currentframe().f_back\n",
    "    \n",
    "    # If name not provided, try to get the variable name from assignment\n",
    "    if name is None:\n",
    "        # Get the code context from the frame\n",
    "        context = utils.inspect.getframeinfo(frame).code_context\n",
    "        if context:\n",
    "            # Find the variable name from assignment\n",
    "            caller_lines = \"\".join(context)\n",
    "            assignment = caller_lines.split(\"=\")[0].strip()\n",
    "            name = assignment\n",
    "    \n",
    "    # Fallback if we couldn't determine the name\n",
    "    if not name:\n",
    "        name = \"transfer_tool\"\n",
    "        \n",
    "    # Create a simple schema with message field\n",
    "    schema = t.create_model(\n",
    "        f\"{name}_schema\",\n",
    "        __base__=t.BaseModel,\n",
    "        query=(str, None)  # Optional message field for any additional info\n",
    "    )\n",
    "    \n",
    "    return tools_lc.StructuredTool(\n",
    "        name=name,\n",
    "        description=description,\n",
    "        func=lambda query=None: None,  # Simple pass-through function\n",
    "        args_schema=schema\n",
    "    )\n",
    "\n",
    "# llm = llms.create_tooled_llm(\n",
    "#     inst.llm_main,\n",
    "#     tools=[tool_transfer_to_agent_mul, tool_transfer_to_agent_add]\n",
    "# )\n",
    "# result = llm.invoke(\"How to add one and two multiply three\")\n",
    "# rp_print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define registry with proper framework typing\n",
    "TOOL_REGISTRY: t.Dict[str, tools_lc.BaseTool] = {}\n",
    "\n",
    "def process_tools(response: msgs_lc.AIMessage, messages: list) -> tuple[list, bool]:\n",
    "    \"\"\"\n",
    "    Process tool calls from the LLM response.\n",
    "    \n",
    "    Args:\n",
    "        response: The AI message containing tool calls\n",
    "        messages: Current message history\n",
    "        \n",
    "    Returns:\n",
    "        tuple[list, bool]: Updated messages and transfer flag\n",
    "    \"\"\"\n",
    "    updated_msgs = messages + [response]\n",
    "    transfer = False\n",
    "    \n",
    "    if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "        for tool_call in response.tool_calls:\n",
    "            name = tool_call[\"name\"]\n",
    "            call_id = tool_call[\"id\"]\n",
    "            \n",
    "            if name in TOOL_REGISTRY:\n",
    "                # Use the tool's built-in invoke method\n",
    "                tool = TOOL_REGISTRY[name]\n",
    "                result = tool.invoke(tool_call)\n",
    "                \n",
    "                # Extract just the value from the result\n",
    "                if isinstance(result, str) and 'content=' in result:\n",
    "                    content = result.split(\"'\")[1]\n",
    "                else:\n",
    "                    content = str(result)\n",
    "                \n",
    "                tool_msg = msgs_lc.ToolMessage(\n",
    "                    content=content,\n",
    "                    tool_call_id=call_id\n",
    "                )\n",
    "                updated_msgs.append(tool_msg)\n",
    "            elif \"tool_transfer_to_agent\" in name:\n",
    "                tool_msg = msgs_lc.ToolMessage(\n",
    "                    content=\"Transfer request acknowledged\",\n",
    "                    tool_call_id=call_id\n",
    "                )\n",
    "                updated_msgs.append(tool_msg)\n",
    "                transfer = True\n",
    "    \n",
    "    return updated_msgs, transfer\n",
    "\n",
    "# Define template for system prompts\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are an expert agent specializing in {domain}. \n",
    "\n",
    "ROLE AND RESPONSIBILITIES:\n",
    "1. You are responsible for {primary_task}\n",
    "2. Stay focused on your specific expertise area\n",
    "3. Collaborate with other agents when needed\n",
    "\n",
    "TOOL USAGE PRINCIPLES:\n",
    "1. Use your assigned tools effectively and appropriately\n",
    "2. Make all necessary tool calls in a single response\n",
    "3. Validate inputs before using tools\n",
    "4. Process results clearly and accurately\n",
    "\n",
    "COLLABORATION RULES:\n",
    "1. Transfer to other experts when task is outside your expertise\n",
    "2. Always complete your part before transferring\n",
    "3. Provide clear context when transferring\n",
    "4. Never transfer back to an agent that just transferred to you\n",
    "\n",
    "RESPONSE STRUCTURE:\n",
    "1. Analyze the task first\n",
    "2. Use appropriate tools as needed\n",
    "3. Show work clearly and step by step\n",
    "4. Transfer only when necessary\n",
    "\n",
    "{specific_instructions}\n",
    "\"\"\"\n",
    "\n",
    "def pretty_print_stream(graph_stream):\n",
    "    \"\"\"\n",
    "    Pretty prints the stream from a LangGraph, showing only new messages at each turn.\n",
    "    \n",
    "    Args:\n",
    "        graph_stream: Iterator from graph.stream()\n",
    "    \"\"\"\n",
    "    seen_message_ids = set()\n",
    "    \n",
    "    def print_new_messages(messages):\n",
    "        \"\"\"Helper function to print only unseen messages.\"\"\"\n",
    "        for msg in messages:\n",
    "            # Skip if we've seen this message before\n",
    "            if hasattr(msg, 'id') and msg.id in seen_message_ids:\n",
    "                continue\n",
    "                \n",
    "            # Add to seen messages if it has an ID\n",
    "            if hasattr(msg, 'id'):\n",
    "                seen_message_ids.add(msg.id)\n",
    "            \n",
    "            # Print the message content based on type\n",
    "            if hasattr(msg, 'content') and msg.content:\n",
    "                print(f\"Message: {msg.content}\")\n",
    "            \n",
    "            # Print tool calls if present\n",
    "            if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                for tool_call in msg.tool_calls:\n",
    "                    tool_name = tool_call.get('name', 'unknown_tool')\n",
    "                    tool_args = tool_call.get('args', {})\n",
    "                    print(f\"Tool Call: {tool_name}\")\n",
    "                    print(f\"Arguments: {tool_args}\")\n",
    "            \n",
    "            # Print tool message results\n",
    "            if hasattr(msg, 'tool_call_id'):\n",
    "                print(f\"Tool Result: {msg.content}\")\n",
    "            \n",
    "            if hasattr(msg, 'content') or hasattr(msg, 'tool_calls') or hasattr(msg, 'tool_call_id'):\n",
    "                print(\"-\" * 50)\n",
    "    \n",
    "    for chunk in graph_stream:\n",
    "        if isinstance(chunk, tuple):\n",
    "            # Handle subgraph updates\n",
    "            ns, update = chunk\n",
    "            if not ns:\n",
    "                continue\n",
    "            print(f\"\\n=== Update from subgraph {ns[-1].split(':')[0]} ===\")\n",
    "            if 'messages' in update:\n",
    "                print_new_messages(update['messages'])\n",
    "        else:\n",
    "            # Handle regular node updates\n",
    "            for node_name, node_update in chunk.items():\n",
    "                print(f\"\\n=== Update from {node_name} ===\")\n",
    "                if 'messages' in node_update:\n",
    "                    print_new_messages(node_update['messages'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NODE(t.EnumCustom):\n",
    "\tAGENT_ADD = t.auto()\n",
    "\tAGENT_MUL = t.auto()\n",
    "\t\n",
    "@tools_lc.tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tools_lc.tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Register tools after creation\n",
    "TOOL_REGISTRY['add'] = add\n",
    "TOOL_REGISTRY['multiply'] = multiply\n",
    "\n",
    "# Usage example - much simpler now\n",
    "tool_transfer_to_agent_mul = create_transfer_tool(\n",
    "    description=\"Ask multiplication agent for help.\"\n",
    ")\n",
    "\n",
    "tool_transfer_to_agent_add = create_transfer_tool(\n",
    "    description=\"Ask addition agent for help.\"\n",
    ")\n",
    "\n",
    "# Specific instructions for each agent type\n",
    "ADD_SPECIFIC = \"\"\"\n",
    "KEY RULES FOR ADDITION EXPERT:\n",
    "1. PATTERN RECOGNITION:\n",
    "\tWhen you see expressions like \"(a + b) * c\", this ALWAYS requires TWO tool calls:\n",
    "\t- First call: add tool for (a + b)\n",
    "\t- Second call: transfer to multiplication expert for the result * c\n",
    "\tYou MUST make BOTH calls in the SAME response.\n",
    "\n",
    "2. REQUIRED TOOL SEQUENCE:\n",
    "\tFor ANY expression involving multiplication after addition:\n",
    "\tStep 1: Use add tool to calculate the addition\n",
    "\tStep 2: IMMEDIATELY use tool_transfer_to_agent_mul in the SAME response\n",
    "\tDO NOT wait for another interaction to transfer.\n",
    "\n",
    "3. EXAMPLE SEQUENCES:\n",
    "\tFor \"(3 + 5) * 12\":\n",
    "\t- CORRECT (do this):\n",
    "\t\t1. add(a=3, b=5)\n",
    "\t\t2. tool_transfer_to_agent_mul(query=\"8 * 12\")\n",
    "\t- INCORRECT (don't do this):\n",
    "\t\t× Only calling add without transfer\n",
    "\t\t× Waiting for next message to transfer\n",
    "\n",
    "4. MANDATORY ACTIONS:\n",
    "\t- NEVER handle addition alone if multiplication follows\n",
    "\t- ALWAYS make both tool calls in one response\n",
    "\t- ALWAYS transfer after completing addition\n",
    "\"\"\"\n",
    "\n",
    "MUL_SPECIFIC = \"\"\"\n",
    "MULTIPLICATION EXPERTISE:\n",
    "1. You handle multiplication operations using the 'multiply' tool\n",
    "2. Transfer to addition expert if addition is needed first\n",
    "3. Complete multiplications when numbers are ready\n",
    "4. Present final results clearly\n",
    "\n",
    "Example workflow:\n",
    "For received \"8 * 12\":\n",
    "1. multiply(a=8, b=12)  # Calculate final result\n",
    "\"\"\"\n",
    "\t\n",
    "def agent_addition(\n",
    "\t\tstate: graphs.MessagesState,\n",
    ") -> graphs.Command[t.Literal[NODE.AGENT_MUL, graphs.END]]:\n",
    "\t\tmodel = llms.create_tooled_llm(inst.llm_main, [tool_transfer_to_agent_mul, add])\n",
    "\t\tprompt_system = SYSTEM_PROMPT_TEMPLATE.format(\n",
    "\t\t\t\tdomain=\"mathematical addition\",\n",
    "\t\t\t\tprimary_task=\"handling addition operations and coordinating with multiplication expert\",\n",
    "\t\t\t\tspecific_instructions=ADD_SPECIFIC\n",
    "\t\t)\n",
    "\t\tmsgs = [msgs_lc.SystemMessage(prompt_system)] + state[\"messages\"]\n",
    "\t\tmsg_ai: msgs_lc.AIMessage = model.invoke(msgs)\n",
    "\n",
    "\t\t# Process tool calls and get updated messages\n",
    "\t\tupdated_msgs, should_transfer = process_tools(msg_ai, state[\"messages\"])\n",
    "\t\t\n",
    "\t\tif should_transfer:\n",
    "\t\t\t\treturn graphs.Command(\n",
    "\t\t\t\t\t\tgoto=NODE.AGENT_MUL,\n",
    "\t\t\t\t\t\tupdate={\"messages\": updated_msgs}\n",
    "\t\t\t\t)\n",
    "\t\t\n",
    "\t\treturn {\"messages\": updated_msgs}\n",
    "\n",
    "def agent_multiplication(\n",
    "\t\tstate: graphs.MessagesState,\n",
    ") -> graphs.Command[t.Literal[NODE.AGENT_ADD, graphs.END]]:\n",
    "\t\tmodel = llms.create_tooled_llm(inst.llm_main, [tool_transfer_to_agent_add, multiply])\n",
    "\t\tprompt_system = SYSTEM_PROMPT_TEMPLATE.format(\n",
    "\t\t\t\tdomain=\"mathematical multiplication\",\n",
    "\t\t\t\tprimary_task=\"handling multiplication operations and coordinating with addition expert\",\n",
    "\t\t\t\tspecific_instructions=MUL_SPECIFIC\n",
    "\t\t)\n",
    "\t\tmsgs = [msgs_lc.SystemMessage(prompt_system)] + state[\"messages\"]\n",
    "\t\tmsg_ai: msgs_lc.AIMessage = model.invoke(msgs)\n",
    "\n",
    "\t\t# Process tool calls and get updated messages\n",
    "\t\tupdated_msgs, should_transfer = process_tools(msg_ai, state[\"messages\"])\n",
    "\t\t\n",
    "\t\tif should_transfer:\n",
    "\t\t\t\treturn graphs.Command(\n",
    "\t\t\t\t\t\tgoto=NODE.AGENT_ADD,\n",
    "\t\t\t\t\t\tupdate={\"messages\": updated_msgs}\n",
    "\t\t\t\t)\n",
    "\t\t\n",
    "\t\treturn {\"messages\": updated_msgs}\n",
    "\n",
    "builder = graphs.StateGraph(graphs.MessagesState)\n",
    "\n",
    "builder.add_node(NODE.AGENT_ADD, agent_addition)\n",
    "builder.add_node(NODE.AGENT_MUL, agent_multiplication)\n",
    "\n",
    "builder.add_edge(graphs.START, NODE.AGENT_ADD)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"what's (3 + 5) * 12\"\n",
    "# content = \"what's 3*3 + 1\"\n",
    "\n",
    "pretty_print_stream(\n",
    "\t\tgraph.stream({\"messages\": [msgs_lc.HumanMessage(content=content)]})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
