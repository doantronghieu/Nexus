# Edge LLM

## ðŸ”Ž Keywords

- LLM Large Language Models on Edge Device
- On-Device LLM Large Language Model
- Mobile LLM Github
- Edge LLM Github
- Small LLM

## ðŸ¤– Models

### ðŸ“Š Benchmarks

| Name       | Source | Params | Size  | Context | Hardware | Infer. Time (ms) | Memory Usage (MB) | Acc. (%) | Lang |
|------------|--------|--------|------ |---------|----------|------------------|-------------------|----------|------|
| Phi-3      | ollama | 3.8B   | 2.2BG | 128K    | ...      | ...              | ...               | ...      | ...  |
| Llama 3.1  | ollama | 8B     | 4.7GB | ...     | ...      | ...              | ...               | ...      | ...  |
| Gemma 2    | ollama | 2B     | 1.6GB | ...     | ...      | ...              | ...               | ...      | ...  |
| Qwen2      | ollama | 1.5B   | 935MB | ...     | ...      | ...              | ...               | ...      | ...  |
| ...        | ...    | ...    | ...   | ...     | ...      | ...              | ...               | ...      | ...  |

- VLM:
  - https://molmo.org/

- https://sambanova.ai/
- https://docs.mistral.ai/getting-started/models/models_overview/
- https://qwenlm.github.io/

- https://huggingface.co/collections/facebook/mobilellm-6722be18cb86c20ebe113e95
- https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct

### Ranking

- https://artificialanalysis.ai/
- https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard
- Embedding: https://huggingface.co/spaces/mteb/leaderboard
- https://ollama.com/library
- https://openrouter.ai/rankings

## Repos

- https://github.com/microsoft/Phi-3CookBook
- https://github.com/SqueezeAILab/TinyAgent
- https://github.com/facebookresearch/MobileLLM
- https://huggingface.co/stabilityai/stablelm-zephyr-3b
- https://huggingface.co/TheBloke?sort_models=likes#models

### Dev

- https://github.com/instructor-ai/instructor
- https://github.com/BerriAI/litellm

### ðŸš€ Deployment/Inference

- https://github.com/ggerganov/llama.cpp (ðŸ”¥)
  - https://github.com/microsoft/BitNet
- https://github.com/vllm-project/vllm (ðŸ”¥)
- https://github.com/mlc-ai/mlc-llm
- sudo https://github.com/mudler/LocalAI (ðŸ”¥) |
  - https://llamahub.ai/l/llms/llama-index-llms-localai?from=llms
- https://github.com/xorbitsai/inference (ðŸ”¥)
- https://github.com/turboderp/exllamav2 (ðŸ”¥)
- https://github.com/microsoft/DeepSpeed (ðŸ”¥)
- https://github.com/microsoft/DeepSpeed-MII
- https://github.com/InternLM/lmdeploy
- https://github.com/intel-analytics/ipex-llm
- https://github.com/NVIDIA/TensorRT-LLM
- https://github.com/openvinotoolkit/openvino

Test:
- https://github.com/PygmalionAI/aphrodite-engine
- https://github.com/sgl-project/sglang

### RAG

- https://github.com/microsoft/graphrag
- https://github.com/QuivrHQ/quivr
- https://github.com/infiniflow/ragflow
- https://github.com/weaviate/Verba
- https://github.com/llmware-ai/llmware
- https://github.com/truefoundry/cognita

### NVIDIA

- https://github.com/dusty-nv/jetson-containers
- https://github.com/dusty-nv/jetson-inference
- https://github.com/rbonghi/jetson_stats
- https://github.com/NVIDIA-AI-IOT
- https://github.com/pythops/jetson-image
- https://github.com/pytorch/TensorRT
- https://github.com/NVIDIA/TensorRT-LLM
- https://github.com/NVlabs/VILA
- https://github.com/NVIDIA/nvidia-container-toolkit
- https://github.com/NVIDIA/k8s-device-plugin
- https://github.com/Syllo/nvtop

### Others

- https://github.com/mit-han-lab/TinyChatEngine
- https://github.com/UbiquitousLearning/mllm
- https://github.com/kvcache-ai/ktransformers
- https://github.com/LlamaEdge/LlamaEdge

### Agents

- https://github.com/mem0ai/mem0
- https://github.com/phidatahq/phidata

### ðŸ”§ Optimizations

#### Finetuning

- https://github.com/hiyouga/LLaMA-Factory (ðŸ”¥)
- https://github.com/axolotl-ai-cloud/axolotl (ðŸ”¥)
- https://github.com/h2oai/h2o-wizardlm

#### Quantization

- https://github.com/mit-han-lab/llm-awq
- https://github.com/AutoGPTQ/AutoGPTQ
- https://github.com/casper-hansen/AutoAWQ

## Vector DB

- https://github.com/facebookresearch/faiss

## ðŸ“š Resources

- https://github.com/Hannibal046/Awesome-LLM
- https://github.com/Curated-Awesome-Lists/awesome-llms-fine-tuning
- https://github.com/DefTruth/Awesome-LLM-Inference
- https://github.com/horseee/Awesome-Efficient-LLM
- https://www.reddit.com/r/LocalLLaMA/
- https://pytorch.org/executorch/stable/index.html
- https://hanlab.mit.edu/

### ðŸ“ƒ Surveys

- https://github.com/stevelaskaridis/awesome-mobile-llm
- https://github.com/NexaAI/Awesome-LLMs-on-device

### ðŸ“° Blogs

- https://deepsense.ai/implementing-small-language-models-slms-with-rag-on-embedded-devices-leading-to-cost-reduction-data-privacy-and-offline-use/
- https://developer.nvidia.com/blog/visual-language-intelligence-and-edge-ai-2-0/
- https://azure.microsoft.com/en-us/products/phi-3
- https://developer.nvidia.com/blog/deploy-large-language-models-at-the-edge-with-nvidia-igx-orin-developer-kit/
- https://vinija.ai/concepts/LLMOps/
- https://thenewstack.io/federated-language-models-slms-at-the-edge-plus-cloud-llms/
- https://www.hackster.io/mjrobot/running-large-language-models-on-raspberry-pi-at-the-edge-63bb11

### ðŸ“œ Papers

- https://arxiv.org/pdf/2403.11805
- https://arxiv.org/pdf/2312.11514
- https://matt-rickard.com/a-hackers-guide-to-llm-optimization